{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpwowf_F0Wk7"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6fy0XFU-zo26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3cbb0a-52f4-4e38-e835-fa3df7183ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sklearn_crfsuite\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite import scorers\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ1zU9lkEnd3"
      },
      "source": [
        "***Data From https://github.com/UnB-KnEDLe/experiments/tree/master/members/ian/atos_licitacao_contratos/Corpus3***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORjOObsvR2NU",
        "outputId": "1eea6afe-149d-46b5-bb1c-249b14800e8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/MyDrive/Treinamento_CRF/' 'CRF'"
      ],
      "metadata": {
        "id": "DyjRQIzjR7L5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = 'CRF/'"
      ],
      "metadata": {
        "id": "U6jcEf_nSAiV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Aditamento***"
      ],
      "metadata": {
        "id": "y_OpvBxaQuJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_aditamento = pd.read_csv(folder_path + 'aditamento.csv')"
      ],
      "metadata": {
        "id": "TJfJ-GRrPe7A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Anulação***"
      ],
      "metadata": {
        "id": "p30ZBGsMQwlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_anulacao = pd.read_csv(folder_path + 'anulacao.csv')"
      ],
      "metadata": {
        "id": "ejMPQioRQEjf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Contrato***"
      ],
      "metadata": {
        "id": "fZhmulaNQ2Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_contrato = pd.read_csv(folder_path + 'contrato.csv')"
      ],
      "metadata": {
        "id": "XV19fAnBQFdy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Licitação***"
      ],
      "metadata": {
        "id": "I1p7U9H3Q4NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_licitacao = pd.read_csv(folder_path + 'licitacao.csv')"
      ],
      "metadata": {
        "id": "JN5259O2QFov"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Suspensao***"
      ],
      "metadata": {
        "id": "ye-GxvtCQ688"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_suspensao = pd.read_csv(folder_path + 'suspensao.csv')"
      ],
      "metadata": {
        "id": "8HDUDbInQGRC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Classe CRF***\n",
        "\n"
      ],
      "metadata": {
        "id": "UtmMOrHvA5W_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qljULwbBzZgQ"
      },
      "outputs": [],
      "source": [
        "class CRF_Flow():\n",
        "\n",
        "  def __init__(self, tipo):\n",
        "\n",
        "    self.tipo = tipo\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.x_train = None\n",
        "    self.y_train = None\n",
        "    self.x_test = None\n",
        "    self.y_test = None\n",
        "    self.metrics = {\n",
        "        'tipo': []\n",
        "    }\n",
        "\n",
        "    self.crf = sklearn_crfsuite.CRF(\n",
        "      algorithm = 'lbfgs',\n",
        "      c1=0.17,\n",
        "      c2=0.17,\n",
        "      max_iterations=50,\n",
        "      all_possible_transitions=True\n",
        "    )\n",
        "\n",
        "  def get_features(self, sentence):\n",
        "        \"\"\"Create features for each word in act.\n",
        "        Create a list of dict of words features to be used in the predictor module.\n",
        "        Args:\n",
        "            act (list): List of words in an act.\n",
        "        Returns:\n",
        "            A list with a dictionary of features for each of the words.\n",
        "        \"\"\"\n",
        "        sent_features = []\n",
        "        for i in range(len(sentence)):\n",
        "            # print(sentence[i])\n",
        "            word_feat = {\n",
        "                # Palavra atual\n",
        "                'word': sentence[i].lower(),\n",
        "                'capital_letter': sentence[i][0].isupper(),\n",
        "                'all_capital': sentence[i].isupper(),\n",
        "                'isdigit': sentence[i].isdigit(),\n",
        "                # Uma palavra antes\n",
        "                'word_before': '' if i == 0 else sentence[i-1].lower(),\n",
        "                'word_before_isdigit': '' if i == 0 else sentence[i-1].isdigit(),\n",
        "                'word_before_isupper': '' if i == 0 else sentence[i-1].isupper(),\n",
        "                'word_before_istitle': '' if i == 0 else sentence[i-1].istitle(),\n",
        "\n",
        "                # Uma palavra depois\n",
        "                'word_after': '' if i+1 >= len(sentence) else sentence[i+1].lower(),\n",
        "                'word_after_isdigit': '' if i+1 >= len(sentence) else sentence[i+1].isdigit(),\n",
        "                'word_after_isupper': '' if i+1 >= len(sentence) else sentence[i+1].isupper(),\n",
        "                'word_after_istitle': '' if i+1 >= len(sentence) else sentence[i+1].istitle(),\n",
        "\n",
        "                'BOS': i == 0,\n",
        "                'EOS': i == len(sentence)-1\n",
        "            }\n",
        "            sent_features.append(word_feat)\n",
        "        return sent_features\n",
        "\n",
        "  def load(self, data_frame):\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "\n",
        "    for i, row in enumerate(data_frame['treated_text']):\n",
        "      self.x.append(word_tokenize(data_frame['treated_text'][i]))\n",
        "      self.y.append(data_frame['IOB'][i].split())\n",
        "\n",
        "    for i in range(len(self.x)):\n",
        "      self.x[i] = self.get_features(self.x[i])\n",
        "\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
        "\n",
        "  def train(self):\n",
        "    self.crf.fit(self.x_train, self.y_train)\n",
        "\n",
        "  def validate(self):\n",
        "\n",
        "    classes = list(self.crf.classes_)\n",
        "    classes.remove('O')\n",
        "\n",
        "    y_pred = self.crf.predict(self.x_test)\n",
        "\n",
        "    self.metrics['tipo'].append(self.tipo)\n",
        "                                \n",
        "    for c in classes:\n",
        "      self.metrics[c] = metrics.flat_f1_score(self.y_test, y_pred, average='weighted', labels=c)\n",
        "\n",
        "  def pred(self, ato):\n",
        "    ato = word_tokenize(ato)\n",
        "    ato = self.get_features(ato)\n",
        "    prediction = self.crf.predict([ato])\n",
        "    \n",
        "    print(prediction)\n",
        "\n",
        "  def save(self):\n",
        "    save_df = pd.DataFrame(self.metrics)\n",
        "    save_df.to_csv(self.tipo + '_metricas.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Métricas***"
      ],
      "metadata": {
        "id": "uSRsN0cbQ_OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_aditamento = CRF_Flow('aditamento')\n",
        "model_aditamento.load(df_aditamento)\n",
        "model_aditamento.train()\n",
        "model_aditamento.validate()\n",
        "model_aditamento.save()"
      ],
      "metadata": {
        "id": "iiZS-syqSwUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_anulacao = CRF_Flow('anulacao')\n",
        "model_anulacao.load(df_anulacao)\n",
        "model_anulacao.train()\n",
        "model_anulacao.validate()\n",
        "model_anulacao.save()"
      ],
      "metadata": {
        "id": "A1_w-8nhVd-I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_contrato = CRF_Flow('contrato')\n",
        "model_contrato.load(df_contrato)\n",
        "model_contrato.train()\n",
        "model_contrato.validate()\n",
        "model_contrato.save()"
      ],
      "metadata": {
        "id": "QR-qt-LuVeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_licitacao = CRF_Flow('licitacao')\n",
        "model_licitacao.load(df_licitacao)\n",
        "model_licitacao.train()\n",
        "model_licitacao.validate()\n",
        "model_licitacao.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1nHORM-VeoS",
        "outputId": "5bae0fef-98a2-44e9-cc31-8cbd07762cd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_suspensao = CRF_Flow('suspensao')\n",
        "model_suspensao.load(df_suspensao)\n",
        "model_suspensao.train()\n",
        "model_suspensao.validate()\n",
        "model_suspensao.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spxFQDiOVexj",
        "outputId": "5fb1bfd6-d326-4ac1-ab04-17c926d928d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}