{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando atos no DODFCorpus_contratos_licitacoes_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Corpus3/DODFCorpus_contratos_licitacoes_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_by_word(text):\n",
    "    a = \"\\n\".join([l for l in text.split(\"\\n\") if l != \"\"])\n",
    "    words = a.replace(\"\\n\", \" \").split(\" \")\n",
    "    words = [w for w in words if w != \"\"]\n",
    "    \n",
    "    m_words = []\n",
    "    dash_cut = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "\n",
    "        if (word[-1] == \"-\") and (i+1)<len(words):\n",
    "            word = word[:-1] + words[i+1]\n",
    "            i += 1\n",
    "\n",
    "        m_words.append(word)\n",
    "        \n",
    "    return \" \".join(m_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['id_ato', 'id_dodf', 'tipo_rel', 'tipo_ent', 'texto']].loc[(data['tipo_ent'] == 'EXTRATO_ADITAMENTO_CONTRATUAL') |\\\n",
    "                                                               (data['tipo_ent'] == 'AVISO_LICITACAO') |\\\n",
    "                                                               (data['tipo_ent'] == 'AVISO_SUSPENSAO_LICITACAO') |\\\n",
    "                                                               (data['tipo_ent'] == 'EXTRATO_CONTRATO') |\\\n",
    "                                                               (data['tipo_ent'] == 'EXTRATO_CONVENIO') |\\\n",
    "                                                               (data['tipo_ent'] == 'AVISO_ANUL_REV_LICITACAO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'EXTRATO_ADITAMENTO_CONTRATUAL')]\n",
    "\n",
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'AVISO_LICITACAO')]\n",
    "\n",
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'AVISO_SUSPENSAO_LICITACAO')]\n",
    "\n",
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'EXTRATO_CONTRATO')]\n",
    "\n",
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'EXTRATO_CONVENIO')]\n",
    "\n",
    "data = data[['id_ato', 'id_dodf', 'tipo_rel', 'id_rel', 'anotador_rel', \n",
    "       'tipo_ent', 'id_ent', 'anotador_ent','offset', 'length', 'texto']\n",
    "       ].loc[(data['tipo_ent'] != 'AVISO_ANUL_REV_LICITACAO')]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data1 = data1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = data['tipo_ent'].unique()\n",
    "\n",
    "for token in tokens:\n",
    "    data1[token] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data1)):\n",
    "    texto = clean_text_by_word(data1.loc[i, 'texto']).replace(\"\\r\", \"\")\n",
    "    data1.loc[i, 'texto'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(len(data1)):\n",
    "        if data['id_ato'][i] == data1['id_ato'][j]:\n",
    "            entitie = re.sub('xxbcet ?|xxbcet ?|xxeob ?|xxbob ?|xxecet ?', '', clean_text_by_word(data['texto'][i]).replace(\"\\r\", \"\"))\n",
    "            data1.loc[j, data['tipo_ent'][i]] = entitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['VALOR'] = np.nan\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if type(data1['valor_contrato'][i]) == str:\n",
    "        data1.loc[i, 'VALOR'] = data1['valor_contrato'][i]\n",
    "    elif type(data1['valor_convenio'][i]) == str:\n",
    "        data1.loc[i, 'VALOR'] = data1['valor_convenio'][i]\n",
    "\n",
    "data1['DATA_ASSINATURA'] = np.nan\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if type(data1['data_assinatura_contrato'][i]) == str:\n",
    "        data1.loc[i, 'DATA_ASSINATURA'] = data1['data_assinatura_contrato'][i]\n",
    "    elif type(data1['data_assinatura_convenio'][i]) == str:\n",
    "        data1.loc[i, 'DATA_ASSINATURA'] = data1['data_assinatura_convenio'][i]\n",
    "\n",
    "data1['NUM_AJUSTE'] = np.nan\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if type(data1['numero_contrato'][i]) == str:\n",
    "        data1.loc[i, 'NUM_AJUSTE'] = data1['numero_contrato'][i]\n",
    "    elif type(data1['numero_convenio'][i]) == str:\n",
    "        data1.loc[i, 'NUM_AJUSTE'] = data1['numero_convenio'][i]\n",
    "\n",
    "data1['OBJ_AJUSTE'] = np.nan\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if type(data1['objeto_contrato'][i]) == str:\n",
    "        data1.loc[i, 'OBJ_AJUSTE'] = data1['objeto_contrato'][i]\n",
    "    elif type(data1['objeto_convenio'][i]) == str:\n",
    "        data1.loc[i, 'OBJ_AJUSTE'] = data1['objeto_convenio'][i]\n",
    "\n",
    "data1['VIGENCIA'] = np.nan\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if type(data1['vigencia_contrato'][i]) == str:\n",
    "        data1.loc[i, 'VIGENCIA'] = data1['vigencia_contrato'][i]\n",
    "    elif type(data1['vigencia_convenio'][i]) == str:\n",
    "        data1.loc[i, 'VIGENCIA'] = data1['vigencia_convenio'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_ato', 'dodf', 'tipo_rel', 'ato', 'treated_text',\n",
       "       'MODALIDADE_LICITACAO', 'NUM_LICITACAO', 'VALOR_ESTIMADO',\n",
       "       'DATA_ABERTURA', 'SISTEMA_COMPRAS', 'NOME_RESPONSAVEL', 'TIPO_OBJ',\n",
       "       'PROCESSO', 'OBJ_LICITACAO', 'CODIGO_SISTEMA_COMPRAS',\n",
       "       'ORGAO_LICITANTE', 'DECISAO_TCDF', 'numero_contrato', 'CONTRATANTE',\n",
       "       'CONTRATADA', 'valor_contrato', 'NOTA_EMPENHO', 'CODIGO_UO',\n",
       "       'PROGRAMA_TRABALHO', 'NATUREZA_DESPESA', 'FONTE_RECURSO',\n",
       "       'data_assinatura_contrato', 'objeto_contrato', 'vigencia_contrato',\n",
       "       'NUM_ADITIVO', 'OBJ_ADITIVO', 'DATA_ESCRITO', 'CNPJ_CONTRATADA',\n",
       "       'numero_convenio', 'CONCEDENTE', 'CONVENENTE', 'vigencia_convenio',\n",
       "       'CNPJ_CONVENENTE', 'valor_convenio', 'objeto_convenio',\n",
       "       'data_assinatura_convenio', 'IDENTIFICACAO_OCORRENCIA',\n",
       "       'CNPJ_CONTRATANTE', 'CNPJ_CONCEDENTE', 'CODIGO_SIGGO', 'VALOR',\n",
       "       'DATA_ASSINATURA', 'NUM_AJUSTE', 'OBJ_AJUSTE', 'VIGENCIA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.rename({'id_dodf': 'dodf', 'tipo_ent': 'ato', 'texto': 'treated_text',\n",
    "       'numero_termo_aditivo': 'NUM_ADITIVO', 'orgao_contratante': 'CONTRATANTE',\n",
    "       'objeto_aditamento_contratual': 'OBJ_ADITIVO', 'processo_gdf': 'PROCESSO', 'modalidade_licitacao': 'MODALIDADE_LICITACAO',\n",
    "       'numero_licitacao': 'NUM_LICITACAO', 'orgao_licitante': 'ORGAO_LICITANTE', 'sistema_compras': 'SISTEMA_COMPRAS',\n",
    "       'valor_estimado_contratacao': 'VALOR_ESTIMADO', 'data_abertura_licitacao': 'DATA_ABERTURA',\n",
    "       'nome_responsavel': 'NOME_RESPONSAVEL', 'tipo_objeto': 'TIPO_OBJ', 'objeto_licitacao': 'OBJ_LICITACAO', 'data_escrito': 'DATA_ESCRITO',\n",
    "       'codigo_licitacao_sistema_compras': 'CODIGO_SISTEMA_COMPRAS', 'decisao_tcdf': 'DECISAO_TCDF',\n",
    "       'entidade_contratada': 'CONTRATADA', 'nota_empenho': 'NOTA_EMPENHO',\n",
    "       'unidade_orcamentaria': 'CODIGO_UO', 'programa_trabalho': 'PROGRAMA_TRABALHO', 'natureza_despesa': 'NATUREZA_DESPESA',\n",
    "       'fonte_recurso': 'FONTE_RECURSO',\n",
    "       'cnpj_entidade_contratada': 'CNPJ_CONTRATADA', 'orgao_concedente': 'CONCEDENTE',\n",
    "       'entidade_convenente': 'CONVENENTE', 'cnpj_entidade_convenente': 'CNPJ_CONVENENTE',\n",
    "       'identificacao_ocorrencia': 'IDENTIFICACAO_OCORRENCIA',\n",
    "       'cnpj_orgao_contratante': 'CNPJ_CONTRATANTE', 'cnpj_orgao_concedente': 'CNPJ_CONCEDENTE', 'codigo_siggo': 'CODIGO_SIGGO'}, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acts = data1[['ato', 'dodf', 'treated_text', 'PROCESSO',\n",
    "       'NUM_AJUSTE', 'CONTRATANTE', 'CONTRATADA', 'OBJ_AJUSTE', 'VIGENCIA',\n",
    "       'VALOR', 'PROGRAMA_TRABALHO', 'DATA_ASSINATURA', 'CODIGO_UO', 'NATUREZA_DESPESA', 'NOTA_EMPENHO',\n",
    "       'ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
    "       'MODALIDADE_LICITACAO', 'DATA_ABERTURA', 'TIPO_OBJ', 'VALOR_ESTIMADO',\n",
    "       'CODIGO_SISTEMA_COMPRAS', 'OBJ_ADITIVO', 'NUM_ADITIVO',\n",
    "       'SISTEMA_COMPRAS', 'CONVENENTE', 'DECISAO_TCDF',\n",
    "       'NOME_RESPONSAVEL', 'DATA_ESCRITO', 'FONTE_RECURSO',\n",
    "       'CNPJ_CONTRATADA', 'CONCEDENTE',  'CNPJ_CONVENENTE',\n",
    "       'IDENTIFICACAO_OCORRENCIA', 'CNPJ_CONTRATANTE', 'CNPJ_CONCEDENTE', 'CODIGO_SIGGO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_acts.to_csv('Corpus3/data_acts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando atos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_acts = pd.read_csv('Corpus2/data_acts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AVISO_LICITACAO', 'AVISO_SUSPENSAO_LICITACAO', 'EXTRATO_CONTRATO',\n",
       "       'EXTRATO_ADITAMENTO_CONTRATUAL', 'EXTRATO_CONVENIO',\n",
       "       'AVISO_ANUL_REV_LICITACAO'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_acts['ato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lic = data_acts[list(data_acts.columns)].loc[(data_acts['ato'] == 'AVISO_LICITACAO')]\n",
    "lic = lic.reset_index(drop=True)\n",
    "\n",
    "sus = data_acts[list(data_acts.columns)].loc[(data_acts['ato'] == 'AVISO_SUSPENSAO_LICITACAO')]\n",
    "sus = sus.reset_index(drop=True)\n",
    "\n",
    "anr = data_acts[list(data_acts.columns)].loc[(data_acts['ato'] == 'AVISO_ANUL_REV_LICITACAO')]\n",
    "anr = anr.reset_index(drop=True)\n",
    "\n",
    "adi = data_acts[list(data_acts.columns)].loc[(data_acts['ato'] == 'EXTRATO_ADITAMENTO_CONTRATUAL')]\n",
    "adi = adi.reset_index(drop=True)\n",
    "\n",
    "con = data_acts[list(data_acts.columns)].loc[(data_acts['ato'] == 'EXTRATO_CONTRATO') |\\\n",
    "                               (data_acts['ato'] == 'EXTRATO_CONVENIO') |\\\n",
    "                               (data_acts['ato'] == 'EXTRATO_CONTRATO_CONVENIO')]\n",
    "con = con.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 46, 68, 1537, 1566, 3855)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lic), len(anr), len(sus), len(adi), len(con), len(data_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ['ato', 'dodf', 'treated_text']\n",
    "\n",
    "for i in range(3, len(list(lic.isnull().sum()))):\n",
    "    if list(lic.isnull().sum())[i] != len(lic):\n",
    "        ent.append(list(lic.columns)[i])\n",
    "\n",
    "lic = lic[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ['ato', 'dodf', 'treated_text']\n",
    "\n",
    "for i in range(3, len(list(anr.isnull().sum()))):\n",
    "    if list(anr.isnull().sum())[i] != len(anr):\n",
    "        ent.append(list(anr.columns)[i])\n",
    "\n",
    "anr = anr[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ['ato', 'dodf', 'treated_text']\n",
    "\n",
    "for i in range(3, len(list(sus.isnull().sum()))):\n",
    "    if list(sus.isnull().sum())[i] != len(sus):\n",
    "        ent.append(list(sus.columns)[i])\n",
    "\n",
    "sus = sus[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ['ato', 'dodf', 'treated_text']\n",
    "\n",
    "for i in range(3, len(list(adi.isnull().sum()))):\n",
    "    if list(adi.isnull().sum())[i] != len(adi):\n",
    "        ent.append(list(adi.columns)[i])\n",
    "\n",
    "adi = adi[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = ['ato', 'dodf', 'treated_text']\n",
    "\n",
    "for i in range(3, len(list(con.isnull().sum()))):\n",
    "    if list(con.isnull().sum())[i] != len(con):\n",
    "        ent.append(list(con.columns)[i])\n",
    "\n",
    "con = con[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome = False\n",
    "for i in range(len(con)):\n",
    "    if not pd.isna(con['NOME_RESPONSAVEL'][i]):\n",
    "        nome = True\n",
    "        break\n",
    "    \n",
    "if not nome:\n",
    "    con['NOME_RESPONSAVEL'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unindo contrato e convênio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "con['CONTRATANTE_ou_CONCEDENTE'] = np.nan\n",
    "\n",
    "for i in range(len(con)):\n",
    "    if not pd.isna(con['CONTRATANTE'][i]):\n",
    "        con.loc[i, 'CONTRATANTE_ou_CONCEDENTE'] = con['CONTRATANTE'][i]\n",
    "    elif not pd.isna(con['CONCEDENTE'][i]):\n",
    "        con.loc[i, 'CONTRATANTE_ou_CONCEDENTE'] = con['CONCEDENTE'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "con['CONTRATADA_ou_CONVENENTE'] = np.nan\n",
    "\n",
    "for i in range(len(con)):\n",
    "    if not pd.isna(con['CONTRATADA'][i]):\n",
    "        con.loc[i, 'CONTRATADA_ou_CONVENENTE'] = con['CONTRATADA'][i]\n",
    "    elif not pd.isna(con['CONVENENTE'][i]):\n",
    "        con.loc[i, 'CONTRATADA_ou_CONVENENTE'] = con['CONVENENTE'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "con['CNPJ_CONTRATANTE_ou_CONCEDENTE'] = np.nan\n",
    "\n",
    "for i in range(len(con)):\n",
    "    if not pd.isna(con['CNPJ_CONTRATANTE'][i]):\n",
    "        con.loc[i, 'CNPJ_CONTRATANTE_ou_CONCEDENTE'] = con['CNPJ_CONTRATANTE'][i]\n",
    "    elif not pd.isna(con['CNPJ_CONCEDENTE'][i]):\n",
    "        con.loc[i, 'CNPJ_CONTRATANTE_ou_CONCEDENTE'] = con['CNPJ_CONCEDENTE'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "con['CNPJ_CONTRATADA_ou_CONVENENTE'] = np.nan\n",
    "\n",
    "for i in range(len(con)):\n",
    "    if not pd.isna(con['CNPJ_CONTRATADA'][i]):\n",
    "        con.loc[i, 'CNPJ_CONTRATADA_ou_CONVENENTE'] = con['CNPJ_CONTRATADA'][i]\n",
    "    elif not pd.isna(con['CNPJ_CONVENENTE'][i]):\n",
    "        con.loc[i, 'CNPJ_CONTRATADA_ou_CONVENENTE'] = con['CNPJ_CONVENENTE'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = con[['ato', 'dodf', 'treated_text', 'PROCESSO', 'NUM_AJUSTE',\n",
    "       'OBJ_AJUSTE', 'VIGENCIA', 'VALOR', 'PROGRAMA_TRABALHO',\n",
    "       'DATA_ASSINATURA', 'CODIGO_UO', 'NATUREZA_DESPESA', 'NOTA_EMPENHO',\n",
    "       'NOME_RESPONSAVEL', 'FONTE_RECURSO',\n",
    "       'CONTRATANTE_ou_CONCEDENTE', 'CONTRATADA_ou_CONVENENTE',\n",
    "       'CNPJ_CONTRATANTE_ou_CONCEDENTE', 'CNPJ_CONTRATADA_ou_CONVENENTE', 'CODIGO_SIGGO']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, tokenizer=''):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "    def __call__(self, X, **kw_params):\n",
    "        return self.tokenizer(X, **kw_params)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, **kw_params):\n",
    "        if not isinstance(X, pd.Series):\n",
    "            print(\"[preprocess.Tokenizer.transform] TYPE:\", type(X))\n",
    "            print('X:::: ', X)\n",
    "            X = pd.Series(X)\n",
    "        return X.map(self)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IOBifyer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    @staticmethod\n",
    "    def find_entity(row, token, ignore_idx=0,\n",
    "        tokenizer=''):\n",
    "        # TODO: aceitar opção de offset, para não ter tennhum tipo de problema\n",
    "        for idx, column in enumerate(row.keys()):\n",
    "            if idx == ignore_idx:\n",
    "                continue\n",
    "            if isinstance(row[column], str) and \\\n",
    "                token == word_tokenize(row[column])[0]:\n",
    "                return column\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_IOB_labels(row, idx, tokenizer, dbg={}):\n",
    "        labels = []\n",
    "        entity_started = False\n",
    "        text = row.iloc[idx]\n",
    "        for token in word_tokenize(text):                         \n",
    "            if not entity_started:                               \n",
    "                entity = IOBifyer.find_entity(row, token, idx)                 \n",
    "                if entity is not None:                           \n",
    "                    entity_started = True\n",
    "                    token_index = 1\n",
    "                    labels.append('B-' + entity)\n",
    "                else:\n",
    "                    labels.append('O')\n",
    "            else:\n",
    "                if token_index < len(word_tokenize(row[entity])) and \\\n",
    "                    token == word_tokenize(row[entity])[token_index]:\n",
    "                    labels.append('I-' + entity)\n",
    "                    token_index += 1\n",
    "                    if token_index >= len(word_tokenize(row[entity])):\n",
    "                        entity_started = False\n",
    "                else:\n",
    "                    entity_started = False\n",
    "                    labels.append('O')\n",
    "        if labels[0] != 'O':\n",
    "            dbg['l'] = dbg.get('l', []) + [(row, idx)]\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def dump_iob(tokens_mat, labels_mat, path='dump.txt',\n",
    "                            sep=' X X ', sent_sep='\\n',):\n",
    "        dbg_mat = []\n",
    "        if isinstance(path, Path):\n",
    "            path = path.as_posix()\n",
    "        if '/' in path:\n",
    "            os.makedirs('/'.join(path.split('/')[:-1]), exist_ok=True)\n",
    "\n",
    "        with open(path, 'w') as fp:\n",
    "            for tokens_lis, labels_lis in zip(tokens_mat, labels_mat):\n",
    "                dbg_mat.append([])\n",
    "                for token, label in zip(tokens_lis, labels_lis):\n",
    "                    dbg_mat[-1].append((token, label))\n",
    "                    fp.write(f\"{token}{sep}{label}\\n\")\n",
    "                fp.write(sent_sep)\n",
    "        return dbg_mat\n",
    "\n",
    "\n",
    "    def __init__(self, column='act_column',\n",
    "        tokenizer=''):\n",
    "        self.column = column\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dbg = {}\n",
    "\n",
    "\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, df):\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(f\"`df` expected to be a pd.DataFrame. Got {type(df)}\")\n",
    "        if df.empty:\n",
    "            print(\"[core.preprocess]Warning: empty DataFrame. There won't be ioblabels.\")\n",
    "            return pd.Series()\n",
    "\n",
    "        idx = self.column if isinstance(self.column, int) else  \\\n",
    "                df.columns.get_loc(self.column)\n",
    "        labels_row = []\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                labels_row.append(\n",
    "                    IOBifyer.generate_IOB_labels(\n",
    "                        row, idx, self.tokenizer, self.dbg\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"problem iobifyin row:\", row)\n",
    "                raise e\n",
    "        return pd.Series(labels_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ianfi\\AppData\\Local\\Temp\\ipykernel_20136\\1078628249.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lic[\"IOB\"] = np.nan\n",
      "C:\\Users\\ianfi\\AppData\\Local\\Temp\\ipykernel_20136\\1078628249.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lic.loc[i, \"IOB\"] = ' '.join(r_lic[i])\n"
     ]
    }
   ],
   "source": [
    "# Licitacao\n",
    "lic_iob = lic[list(lic.columns)[2:]]\n",
    "\n",
    "iob_lic= IOBifyer(column='treated_text')\n",
    "r_lic = iob_lic.transform(lic_iob)\n",
    "lic[\"IOB\"] = np.nan\n",
    "\n",
    "for i in range(len(lic)):\n",
    "    lic.loc[i, \"IOB\"] = ' '.join(r_lic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lic)):\n",
    "    if len(lic.loc[0, \"IOB\"].split()) != len(word_tokenize(lic.loc[0, \"treated_text\"])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suspensao\n",
    "sus_iob = sus[list(sus.columns)[2:]]\n",
    "\n",
    "iob_sus = IOBifyer(column='treated_text')\n",
    "r_sus = iob_sus.transform(sus_iob)\n",
    "sus[\"IOB\"] = np.nan\n",
    "\n",
    "for i in range(len(sus)):\n",
    "    sus.loc[i, \"IOB\"] = ' '.join(r_sus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sus)):\n",
    "    if len(sus.loc[0, \"IOB\"].split()) != len(word_tokenize(sus.loc[0, \"treated_text\"])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anulacao e revogacao\n",
    "anr_iob = anr[list(anr.columns)[2:]]\n",
    "\n",
    "iob_anr = IOBifyer(column='treated_text')\n",
    "r_anr = iob_anr.transform(anr_iob)\n",
    "anr[\"IOB\"] = np.nan\n",
    "\n",
    "for i in range(len(anr)):\n",
    "    anr.loc[i, \"IOB\"] = ' '.join(r_anr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(anr)):\n",
    "    if len(anr.loc[0, \"IOB\"].split()) != len(word_tokenize(anr.loc[0, \"treated_text\"])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aditamento\n",
    "adi_iob = adi[list(adi.columns)[2:]]\n",
    "\n",
    "iob_adi = IOBifyer(column='treated_text')\n",
    "r_adi = iob_adi.transform(adi_iob)\n",
    "adi[\"IOB\"] = np.nan\n",
    "\n",
    "for i in range(len(adi)):\n",
    "    adi.loc[i, \"IOB\"] = ' '.join(r_adi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(adi)):\n",
    "    if len(adi.loc[0, \"IOB\"].split()) != len(word_tokenize(adi.loc[0, \"treated_text\"])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrato e convenio\n",
    "con_iob = con[list(con.columns)[2:]]\n",
    "\n",
    "iob_con = IOBifyer(column='treated_text')\n",
    "r_con = iob_con.transform(con_iob)\n",
    "con[\"IOB\"] = np.nan\n",
    "\n",
    "for i in range(len(con)):\n",
    "    con.loc[i, \"IOB\"] = ' '.join(r_con[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(con)):\n",
    "    if len(con.loc[0, \"IOB\"].split()) != len(word_tokenize(con.loc[0, \"treated_text\"])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 68, 46, 1537, 1566)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lic), len(sus), len(anr), len(adi), len(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lic.to_csv('Corpus3/licitacao.csv', index=False)\n",
    "# sus.to_csv('Corpus3/suspensao.csv', index=False)\n",
    "# anr.to_csv('Corpus3/anulacao_revogacao.csv', index=False)\n",
    "# adi.to_csv('Corpus3/aditamento_contratual.csv', index=False)\n",
    "# con.to_csv('Corpus3/contrato_convenio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "326a1a2f783c07b18559778bdda0b8194460ae1418816323f0f6f16e12b614e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
