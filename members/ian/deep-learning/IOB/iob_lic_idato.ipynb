{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from typing import Iterable as Iter\n",
    "from typing import Callable\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../acts_parquet/iob_contratos_idato.parquet')\n",
    "df2 = pd.read_parquet('../acts_parquet/aviso_licitacao_all_entities_iob.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[list(data.columns)].loc[(data['tipo_ent'] == 'AVISO_LICITACAO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dict(df.isnull().sum()).items():\n",
    "    if  v == len(df):\n",
    "        df.drop(k, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_ato', 'id_dodf', 'tipo_rel', 'tipo_ent', 'texto', 'processo_gdf',\n",
       "       'modalidade_licitacao', 'numero_licitacao', 'orgao_licitante',\n",
       "       'sistema_compras', 'valor_estimado_contratacao',\n",
       "       'data_abertura_licitacao', 'nome_responsavel', 'tipo_objeto',\n",
       "       'objeto_licitacao', 'codigo_licitacao_sistema_compras', 'IOB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'texto': 'treated_text', 'processo_gdf': 'PROCESSO',\n",
    "       'modalidade_licitacao': 'MODALIDADE_LICITACAO', 'numero_licitacao': 'NUM_LICITACAO', 'orgao_licitante': 'ORGAO_LICITANTE',\n",
    "       'sistema_compras': 'SISTEMA_COMPRAS', 'valor_estimado_contratacao': 'VALOR_ESTIMADO',\n",
    "       'data_abertura_licitacao': 'DATA_ABERTURA', 'nome_responsavel': 'NOME_RESPONSAVEL', 'tipo_objeto': 'TIPO_OBJ',\n",
    "       'objeto_licitacao': 'OBJ_LICITACAO', 'codigo_licitacao_sistema_compras': 'CODIGO_SISTEMA_COMPRAS',}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_ato', 'id_dodf', 'tipo_rel', 'tipo_ent', 'treated_text', 'PROCESSO',\n",
       "       'MODALIDADE_LICITACAO', 'NUM_LICITACAO', 'ORGAO_LICITANTE',\n",
       "       'SISTEMA_COMPRAS', 'VALOR_ESTIMADO', 'DATA_ABERTURA',\n",
       "       'NOME_RESPONSAVEL', 'TIPO_OBJ', 'OBJ_LICITACAO',\n",
       "       'CODIGO_SISTEMA_COMPRAS', 'IOB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
    "       'MODALIDADE_LICITACAO', 'PROCESSO', 'DATA_ABERTURA', 'TIPO_OBJ',\n",
    "       'VALOR_ESTIMADO', 'CODIGO_SISTEMA_COMPRAS', 'SISTEMA_COMPRAS',\n",
    "       'NOME_RESPONSAVEL', 'treated_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['NOME_RESPONSAVEL'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
       "       'MODALIDADE_LICITACAO', 'PROCESSO', 'DATA_ABERTURA', 'TIPO_OBJ',\n",
       "       'VALOR_ESTIMADO', 'CODIGO_SISTEMA_COMPRAS', 'SISTEMA_COMPRAS',\n",
       "       'treated_text', 'IOB', 'NOME_RESPONSAVEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
    "       'MODALIDADE_LICITACAO', 'PROCESSO', 'DATA_ABERTURA', 'TIPO_OBJ',\n",
    "       'VALOR_ESTIMADO', 'CODIGO_SISTEMA_COMPRAS', 'SISTEMA_COMPRAS',\n",
    "       'NOME_RESPONSAVEL', 'treated_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acts = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acts = df_acts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "DEFAULT_TOKENIZER = nltk.RegexpTokenizer(r\"\\w+|\\$[\\d\\.\\-\\\\]+|\\S+\").tokenize\n",
    "class Tokenizer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\" Class to apply tokenizer to pandas DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer=DEFAULT_TOKENIZER):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "    def __call__(self, X, **kw_params):\n",
    "        return self.tokenizer(X, **kw_params)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, **kw_params):\n",
    "        if not isinstance(X, pd.Series):\n",
    "            print(\"[preprocess.Tokenizer.transform] TYPE:\", type(X))\n",
    "            print('X:::: ', X)\n",
    "            X = pd.Series(X)\n",
    "        return X.map(self)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IOBifyer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def find_entity(row, token, ignore_idx=0,\n",
    "        tokenizer=DEFAULT_TOKENIZER):\n",
    "        # TODO: aceitar opção de offset, para não ter tennhum tipo de problema\n",
    "        \"\"\"Searches for named entities on columns, except by ignore_idx-columns.\n",
    "\n",
    "        ignore_idx: int indicating which column has\n",
    "                    the TEXT where the named entity were extracted from\n",
    "        \"\"\"\n",
    "        for idx, column in enumerate(row.keys()):\n",
    "            if idx == ignore_idx:\n",
    "                continue\n",
    "            if isinstance(row[column], str) and \\\n",
    "                token == tokenizer(row[column])[0]:\n",
    "                return column\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_IOB_labels(row, idx, tokenizer, dbg={}):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            row ([pd.Series]): [pandas series having act text and entities text]\n",
    "            idx ([int]): [index such that `row[idx]` has the whole act]\n",
    "            tokenizer ([Callable]): [function to use to tokenize `row[idx]`]\n",
    "            dbg (dict, optional): [dictionay for debug purposes]. Defaults to {}.\n",
    "\n",
    "        Returns:\n",
    "            [Iter[Iter[str]]]: [matrix of IOB labels]\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        entity_started = False\n",
    "        text = row.iloc[idx]\n",
    "        for token in tokenizer(text):                         # Itera sobre cada token da anotação do ato.\n",
    "            if not entity_started:                               # Caso uma entidade ainda n tenha sido identificada nos tokens.\n",
    "                entity = IOBifyer.find_entity(row, token, idx)                 # Busca o token atual no primeiro token de todos os campos do df.\n",
    "                if entity is not None:                           # Se foi encontrado o token no inicio de alguma entidade ele inicia a comparação token a token com a entidade.\n",
    "                    entity_started = True\n",
    "                    token_index = 1\n",
    "                    labels.append('B-' + entity)\n",
    "                else:\n",
    "                    labels.append('O')\n",
    "            else:     # Caso uma entidade já tenha sido identificada\n",
    "                if token_index < len(tokenizer(row[entity])) and \\\n",
    "                    token == tokenizer(row[entity])[token_index]:\n",
    "                    # Checa se o próximo token pertence à entidade\n",
    "                    # e se o tamanho da entidade chegou ao fim.\n",
    "                    labels.append('I-' + entity)\n",
    "                    # Se a entidade ainda possui tokens e a comparação foi bem\n",
    "                    # sucedida adicione o label I.\n",
    "                    token_index += 1\n",
    "                    if token_index >= len(tokenizer(row[entity])):\n",
    "                        entity_started = False\n",
    "                else:\n",
    "                    # Se o token n for igual ou a entidade chegou ao fim.\n",
    "                    entity_started = False\n",
    "                    labels.append('O')\n",
    "        if labels[0] != 'O':\n",
    "            dbg['l'] = dbg.get('l', []) + [(row, idx)]\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def dump_iob(tokens_mat, labels_mat, path='dump.txt',\n",
    "                            sep=' X X ', sent_sep='\\n',):\n",
    "        \"\"\"This method dumps the token matrix according its IOB labels.\n",
    "\n",
    "        For debug purposes, a list of list of pairs (token, label) is returned.\n",
    "        Args:\n",
    "            tokens_mat ([Iter[Iter[str]]]): [matrix of strings corresponding to tokens]\n",
    "            labels_mat ([Iter[Iter[str]]]): [matrix of strings corresponding to IOB labels]\n",
    "            path (str, optional): [Path to dump text file]. Defaults to 'dump.txt'.\n",
    "            sep (str, optional): [description]. Defaults to ' X X '.\n",
    "            sent_sep (str, optional): [description]. Defaults to '\\n'.\n",
    "\n",
    "        Returns:\n",
    "            [List[LIst[Tuple(str, str)]]]: [list of list of pairs (token, label), as dumped. For debug purposes.]\n",
    "        \"\"\"\n",
    "        dbg_mat = []\n",
    "        if isinstance(path, Path):\n",
    "            path = path.as_posix()\n",
    "        if '/' in path:\n",
    "            os.makedirs('/'.join(path.split('/')[:-1]), exist_ok=True)\n",
    "\n",
    "        with open(path, 'w') as fp:\n",
    "            for tokens_lis, labels_lis in zip(tokens_mat, labels_mat):\n",
    "                dbg_mat.append([])\n",
    "                for token, label in zip(tokens_lis, labels_lis):\n",
    "                    dbg_mat[-1].append((token, label))\n",
    "                    fp.write(f\"{token}{sep}{label}\\n\")\n",
    "                fp.write(sent_sep)\n",
    "        return dbg_mat\n",
    "\n",
    "\n",
    "    def __init__(self, column='act_column',\n",
    "        tokenizer=DEFAULT_TOKENIZER):\n",
    "        self.column = column\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dbg = {}\n",
    "\n",
    "\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, df):\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(f\"`df` expected to be a pd.DataFrame. Got {type(df)}\")\n",
    "        if df.empty:\n",
    "            print(\"[core.preprocess]Warning: empty DataFrame. There won't be ioblabels.\")\n",
    "            return pd.Series()\n",
    "\n",
    "        idx = self.column if isinstance(self.column, int) else  \\\n",
    "                df.columns.get_loc(self.column)\n",
    "        labels_row = []\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                labels_row.append(\n",
    "                    IOBifyer.generate_IOB_labels(\n",
    "                        row, idx, self.tokenizer, self.dbg\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"problem iobifyin row:\", row)\n",
    "                raise e\n",
    "        return pd.Series(labels_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
       "       'MODALIDADE_LICITACAO', 'PROCESSO', 'DATA_ABERTURA', 'TIPO_OBJ',\n",
       "       'VALOR_ESTIMADO', 'CODIGO_SISTEMA_COMPRAS', 'SISTEMA_COMPRAS',\n",
       "       'NOME_RESPONSAVEL', 'treated_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_acts[['ORGAO_LICITANTE', 'NUM_LICITACAO', 'OBJ_LICITACAO',\n",
    "       'MODALIDADE_LICITACAO', 'PROCESSO', 'DATA_ABERTURA',\n",
    "       'VALOR_ESTIMADO', 'CODIGO_SISTEMA_COMPRAS', 'SISTEMA_COMPRAS',\n",
    "       'NOME_RESPONSAVEL', 'treated_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "iob = IOBifyer(column='treated_text')\n",
    "r = iob.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [O, O, O, B-MODALIDADE_LICITACAO, I-MODALIDADE...\n",
       "1      [B-MODALIDADE_LICITACAO, I-MODALIDADE_LICITACA...\n",
       "2      [O, O, O, O, O, O, O, B-MODALIDADE_LICITACAO, ...\n",
       "3      [O, O, O, B-MODALIDADE_LICITACAO, I-MODALIDADE...\n",
       "4      [O, O, O, B-MODALIDADE_LICITACAO, I-MODALIDADE...\n",
       "                             ...                        \n",
       "430    [B-MODALIDADE_LICITACAO, O, B-NUM_LICITACAO, I...\n",
       "431    [B-MODALIDADE_LICITACAO, O, B-NUM_LICITACAO, I...\n",
       "432    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "433    [O, O, O, O, O, O, B-PROCESSO, I-PROCESSO, O, ...\n",
       "434    [O, O, O, B-MODALIDADE_LICITACAO, I-MODALIDADE...\n",
       "Length: 435, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((435, 11), (435,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"IOB\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data.loc[i, \"IOB\"] = ' '.join(r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if len(data['IOB'][i].split()) != len(DEFAULT_TOKENIZER(data['treated_text'][i])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('../acts_parquet/lic_435_acts_200x_2018_2020.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d973542429c9f505f96bdf709f83097f4740f6c9df1afcdf6fa66ab031bc1ccc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ian': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
