{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skweak\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resgate():\n",
    "    pdf = open('contratos.txt', 'r')    \n",
    "    leitura = pdf.read().replace(\"\\n\", \"\")\n",
    "    regex_ = re.compile(r\"(EXTRATO\\sD[O|E]\\sCONTRATO[.|\\s|\\S]*?<>END OF BLOCK<>)\")\n",
    "    return(regex_.findall(leitura))\n",
    "\n",
    "dados = resgate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"lemmatizer\"])\n",
    "nlp = spacy.load('pt_core_news_sm', disable=[\"ner\", \"lemmatizer\"])\n",
    "docs = list(nlp.pipe(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrato_(doc):\n",
    "    expression = r\"(\\d+/\\d{4})\"\n",
    "    for match in re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            tamanho = len(grupo.split())\n",
    "            for token in docs:\n",
    "                if token.text in {grupo}:\n",
    "                    yield token.i, token.i+tamanho, \"CONTRATO\"\n",
    "                    # print(docs[0][token.i:token.i+tamanho])\n",
    "            break \n",
    "\n",
    "def processo_(doc):\n",
    "    expression = r\"[P|p][R|r][O|o][C|c][E|e][S|s][S|s][O|o][:|\\sSEI].*?(\\d+[\\.|-|-|\\/]\\d+[\\.|-|-|\\/]\\d+[\\.|-|-|\\/]\\d*)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'\\/\\s', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"PROCESSO\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def data_assinatura_(doc):\n",
    "    expression = r\"[A|a][S|s][S|s][I|i][N|n][A|a][T|t][U|u][R|r][A|a]:.*?[\\s\\S](\\d{2}\\/\\d{2}\\/\\d{4}|\\d+.*?[\\s\\S]\\w+.*?[\\s\\S]\\w+.*?[\\s\\S]\\w+.*?[\\s\\S]\\d+)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'\\/\\s', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"DATA ASSINAT.\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "# def partes_(doc):\n",
    "#     expression = r\"[P|p][A|a][R|r][T|t][E|e][S|s]:.?([^,|;|]*)\"\n",
    "#     for match in re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "#         if(match.groups):\n",
    "#             grupo = (match.groups()[0])\n",
    "#             if (\"(\" or \")\") in grupo:\n",
    "#                     grupo = grupo.replace(\"(\", \"\\(\")\n",
    "#                     grupo = grupo.replace(\")\", \"\\)\")\n",
    "#             start = re.search(grupo, docs[0].text).span()[0]\n",
    "#             end = re.search(grupo, docs[0].text).span()[1]\n",
    "#             span = docs[0].char_span(start, end)\n",
    "#             print(\"Found match:\", span.text)\n",
    "#             break\n",
    "\n",
    "# def objeto_(doc):\n",
    "#     expression = r\"[O|o][B|b][J|j][E|e][T|t][O|o]:.?([^,|;|.]*)\"\n",
    "#     for match in re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "#         if(match.groups):\n",
    "#             grupo = (match.groups()[0])\n",
    "#             if (\"(\" or \")\") in grupo:\n",
    "#                     grupo = grupo.replace(\"(\", \"\\(\")\n",
    "#                     grupo = grupo.replace(\")\", \"\\)\")\n",
    "#             start = re.search(grupo, docs[0].text).span()[0]\n",
    "#             end = re.search(grupo, docs[0].text).span()[1]\n",
    "#             span = docs[0].char_span(start, end)\n",
    "#             print(\"Found match:\", span.text)\n",
    "#             break\n",
    "\n",
    "\n",
    "def vigencia_(doc):\n",
    "    expression = r\"[V|v][I|i][G|g][E|e|ê][N|n][C|c][I|i][A|a].*?[\\S\\s].*?([^,|;|.]*)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"VIGÊNCIA\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def valor_(doc):\n",
    "    expression = r\"[v|V][a|A][l|L][o|O][r|R].*?[\\s\\S].*?([\\d\\.]*,\\d{2})\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"VALOR\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def unidade_orcamento_(doc):\n",
    "    expression = r\"[o|O][r|R][c|C|ç|Ç][a|A][m|M][e|E][n|N][t|T][a|A|á|Á][r|R][i|I][a|A].*?[\\s\\S].*?(\\d+.\\d+)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"UN. ORCAMENTARIA\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def programa_trabalho_(doc):\n",
    "    expression = r\"[T|t][R|r][A|a][B|b][A|a][L|l][H|h][O|o]?[:|;|[\\s\\S].*?(\\d*.\\d*.\\d*.\\d*.\\d{4,6}.\\d{4,6})\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"PROG. TRABALHO\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def natureza_emepnho_(doc):\n",
    "    expression = r\"Natureza d[e|a] Despesa:[\\s\\S].*?([\\d.\\d]*)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"NAT. EMPENHO\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "def nota_empenho_(doc):\n",
    "    expression = r\"(\\d+NE\\d+)\"\n",
    "    for match in  re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "        if(match.groups):\n",
    "            grupo = (match.groups()[0])\n",
    "            grupo_copy = grupo\n",
    "            if (\"(\" or \")\") in grupo:\n",
    "                    grupo = grupo.replace(\"(\", \"\\(\")\n",
    "                    grupo = grupo.replace(\")\", \"\\)\")\n",
    "            tamanho = len(grupo.split())\n",
    "            start = re.search(grupo, doc.text).span()[0]\n",
    "            end = re.search(grupo, doc.text).span()[1]\n",
    "            span = str(doc.char_span(start, end))\n",
    "            x = re.findall(r'[\\(|\\)]', span)\n",
    "            for token in doc:\n",
    "                if(grupo_copy in str(doc[token.i: token.i+tamanho+len(x)])):\n",
    "                    yield token.i, token.i+tamanho+len(x), \"NOTA EMPENHO\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "\n",
    "# def entidade_contratada_(doc):\n",
    "#     expression = r\"[c|C][o|O][n|N][t|T][r|R][a|A][t|T][a|A][d|D][a|A|o|O].(.+\\w+[\\s\\S].*?[\\/.|])\"\n",
    "#     for match in re.finditer(expression, doc.text): #doc.tex with m re.finditer to return span with char_span\n",
    "#         if(match.groups):\n",
    "#             grupo = (match.groups()[0])\n",
    "#             if (\"(\" or \")\") in grupo:\n",
    "#                     grupo = grupo.replace(\"(\", \"\\(\")\n",
    "#                     grupo = grupo.replace(\")\", \"\\)\")\n",
    "#             start = re.search(grupo, docs[0].text).span()[0]\n",
    "#             end = re.search(grupo, docs[0].text).span()[1]\n",
    "#             span = docs[0].char_span(start, end)\n",
    "#             print(\"Found match:\", span.text)\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detec_contrato = skweak.heuristics.FunctionAnnotator(\"detec_contrato\", contrato_)\n",
    "detec_processo = skweak.heuristics.FunctionAnnotator(\"detec_processo\", processo_)\n",
    "detec_data = skweak.heuristics.FunctionAnnotator(\"detec_data\", data_assinatura_)\n",
    "detec_vigencia = skweak.heuristics.FunctionAnnotator(\"detec_vigencia\", vigencia_)\n",
    "detec_valor = skweak.heuristics.FunctionAnnotator(\"detec_valor\", valor_)\n",
    "detec_unidade = skweak.heuristics.FunctionAnnotator(\"detec_unidade\", unidade_orcamento_)\n",
    "detec_programa = skweak.heuristics.FunctionAnnotator(\"detec_programa\", programa_trabalho_)\n",
    "detec_natureza = skweak.heuristics.FunctionAnnotator(\"detec_natureza\", natureza_emepnho_)\n",
    "detec_nota = skweak.heuristics.FunctionAnnotator(\"detec_nota\", nota_empenho_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(detec_contrato.pipe(docs))\n",
    "docs = list(detec_processo.pipe(docs))\n",
    "docs = list(detec_data.pipe(docs))\n",
    "docs = list(detec_vigencia.pipe(docs))\n",
    "docs = list(detec_valor.pipe(docs))\n",
    "docs = list(detec_unidade.pipe(docs))\n",
    "docs = list(detec_programa.pipe(docs))\n",
    "docs = list(detec_natureza.pipe(docs))\n",
    "docs = list(detec_nota.pipe(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">EXTRATO DO CONTRATO No 29/2013, NOS TERMOS DO PADRAO No 09/2012.Processo: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    139.000.604/2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROCESSO</span>\n",
       "</mark>\n",
       ". Partes: DF/RAXI x SUMMIT CONSTRUCOES E TECNOLOGIA LTDA.-EPP, Fundamento Legal: Convite no 028/2013-RA XI. Objeto: Contratacao de Empresa para Execucao de Reforma e Instalacoes Eletrica da Feira Permanente do Cruzeiro, conforme especificacoes tecnicas do convite e proposta que passam a integrar o presente Termo. Valor: O Valor total do Contrato e de R$ \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    145.832,25\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VALOR</span>\n",
       "</mark>\n",
       " (cento e quarenta e cinco mil, oitocentos e trinta e dois reais e vinte e cinco centavos), Dotacao orcamentaria: U.O: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    09113\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UN. ORCAMENTARIA</span>\n",
       "</mark>\n",
       ". Programa de Traba-lho: 15.451.6208.1110.9795 Natureza de Despesa: 449051. Fonte de Recurso: 100. Empenho \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2013NE00430\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOTA EMPENHO</span>\n",
       "</mark>\n",
       ". Vigencia: O presente Termo Aditivo entrara em vigor a partir da data da sua assinatura. Data da assinatura: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    31 de outubro de 2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATA ASSINAT.</span>\n",
       "</mark>\n",
       ". Signatarios: Pelo DF, Antonio Sabino de Vasconcelos Neto, e pela Contratada, Celia Regina Assencio Carvalho. &lt;&gt;END OF BLOCK&lt;&gt;</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# docsAux = list(detec_processo.pipe(docs))\n",
    "skweak.utils.display_entities(docs[0], [\"detec_contrato\", \"detec_processo\", \"detec_valor\", \"detec_data\", \"detec_vigencia\", \"detec_unidade\", \"detec_programa\",\"detec_natureza\",\"detec_nota\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1\n",
      "Finished E-step with 54 documents\n",
      "Starting iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -1973.8169             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished E-step with 54 documents\n",
      "Starting iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       -1966.1279          +7.6891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished E-step with 54 documents\n",
      "Starting iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3       -1964.2490          +1.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished E-step with 54 documents\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         4       -1960.2704          +3.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished E-step with 54 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5       -1955.1972          +5.0732\n"
     ]
    }
   ],
   "source": [
    "model = skweak.aggregation.HMM(\"hmm\", [\"CONTRATO\", \"PROCESSO\", \"DATA ASSINAT.\", \"VIGENCIA\", \"VALOR\", \"UN. ORCAMENTARIA\", \"PROG. TRABALHO\", \"NAT. EMPENHO\", \"NOTA EMPENHO\"])\n",
    "docs = model.fit_and_aggregate(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to ./data/reuters_small.spacy...done\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    doc.ents = doc.spans[\"hmm\"]\n",
    "skweak.utils.docbin_writer(docs, \"./data/reuters_small.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.blank(\"pt\")\n",
    "doc_bin = DocBin().from_disk(\"./data/reuters_small.spacy\")  # your file here\n",
    "examples = []  # examples in Prodigy's format\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    lael_iob = \"\"\n",
    "    for i in range(0, len(doc)):\n",
    "        _label_ = doc[i].ent_iob_\n",
    "        _ent_ = doc[i].ent_type_\n",
    "        if(_label_ != \"O\"):\n",
    "            lael_iob+=f'{_label_}-{_ent_} '\n",
    "        else:\n",
    "            lael_iob+=f'{_label_} '\n",
    "    spans = [{\"start\": ent.start_char, \"end\": ent.end_char, \"label\": ent.label_} for ent in doc.ents]\n",
    "    examples.append({\"text\": doc.text, \"iob\": lael_iob,\"spans\": spans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O O O O O O O O O O O O O B-PROCESSO O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-VALOR O O O O O O O O O O O O O O O O O O O O O O O O O O B-UN. ORCAMENTARIA O O O O O O O O O O O O O O O O O O O B-NOTA EMPENHO O O O O O O O O O O O O O O O O O O O O O O B-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. O O O O O O O O O O O O O O O O O O O O O O O O O O O O '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0][\"iob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'EXTRATO DO CONTRATO No 29/2013, NOS TERMOS DO PADRAO No 09/2012.Processo: 139.000.604/2013. Partes: DF/RAXI x SUMMIT CONSTRUCOES E TECNOLOGIA LTDA.-EPP, Fundamento Legal: Convite no 028/2013-RA XI. Objeto: Contratacao de Empresa para Execucao de Reforma e Instalacoes Eletrica da Feira Permanente do Cruzeiro, conforme especificacoes tecnicas do convite e proposta que passam a integrar o presente Termo. Valor: O Valor total do Contrato e de R$ 145.832,25 (cento e quarenta e cinco mil, oitocentos e trinta e dois reais e vinte e cinco centavos), Dotacao orcamentaria: U.O: 09113. Programa de Traba-lho: 15.451.6208.1110.9795 Natureza de Despesa: 449051. Fonte de Recurso: 100. Empenho 2013NE00430. Vigencia: O presente Termo Aditivo entrara em vigor a partir da data da sua assinatura. Data da assinatura: 31 de outubro de 2013. Signatarios: Pelo DF, Antonio Sabino de Vasconcelos Neto, e pela Contratada, Celia Regina Assencio Carvalho. <>END OF BLOCK<>',\n",
       " 'iob': 'O O O O O O O O O O O O O B-PROCESSO O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-VALOR O O O O O O O O O O O O O O O O O O O O O O O O O O B-UN. ORCAMENTARIA O O O O O O O O O O O O O O O O O O O B-NOTA EMPENHO O O O O O O O O O O O O O O O O O O O O O O B-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. I-DATA ASSINAT. O O O O O O O O O O O O O O O O O O O O O O O O O O O O ',\n",
       " 'spans': [{'start': 74, 'end': 90, 'label': 'PROCESSO'},\n",
       "  {'start': 446, 'end': 456, 'label': 'VALOR'},\n",
       "  {'start': 575, 'end': 580, 'label': 'UN. ORCAMENTARIA'},\n",
       "  {'start': 687, 'end': 698, 'label': 'NOTA EMPENHO'},\n",
       "  {'start': 808, 'end': 829, 'label': 'DATA ASSINAT.'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
