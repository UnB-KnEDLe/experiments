{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    inside = False\n",
    "    start = False\n",
    "    text_lines_mod = []\n",
    "    \n",
    "    text_lines = word_tokenize(text)\n",
    "    \n",
    "    for line in text_lines:\n",
    "        if \"B__B-\" in line:\n",
    "            start = True\n",
    "            inside = True\n",
    "            token = line.split(\"B__B\")[1].split(\"-\")[1]\n",
    "        elif \"E__E-\" in line:\n",
    "            inside = False\n",
    "        else:\n",
    "            if not inside:\n",
    "                line += \" X X O\"\n",
    "            else:\n",
    "                if start:\n",
    "                    line += \" X X B-\" + token\n",
    "                else:\n",
    "                    line += \" X X I-\" + token\n",
    "                start = False\n",
    "\n",
    "            text_lines_mod.append(line)\n",
    "            \n",
    "    return text_lines_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_text_lines(base_df, base_text_df):\n",
    "    marked_texts = []\n",
    "\n",
    "    for arquivo in base_df[\"file_id\"].unique():\n",
    "        entidades_df = base_df[base_df[\"file_id\"] == arquivo].copy().reset_index(drop=True)[[\"val_ent\", \"ner_token\", \"loc_begin\", \"loc_end\", \"file_id\"]]\n",
    "        text = base_text_df[base_text_df[\"file_id\"] == arquivo][\"raw_text\"].iloc[0]\n",
    "\n",
    "        entidades_df = entidades_df.sort_values([\"loc_end\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        for token, begin, end in entidades_df[[\"ner_token\", \"loc_begin\", \"loc_end\"]].itertuples(index=False):\n",
    "            mark_token_begin = \" B__B-\" + token + \"-B__B \"\n",
    "            mark_token_end = \" E__E-\" + token + \"-E__E \"\n",
    "\n",
    "            text = text[:end] + mark_token_end +  text[end:]\n",
    "            text = text[:begin] + mark_token_begin +  text[begin:]\n",
    "\n",
    "        marked_texts.append(text)\n",
    "        \n",
    "    marked_texts_df = pd.DataFrame(pd.Series(marked_texts), columns=[\"marked_text\"])\n",
    "    marked_texts_df[\"file_id\"] = base_df[\"file_id\"].unique()\n",
    "    \n",
    "    #return marked_texts_df\n",
    "\n",
    "    marked_texts_df[\"treated_text\"] = clean_text_dodfs(marked_texts_df[\"marked_text\"])\n",
    "    marked_texts_df[\"treated_text\"] = marked_texts_df.apply(lambda row: clean_text_by_word(row[\"treated_text\"]), axis=1)\n",
    "    \n",
    "    marked_texts_df[\"tokenized_text\"] = marked_texts_df.apply(lambda row: tokenize_text(row[\"treated_text\"]), axis=1)\n",
    "    \n",
    "    return marked_texts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_dodfs(dodfs_texts):\n",
    "\n",
    "    start_page_patterns = [r\"\\nPÁGINA\\s([0-9]{1,5})\", r\"\\nDIÁRIO\\sOFICIAL\\sDO\\sDISTRITO\\sFEDERAL\",\n",
    "                           r\"\\nNº(.+?)2([0-9]{3})\", r\"\\nxx([a-z]{0,10}) Diário Oficial do Distrito Federal xx([a-z]{0,10})\",\n",
    "                           r\"\\nDiário Oficial do Distrito Federal\"]\n",
    "\n",
    "    end_page_patterns = [r\"Documento assinado digitalmente conforme MP nº 2.200-2 de 24/08/2001, que institui a\",\n",
    "                            r\"Infraestrutura de Chaves Públicas Brasileira ICP-Brasil\",\n",
    "                            r\"Este documento pode ser verificado no endereço eletrônico\",\n",
    "                            r\"http://wwwin.gov.br/autenticidade.html\",\n",
    "                            r\"pelo código ([0-9]{15,18})\",\n",
    "                            r\"\\nDocumento assinado digitalmente, original em https://www.dodf.df.gov.br\",\n",
    "                        r\"http:/Awwwin.gov.br/autenticidade.html\",\n",
    "                        r\"Documento assinado digitalmente conforme MP nº 2.200-2 de 24/08/2001,\",\n",
    "                        r\"\\nque institui a\\n\",\n",
    "                        r\"\\nhttp://www.in.gov.br/autenticidade.html\",\n",
    "                        r\"\\nhttp://www.in.gov.brautenticidade html\",\n",
    "                        r\"Documento assinado digitalmente conforme MP n 2.200-2 de 24/08/2001, que institui a .\",\n",
    "                        r\"http://www.in.gov.brautenticidade html,\"]\n",
    "\n",
    "    middle_page_patterns = [r\"xx([a-z]{1,10}) \", r\" xx([a-z]{1,10})\", r\"xx([a-z]{1,10})\"]\n",
    "    \n",
    "    special_middle_page_patterns = [r\"\\n-\\n\", r\"\\n- -\\n\", r\"\\n- - -\\n\", r\"\\n[\\.\\,\\-\\—]\\n\", r\"— -\", r\". -\",\n",
    "                                   r\"\\r[\\.\\,\\-\\—]\\r\", r\"\\n-\\r\", r\"\\r\"]\n",
    "    \n",
    "    start_page_patterns = \"|\".join(start_page_patterns)\n",
    "    middle_page_patterns = \"|\".join(middle_page_patterns)\n",
    "    end_page_patterns = \"|\".join(end_page_patterns)\n",
    "    \n",
    "    page_patterns = [start_page_patterns, middle_page_patterns, end_page_patterns]\n",
    "    page_patterns = \"|\".join(page_patterns)\n",
    "    \n",
    "    return dodfs_texts.str.replace(page_patterns, \"\", regex=True).replace(special_middle_page_patterns, \"\\n\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_by_word(text):\n",
    "    a = \"\\n\".join([l for l in text.split(\"\\n\") if l != \"\"])\n",
    "    words = a.replace(\"\\n\", \" \").split(\" \")\n",
    "    words = [w for w in words if w != \"\"]\n",
    "    \n",
    "    m_words = []\n",
    "    dash_cut = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "\n",
    "        if (word[-1] == \"-\") and (i+1)<len(words):\n",
    "            word = word[:-1] + words[i+1]\n",
    "            i += 1\n",
    "\n",
    "        m_words.append(word)\n",
    "        \n",
    "    return \" \".join(m_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_parse(base_df, func=None):\n",
    "    if func == None:\n",
    "        return base_df\n",
    "    else:\n",
    "        return func(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os tokens com base no título de entidade de cada tipo de ato\n",
    "\n",
    "ner_tokens_extrato_contrato = {\n",
    "    \"Número do ajuste\": \"NUM_AJUSTE\",\n",
    "    \"Órgão contratante\": \"CONTRATANTE\",\n",
    "    \"Entidade contratada\": \"CONTRATADA\",\n",
    "    \"Entidades convenentes\": \"CONVENENTE\",\n",
    "    \"Processo do GDF\": \"PROCESSO\",\n",
    "    \"Objeto do ajuste\": \"OBJ_AJUSTE\",\n",
    "    \"Data de assinatura do ajuste\": \"DATA_ASSINATURA\",\n",
    "    \"Vigência do ajuste\": \"VIGENCIA\",\n",
    "    \"Valor do ajuste\": \"VALOR\",\n",
    "    \"Código da unidade orçamentária\": \"CODIGO_UO\",\n",
    "    \"Programa de trabalho\": \"PT\",\n",
    "    \"Natureza da despesa\": \"ND\",\n",
    "    \"Nota de empenho\": \"NE\",\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação que gerou o contrato\": \"NUM_LICITACAO\",\n",
    "    \"Órgão gerenciador da ata\": \"OG_ATA\",\n",
    "    \"Identificação de dispensa\": \"IDENT_DISPENSA\",\n",
    "    \"Fundamento legal da dispensa ou inexigibilidade\": \"FUND_DISPENSA\"\n",
    "}\n",
    "\n",
    "ner_tokens_aditamento_contratual = {\n",
    "    \"Órgão contratante\": \"CONTRATANTE\",\n",
    "    \"Número do contrato\": \"NUM_CONTRATO\",\n",
    "    \"Número do termo aditivo\": \"NUM_ADITIVO\",\n",
    "    \"Objeto do aditamento contratual\": \"OBJ_ADITIVO\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_licitacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Objeto da licitação\": \"OBJ_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Processo do GDF\": \"PROCESSO\",\n",
    "    \"Valor estimado da contratação\": \"VALOR_ESTIMADO\",\n",
    "    \"Data de abertura da licitação\": \"DATA_ABERTURA\",\n",
    "    \"Sistema de compras utilizado\": \"SISTEMA_COMPRAS\",\n",
    "    \"Código da licitação no sistema de compras utilizado\": \"CODIGO_SISTEMA_COMPRAS\",\n",
    "    \"Tipo de objeto\": \"TIPO_OBJ\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_revogacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Identificação revogação/anulação\": \"IDENT_REVOGACAO_ANULACAO\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_suspensao_licitacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Prazo da suspensão\": \"PRAZO_SUSPENSAO\",\n",
    "    \"Decisão do TCDF que determinou a suspensão\": \"DECISAO_TCDF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df = pd.read_parquet(\"reviewed_entities.parquet\")\n",
    "atos_data_text_df = pd.read_parquet(\"reviewed_acts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserir função de tratamento de dados em specific_parse caso haja (filtragem de tipos de ato, por exemplo)\n",
    "filt_atos_data_df = specific_parse(atos_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df[\"ner_token\"] = \"\"\n",
    "\n",
    "atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"extrato_de_contrato_ou_convenio\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"extrato_de_contrato_ou_convenio\"]), \"title_ent\"].replace(ner_tokens_extrato_contrato)\n",
    "atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_aditamento_contratual\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_aditamento_contratual\"]), \"title_ent\"].replace(ner_tokens_aditamento_contratual)\n",
    "atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_licitacao\"]), \"title_ent\"].replace(ner_tokens_aviso_licitacao)\n",
    "atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_revogacao_anulacao_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_revogacao_anulacao_de_licitacao\"]), \"title_ent\"].replace(ner_tokens_aviso_revogacao)\n",
    "atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_suspensao_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"act_type\"].isin([\"aviso_de_suspensao_de_licitacao\"]), \"title_ent\"].replace(ner_tokens_aviso_suspensao_licitacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokenized_texts = get_tokenized_text_lines(filt_atos_data_df, atos_data_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokenized_texts[\"treated_text\"] = full_tokenized_texts[\"tokenized_text\"].apply(lambda row: \" \".join([w.split()[0] for w in row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
