{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os dados da base ouro já tratados e com o IOB\n",
    "gold_data = pd.read_parquet(\"teste_token.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos dados da base ouro, é necessário excluir entidades que não existem na base REGEX\n",
    "# Também é necessário adequar a nomenclatura das entidades para o que está na base REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_entities_gold = [\"CONTRATANTE\", \"CONTRATADA\", \"CONVENENTE\",\n",
    "                   \"ORGAO_LICITANTE\", \"NUM_LICITACAO\", \"OG_ATA\",\n",
    "                   \"IDENT_DISPENSA\", \"FUND_DISPENSA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_gold_to_regex_iob = {\n",
    "    \"NUM_AJUSTE\": \"CONTRATO\",\n",
    "    \"PROCESSO\": \"PROCESSO\",\n",
    "    \"OBJ_AJUSTE\": \"OBJETO\",\n",
    "    \"DATA_ASSINATURA\": \"DATA_ASS.\",\n",
    "    \"VIGENCIA\": \"VIGENCIA\",\n",
    "    \"VALOR\": \"VALOR\",\n",
    "    \"CODIGO_UO\": \"UNI_ORC.\",\n",
    "    \"PT\": \"PROG_TRAB.\",\n",
    "    \"ND\": \"NAT_DESP.\",\n",
    "    \"NE\": \"NOTA_EMP.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_entities_gold = [\"I-\" + l for l in deleted_entities_gold] + [\"B-\" + l for l in deleted_entities_gold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as entidades que não existem na base REGEX\n",
    "gold_data[\"tokenized_text\"] = gold_data[\"tokenized_text\"].str.join(\"\\n\")\n",
    "\n",
    "for l in deleted_entities_gold:\n",
    "    gold_data[\"tokenized_text\"] = gold_data[\"tokenized_text\"].str.replace(l, \"O\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo a nomenclatura das entidades que existem tanto na base ouro quanto na base REGEX\n",
    "keys_gold_to_regex_iob_adj = dict()\n",
    "\n",
    "for key, value in keys_gold_to_regex_iob.items():\n",
    "    for b in [\"B-\", \"I-\"]:\n",
    "        gold_data[\"tokenized_text\"] = gold_data[\"tokenized_text\"].str.replace(b+key, b+value, regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando ao formato original\n",
    "gold_data[\"tokenized_text\"] = gold_data[\"tokenized_text\"].str.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na base REGEX, é preciso deixar no formato IOB1, com labels e text juntos\n",
    "# Tambémé preciso excluir as entidades que não existem na base ouro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os dados da base REGEX já tratados\n",
    "regex_data = pd.read_csv(\"/home/ciri/Desktop/sofia/unb/knedle/vitor2/contratosFINAL.csv\")\n",
    "regex_data = regex_data.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data = regex_data[[\"text\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (regex_data[\"text\"].str.split().str.len() == regex_data[\"labels\"].str.split().str.len()).all(), \"Labels e text não batem na tokenização.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data[\"text\"] = regex_data[\"text\"].str.split()\n",
    "regex_data[\"labels\"] = regex_data[\"labels\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_word(text, labels):\n",
    "    labeled_text = []\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        labeled_text.append(text[i] + \" X X \" + labels[i])\n",
    "    \n",
    "    return labeled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data[\"tokenized_text\"] = regex_data.apply(lambda row: label_word(row[\"text\"], row[\"labels\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_entities_regex = [\"PARTES\", \"SIGNATARIOS\", \"LEI_ORC.\"]\n",
    "deleted_entities_regex = [\"I-\" + l for l in deleted_entities_regex] + [\"B-\" + l for l in deleted_entities_regex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as entidades que não existem na base REGEX\n",
    "regex_data[\"tokenized_text\"] = regex_data[\"tokenized_text\"].str.join(\"\\n\")\n",
    "\n",
    "for l in deleted_entities_regex:\n",
    "    regex_data[\"tokenized_text\"] = regex_data[\"tokenized_text\"].str.replace(l, \"O\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data[\"tokenized_text\"] = regex_data[\"tokenized_text\"].str.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrever os .txt com os dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o treinamento, pegar apenas dados da base REGEX com menos de 1000 caraceteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data_mod = regex_data[regex_data[\"text\"].str.join(\" \").str.len() <= 1000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data_mod[\"treated_text\"] = regex_data_mod[\"text\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_data_mod[\"base\"] = \"regex\"\n",
    "gold_data[\"base\"] = \"gold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([regex_data_mod[[\"treated_text\", \"tokenized_text\", \"base\"]], gold_data[[\"treated_text\", \"tokenized_text\", \"base\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar dados para separar amostras de teste, validação e treinamento para os códigos da Manuela\n",
    "full_data.to_parquet(\"full_data.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar dados no formato para rodar nos códigos do José Reinaldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \"\\n\\n\".join(list(regex_data_mod[\"tokenized_text\"].str.join(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa_set = gold_data.sample(frac=0.5)\n",
    "testb_set = gold_data[~gold_data.index.isin(testa_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa_set = \"\\n\\n\".join(list(testa_set[\"tokenized_text\"].str.join(\"\\n\")))\n",
    "testb_set = \"\\n\\n\".join(list(testb_set[\"tokenized_text\"].str.join(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(\"regex_train.txt\", \"w\")\n",
    "train_file.write(train_set)\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa_file = open(\"regex_testa.txt\", \"w\")\n",
    "testa_file.write(testa_set)\n",
    "testa_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testb_file = open(\"regex_testb.txt\", \"w\")\n",
    "testb_file.write(testb_set)\n",
    "testb_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
