{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import unidecode as uni\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 120 ms, total: 1.29 s\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>text</th>\n",
       "      <th>ents</th>\n",
       "      <th>qtd_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144.846329</td>\n",
       "      <td>190.436508</td>\n",
       "      <td>659.465149</td>\n",
       "      <td>208.861298</td>\n",
       "      <td>ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.702831</td>\n",
       "      <td>353.227753</td>\n",
       "      <td>344.850311</td>\n",
       "      <td>370.024231</td>\n",
       "      <td>Secretaria de Estado de Trabalho, Desenvolvime...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0           x          y0          y1  \\\n",
       "0  144.846329  190.436508  659.465149  208.861298   \n",
       "1   56.702831  353.227753  344.850311  370.024231   \n",
       "\n",
       "                                                text ents  qtd_ents  \n",
       "0  ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...   []         0  \n",
       "1  Secretaria de Estado de Trabalho, Desenvolvime...   []         0  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_origin = pd.read_csv(\n",
    "    '../aposentadoria-ouro-comparacao/blocos_com_entides.csv',\n",
    "    index_col=False\n",
    ")\n",
    "tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 124 ms, total: 30.2 s\n",
      "Wall time: 30.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ents</th>\n",
       "      <th>qtd_ents</th>\n",
       "      <th>sentencas</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secretaria de Estado de Trabalho, Desenvolvime...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Secretaria de Estado de Trabalho, Desenvolvime...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secretaria de Estado de Trabalho, Desenvolvime...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4 16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text ents  qtd_ents  \\\n",
       "0  ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...   []         0   \n",
       "1  Secretaria de Estado de Trabalho, Desenvolvime...   []         0   \n",
       "1  Secretaria de Estado de Trabalho, Desenvolvime...   []         0   \n",
       "\n",
       "                                           sentencas      y  \n",
       "0  ANO XLVII EDICAO No- 248\\nBRASILIA - DF, TERCA...  False  \n",
       "1  Secretaria de Estado de Trabalho, Desenvolvime...  False  \n",
       "1                                               4 16  False  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_work = df_origin.copy()\n",
    "df_work.drop(df_origin.columns[:4], axis=1, inplace=True)\n",
    "# df_work['ents'] = df_work.ents.map(eval)\n",
    "df_work['sentencas'] = df_work.text.map(tokenizer.sentences_from_text) \n",
    "df_work = df_work.explode('sentencas')\n",
    "df_work['y'] = df_work.qtd_ents > 0\n",
    "df_work.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 ms, sys: 20 µs, total: 1.04 ms\n",
      "Wall time: 678 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "tfidf_param = {\n",
    "    'lowercase': False,\n",
    "    'preprocessor': uni.unidecode_expect_ascii,\n",
    "    'stop_words': stop_words, \n",
    "}\n",
    "xgb_param = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 2,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leomaffei/.pyenv/versions/3.8.1/envs/pesquisa-unb/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/leomaffei/.pyenv/versions/3.8.1/envs/pesquisa-unb/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/leomaffei/.pyenv/versions/3.8.1/envs/pesquisa-unb/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/leomaffei/.pyenv/versions/3.8.1/envs/pesquisa-unb/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/leomaffei/.pyenv/versions/3.8.1/envs/pesquisa-unb/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 10s, sys: 24.8 s, total: 37min 34s\n",
      "Wall time: 37min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = {\n",
    "    'acc':[],\n",
    "    'acc_bal': [],\n",
    "    'f1': [],\n",
    "    'prfs': [],\n",
    "    'test_index': [],\n",
    "}\n",
    "pipes = []\n",
    "df = df_work[df_work.sentencas.str.len() > 40].reset_index()\n",
    "\n",
    "for train_index, test_index in skf.split(df.text, df.y):\n",
    "    pipe = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer(**tfidf_param)),\n",
    "        ('clf', xgb.XGBClassifier(**xgb_param))\n",
    "    ])\n",
    "    x_train, x_test = df.sentencas[train_index], df.sentencas[test_index]\n",
    "    y_train, y_test = df.y[train_index], df.y[test_index]\n",
    "    \n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "\n",
    "    scores['acc'].append(accuracy_score(y_test, y_pred))\n",
    "    scores['f1'].append(f1_score(y_test, y_pred))\n",
    "    scores['prfs'].append(precision_recall_fscore_support(y_test, y_pred))\n",
    "    scores['acc_bal'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "    scores['test_index'].append(test_index)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.9983176117047815,\n",
       "  0.9970645224917911,\n",
       "  0.9974125728076486,\n",
       "  0.9977142459332142,\n",
       "  0.9979579049961711],\n",
       " 'acc_bal': [0.9653508271642778,\n",
       "  0.949088844132919,\n",
       "  0.948501233008125,\n",
       "  0.9512000617813099,\n",
       "  0.9528131141254352],\n",
       " 'f1': [0.9456317960254969,\n",
       "  0.9059129788025287,\n",
       "  0.9159442140972484,\n",
       "  0.9254070427868232,\n",
       "  0.9330798479087453],\n",
       " 'prfs': [(array([0.99890426, 0.96039604]),\n",
       "   array([0.99938703, 0.93131462]),\n",
       "   array([0.99914559, 0.9456318 ]),\n",
       "   array([84833,  1354])),\n",
       "  (array([0.99839721, 0.91235955]),\n",
       "   array([0.99862082, 0.89955687]),\n",
       "   array([0.998509  , 0.90591298]),\n",
       "   array([84833,  1354])),\n",
       "  (array([0.99837429, 0.93461538]),\n",
       "   array([0.99899803, 0.89800443]),\n",
       "   array([0.99868606, 0.91594421]),\n",
       "   array([84833,  1353])),\n",
       "  (array([0.99845697, 0.94875776]),\n",
       "   array([0.999222  , 0.90317812]),\n",
       "   array([0.99883934, 0.92540704]),\n",
       "   array([84833,  1353])),\n",
       "  (array([0.9985043 , 0.96159875]),\n",
       "   array([0.99942239, 0.90620384]),\n",
       "   array([0.99896313, 0.93307985]),\n",
       "   array([84832,  1354]))],\n",
       " 'test_index': [array([    0,     1,     2, ..., 86184, 86185, 86186]),\n",
       "  array([ 86187,  86188,  86189, ..., 172508, 172509, 172510]),\n",
       "  array([170231, 170232, 170233, ..., 259206, 259207, 259208]),\n",
       "  array([232077, 232078, 232079, ..., 345056, 345057, 345058]),\n",
       "  array([323243, 323244, 323245, ..., 430929, 430930, 430931])]}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
