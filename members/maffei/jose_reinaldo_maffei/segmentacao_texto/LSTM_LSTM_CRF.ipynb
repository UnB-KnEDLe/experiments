{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "LSTM_LSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u87-rtKYhaJh",
        "outputId": "eb129ec7-8ae4-44d9-fe5f-4031ea339dfd"
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AjVPbl6ZJmN",
        "outputId": "9a19a140-8421-4cd8-d8c7-9683c86910fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRmUduDz95Z1"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gensim.models import KeyedVectors\n",
        "from torchcrf import CRF\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "import unicodedata\n",
        "from math import floor\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "PRF = Path('drive/MyDrive/knedle-data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_kmkctAh7hT"
      },
      "source": [
        "# !unzip drive/MyDrive/knedle-data/segmentation_aposentadoria.zip -d drive/MyDrive/knedle-data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTnpbdHN95aE"
      },
      "source": [
        "# Parte 1 - Criando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hmb9mcEk95aJ"
      },
      "source": [
        "emb = KeyedVectors.load_word2vec_format(\"drive/MyDrive/knedle-data/cbow_s50.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvYoDpNZ95aF"
      },
      "source": [
        "class segmentation_dataset(Dataset):\n",
        "    def __init__(self, tag2idx, word2idx, set_type, path='seg_data.txt'):\n",
        "        \"\"\"\n",
        "        Load the segmentation dataset, (self.__load__())\n",
        "        Truncate long sentences/split long blocks/ignore very short blocks (self.__trunc__())\n",
        "        get indices of words and tags (self.__get_idx__())\n",
        "        PAD the sentences and blocks/create MASKS representing padded elements (self.__pad__())\n",
        "        \"\"\"\n",
        "        self.set_type = set_type\n",
        "        self.min_block_length = 3\n",
        "        self.max_sentence_length = 30\n",
        "        self.max_block_length = 20\n",
        "        self.path = path\n",
        "\n",
        "        self.__load__()\n",
        "        self.__trunc__()\n",
        "        self.__split__()\n",
        "        self.__get_idx__(tag2idx, word2idx)\n",
        "        self.__pad__()\n",
        "        \n",
        "        self.x = torch.LongTensor(self.x)\n",
        "        self.y = torch.LongTensor(self.y)\n",
        "        self.mask = torch.ByteTensor(self.mask)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Get one item from the dataset\n",
        "        \"\"\"\n",
        "        return self.x[index], self.mask[index], self.y[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __load__(self):\n",
        "        \"\"\"\n",
        "        Load raw dataset from `self.path`\n",
        "        \"\"\"\n",
        "        data = open(self.path, 'r').read().splitlines()\n",
        "        x, y, temp_x, temp_y = [], [], [], []\n",
        "        for line in data:\n",
        "            if not line:\n",
        "                if len(temp_x)>0:\n",
        "                    x.append(temp_x)\n",
        "                    y.append(temp_y)\n",
        "                temp_x, temp_y = [], []\n",
        "            else:\n",
        "                if len(line.split())>=2:\n",
        "                    temp_x.append(line[1:].split())\n",
        "                    temp_y.append(line[0])\n",
        "        if temp_x:\n",
        "            x.append(temp_x)\n",
        "            y.append(temp_y)\n",
        "        \n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        \n",
        "    def __trunc__(self):\n",
        "        \"\"\"\n",
        "        Truncate sentences with length > max_sentence_length\n",
        "        Separate blocks with length > max_block_length\n",
        "        Delete blocks with length < min_block_length\n",
        "        \"\"\"\n",
        "        # For each block in x\n",
        "        # for i in range(len(self.x)):\n",
        "        for i, x_i in enumerate(self.x):\n",
        "            # For each sentence in x[i]\n",
        "            for j, x_ij in enumerate(x_i):\n",
        "            # for j in range(len(self.x[i])):\n",
        "                if len(x_ij) > self.max_sentence_length:\n",
        "                # if len(self.x[i][j]) > self.max_sentence_length:\n",
        "                    self.x[i][j] = x_ij[:self.max_sentence_length]\n",
        "\n",
        "        sep_x = []\n",
        "        sep_y = []\n",
        "        # for i in range(len(self.x)):\n",
        "        maxbl = self.max_block_length\n",
        "        for i, x_i in enumerate(self.x):\n",
        "            # if len(self.x[i]) > self.max_block_length:\n",
        "            if len(x_i) > maxbl:\n",
        "                for j in range( (len(x_i) // maxbl) +1):\n",
        "                # for j in range( (len(x_i) // self.max_block_length) +1):\n",
        "                    # if self.x[i][j*self.max_block_length:(j+1)*self.max_block_length]:# and 'B' in self.y[i]:\n",
        "                    # if x_i[j*self.max_block_length:(j+1)*self.max_block_length]:# and 'B' in self.y[i]:\n",
        "                    if x_i[ j * maxbl : (j+1) * maxbl]:# and 'B' in self.y[i]:\n",
        "                        # sep_x.append(self.x[i][j*self.max_block_length:(j+1)*self.max_block_length])\n",
        "                        sep_x.append(x_i[j * maxbl : (j+1) * maxbl])\n",
        "                        # sep_y.append(self.y[i][j*self.max_block_length:(j+1)*self.max_block_length])\n",
        "                        sep_y.append(self.y[i][j * maxbl : (j+1) * maxbl])\n",
        "            elif len(x_i) < self.min_block_length:\n",
        "            # elif len(self.x[i]) < self.min_block_length:\n",
        "                continue\n",
        "#             elif 'B' in self.y[i]:\n",
        "            else:\n",
        "                # sep_x.append(self.x[i])\n",
        "                sep_x.append(x_i)\n",
        "                sep_y.append(self.y[i])\n",
        "        self.x = sep_x\n",
        "        self.y = sep_y\n",
        "        \n",
        "    def __split__(self):\n",
        "        train_split = floor(0.6*len(self.x))\n",
        "        valid_split = floor(0.1*len(self.x)) + train_split \n",
        "        if self.set_type == 'train':\n",
        "            print(\"Treinamento\")\n",
        "            self.x = self.x[:train_split]\n",
        "            self.y = self.y[:train_split]\n",
        "        elif self.set_type == 'valid':\n",
        "            print(\"validacao\")\n",
        "            self.x = self.x[train_split:valid_split]\n",
        "            self.y = self.y[train_split:valid_split]\n",
        "        else:\n",
        "            print(\"teste\")\n",
        "            self.x = self.x[valid_split:]\n",
        "            self.y = self.y[valid_split:]\n",
        "        \n",
        "    def __get_idx__(self, tag2idx, word2idx):\n",
        "        \"\"\"\n",
        "        Convert words (x) into indices for the embedding layer\n",
        "        PADs sentences to self.max_sentence_length\n",
        "        Convert tags (y) into indices \n",
        "        \"\"\"\n",
        "        # get_idx of x\n",
        "        for i in range(len(self.x)):\n",
        "            for j in range(len(self.x[i])):\n",
        "                for k in range(len(self.x[i][j])):\n",
        "                    w = self.x[i][j][k].replace(',', '').replace(';', '').replace(':', '').lower()\n",
        "                    if w in word2idx:\n",
        "                        self.x[i][j][k] = word2idx[w]\n",
        "                    else:\n",
        "                        self.x[i][j][k] = 0\n",
        "                while(len(self.x[i][j]) < self.max_sentence_length):\n",
        "                    self.x[i][j].append(0)\n",
        "                \n",
        "        # get_idx of y      \n",
        "        for i in range(len(self.y)):\n",
        "            for j in range(len(self.y[i])):\n",
        "                self.y[i][j] = tag2idx[self.y[i][j]]\n",
        "                \n",
        "    def __pad__(self):\n",
        "        \"\"\"\n",
        "        Pad blocks of sentences to self.max_block_length\n",
        "        Creates MASKS to indicate padded sentences in each block\n",
        "        \"\"\"\n",
        "        self.mask = []\n",
        "        sent_padder = [0 for i in range(self.max_sentence_length)]\n",
        "        for i in range(len(self.x)):\n",
        "            temp_mask = [0 for i in range(self.max_block_length)]\n",
        "            for j in range(len(self.x[i])):\n",
        "                temp_mask[j] = 1\n",
        "            self.mask.append(temp_mask)\n",
        "            while len(self.x[i]) < self.max_block_length:\n",
        "                self.x[i].append(sent_padder)\n",
        "                self.y[i].append(-1)\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_7t-kbafz_",
        "outputId": "6e89bcb0-0fd3-4c57-b219-af8431d12f64"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "dic = {}\n",
        "for j in emb.wv.index2word:\n",
        "    num = emb.vocab[j].index\n",
        "    word = unicodedata.normalize('NFKD', j).encode('ascii', 'ignore').decode('utf8')\n",
        "    dic[word] = emb.vocab[j].index\n",
        "print(len(dic))\n",
        "\n",
        "dic_tag = {'B': 0, 'I': 1, 'O': 2}\n",
        "idx2tag = {0: 'B', 1:'I', 2:'O'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "866822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuCK_7bF1qpl",
        "outputId": "5f3c6506-2464-4571-d793-14bccff48704"
      },
      "source": [
        "!ls drive/MyDrive/knedle-data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cbow_s50.txt  seg_data.txt\t\t      seg_model_256_50dim_adam\n",
            "cbow_s50.zip  segmentation_aposentadoria.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PflEO8AC95aN",
        "outputId": "ae9dbbbc-96c7-4750-bcb0-268ab5b1c2f4"
      },
      "source": [
        "seg_path = 'drive/MyDrive/knedle-data/seg_data.txt'\n",
        "train_dataset = segmentation_dataset(\n",
        "    tag2idx=dic_tag,\n",
        "    word2idx=dic, \n",
        "    set_type='train', path=seg_path,)\n",
        "valid_dataset = segmentation_dataset(\n",
        "    tag2idx=dic_tag, \n",
        "    word2idx=dic, \n",
        "    set_type='valid', path=seg_path,)\n",
        "test_dataset = segmentation_dataset(\n",
        "    tag2idx=dic_tag, \n",
        "    word2idx=dic, \n",
        "    set_type='test', path=seg_path,)\n",
        "len(train_dataset.x), len(valid_dataset.x), len(test_dataset.x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinamento\n",
            "validacao\n",
            "teste\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81132, 13522, 40566)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vywbWn695aO",
        "outputId": "f9b91bd7-23bf-4864-b3c7-1a16de7b78f7"
      },
      "source": [
        "print(\"Numero de classes por conjunto de dados (treinamento, validacao e teste)\")\n",
        "\n",
        "# tags = {'B':0, 'I':0, 'O':0}\n",
        "tags = [0, 0, 0]\n",
        "for block in train_dataset.y:\n",
        "    for tag in block:\n",
        "        tags[tag] += 1\n",
        "print(\"Conjunto de treinamento:\", tags)\n",
        "\n",
        "# tags = {'B':0, 'I':0, 'O':0}\n",
        "tags = [0, 0, 0]\n",
        "for block in valid_dataset.y:\n",
        "    for tag in block:\n",
        "        tags[tag] += 1\n",
        "print(\"Conjunto de validacao:\", tags)\n",
        "\n",
        "# tags = {'B':0, 'I':0, 'O':0}\n",
        "tags = [0, 0, 0]\n",
        "for block in test_dataset.y:\n",
        "    for tag in block:\n",
        "        tags[tag] += 1\n",
        "print(\"Conjunto de teste:\", tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de classes por conjunto de dados (treinamento, validacao e teste)\n",
            "Conjunto de treinamento: [3613, 10768, 1608259]\n",
            "Conjunto de validacao: [518, 1464, 268458]\n",
            "Conjunto de teste: [1251, 3875, 806194]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG0CaNhs95aP"
      },
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size=32, \n",
        "    shuffle=False, \n",
        "    num_workers=2, \n",
        "    pin_memory=True)\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset = valid_dataset, \n",
        "    batch_size=32, \n",
        "    shuffle=False, \n",
        "    num_workers=2, \n",
        "    pin_memory=True)\n",
        "test_dataloader  = DataLoader(\n",
        "    dataset = test_dataset , \n",
        "    batch_size=32, \n",
        "    shuffle=False, \n",
        "    num_workers=2, \n",
        "    pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdwEEqWD95aQ"
      },
      "source": [
        "# Parte 2 - Criando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91KCrIr95aQ"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import json\n",
        "\n",
        "def devicefy(lis, device):\n",
        "  return [i.to(device) for i in lis]\n",
        "\n",
        "DUMP_PATH = PRF / \"seg_model_256_50dim_adam\"\n",
        "\n",
        "class LSTM_CRF(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_tags, hidden_dim, \n",
        "                 pretrained_emb, idx2tag, dump_path):\n",
        "        super(LSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_tags = num_tags\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embed_layer       = nn.Embedding.from_pretrained(\n",
        "            torch.FloatTensor(pretrained_emb.vectors)\n",
        "            # torch.FloatTensor(pretrained_emb)\n",
        "        )\n",
        "\n",
        "        self.idx2tag_dict = idx2tag\n",
        "        self.dump_path = dump_path\n",
        "\n",
        "\n",
        "        # Defining all the nn layers\n",
        "        \n",
        "        # Bias\n",
        "        self.embed_layer.weight[0] = 0\n",
        "        \n",
        "        self.word_LSTM_layer   = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, num_layers=1, batch_first=True\n",
        "        )\n",
        "        self.sent_LSTM_layer   = nn.LSTM(\n",
        "            hidden_dim, hidden_dim // 4, num_layers=1, batch_first=True\n",
        "        )\n",
        "        self.linear_layer      = nn.Linear(hidden_dim//4, num_tags)\n",
        "        self.crf_layer         = CRF(num_tags, batch_first=True)\n",
        "\n",
        "        # Set device for training\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, batch_input, batch_tags):\n",
        "        \"\"\"\n",
        "        Method to compute the forward pass of the LSTM_CRF model\n",
        "        Input: (x) shape:        (batch_size) x (sequence_length) x (sentence_length)\n",
        "               (y) shape:        (batch_size) x (sequence_length)\n",
        "        output: log_likelihood  of the probability of the expected sequence of tags\n",
        "        \"\"\"\n",
        "        batch_size = batch_input.shape[0]\n",
        "        sequence_pad_size = batch_input.shape[1]\n",
        "        sentence_pad_size = batch_input.shape[2]\n",
        "        \n",
        "        # Embedding Layer\n",
        "        emb_out = self.embed_layer(batch_input)\n",
        "        # Word level LSTM layer\n",
        "        word_lstm_out, (hn, cn) = self.word_LSTM_layer(\n",
        "            emb_out.view(\n",
        "                batch_size*sequence_pad_size, \n",
        "                sentence_pad_size, \n",
        "                self.embedding_dim\n",
        "            )\n",
        "        )\n",
        "        # Sentence level LSTM layer\n",
        "        sent_lstm_out, (hn, cn) = self.sent_LSTM_layer(\n",
        "            hn.view(\n",
        "                batch_size,\n",
        "                sequence_pad_size,\n",
        "                self.hidden_dim\n",
        "            )\n",
        "        )\n",
        "        # Linear (fully-connected) layer\n",
        "        lin_out = self.linear_layer(\n",
        "            sent_lstm_out.reshape(\n",
        "                batch_size * sequence_pad_size,\n",
        "                self.hidden_dim//4\n",
        "            )\n",
        "        )\n",
        "        # CRF layer\n",
        "        return self.crf_layer(\n",
        "            lin_out.view(\n",
        "                batch_size,\n",
        "                sequence_pad_size,\n",
        "                self.num_tags),\n",
        "            batch_tags\n",
        "        )\n",
        "\n",
        "    def fit(self, epoch, train_loader, eval_loader, **kwargs):\n",
        "        \"\"\"\n",
        "        Method to train the LSTM_CRF model\n",
        "        Input: \n",
        "          (x) shape:\n",
        "            (number of batches) x (batch_size) x (sequence_length) x (sentence_length)\n",
        "          (y) shape:\n",
        "            (number of batches) x (batch_size) x (sequence_length)\n",
        "        \n",
        "        output: validation_loss (validation loss over all epochs)\n",
        "        \"\"\"\n",
        "        learning_rate = kwargs.get('lr', 0.01)\n",
        "        wd = kwargs.get('weight_decay', 1e-4)\n",
        "            \n",
        "        validation_loss = []\n",
        "        min_loss = float('inf')\n",
        "#         optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate, weight_decay=wd)\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate, weight_decay=wd)\n",
        "        # TODO: mostrar a duração de tempo de cada época ( time.time() )\n",
        "        \n",
        "        best_params = self.state_dict()\n",
        "        for e in range(epoch):\n",
        "            print(\"Epoch:\", e, '...')\n",
        "            # for batch in tqdm(train_loader):\n",
        "            for i, batch in enumerate(train_loader):\n",
        "                x, mask, y = devicefy(batch, self.device)\n",
        "                # Zerar gradiente antes de usar a rede\n",
        "                self.zero_grad()\n",
        "                                                \n",
        "                loss = -self(x, y,)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "            new_loss = self.evaluate(eval_loader, opt='loss')\n",
        "            \n",
        "            validation_loss.append(new_loss)\n",
        "            if new_loss < min_loss:\n",
        "              st_dict = self.state_dict()\n",
        "              if str(best_params) == str(st_dict):\n",
        "                raise ValueError(\"UUPS!\")\n",
        "              min_loss = new_loss\n",
        "              best_params = self.state_dict()\n",
        "                \n",
        "        torch.save(best_params , self.dump_path)\n",
        "        return validation_loss\n",
        "    \n",
        "            \n",
        "    def predict(self, batch_input, mask):\n",
        "        \"\"\"\n",
        "        Method to predict segmentation tags\n",
        "        Input: sequence - shape:(batch_size)x(sequence_size)x(sentence_size)\n",
        "        output: Predicted tags - shape: (batch_size)x(sequence_size)\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            batch_size, sequence_pad_size, sentence_pad_size = batch_input.shape\n",
        "\n",
        "            # Embedding Layer\n",
        "            emb_out = self.embed_layer(batch_input)\n",
        "            # Word level LSTM layer\n",
        "            word_lstm_out, (hn, cn) = self.word_LSTM_layer(\n",
        "                emb_out.view(\n",
        "                    batch_size*sequence_pad_size,\n",
        "                    sentence_pad_size,\n",
        "                    self.embedding_dim\n",
        "                )\n",
        "            )\n",
        "            # Sentence level LSTM layer\n",
        "            sent_lstm_out, (hn, cn) = self.sent_LSTM_layer(\n",
        "                hn.view(\n",
        "                    batch_size, \n",
        "                    sequence_pad_size, \n",
        "                    self.hidden_dim\n",
        "                )\n",
        "            )\n",
        "            # Linear (fully-connected) layer\n",
        "            lin_out = self.linear_layer(\n",
        "                sent_lstm_out.reshape(\n",
        "                    batch_size * sequence_pad_size,\n",
        "                    self.hidden_dim // 4\n",
        "                )\n",
        "            )\n",
        "            # CRF layer\n",
        "            return self.crf_layer.decode(\n",
        "                lin_out.view(\n",
        "                    batch_size, sequence_pad_size, self.num_tags\n",
        "                ),\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "    def evaluate(self, valid_loader, opt):\n",
        "        \"\"\"\n",
        "        Method to evaluate trained model on unseen data\n",
        "        \"\"\"\n",
        "        print(\"whoami? \", type(self))\n",
        "        if opt == 'loss':\n",
        "            with torch.no_grad():\n",
        "                loss = 0\n",
        "                for batch in valid_loader:\n",
        "                    x, mask, y = devicefy(batch, self.device)                    \n",
        "                    loss -= self(x, y, )\n",
        "                return loss\n",
        "        \n",
        "        elif opt == 'f1':\n",
        "            TP, FP, FN = np.zeros((3, 3), int)\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(valid_loader):\n",
        "                    x, mask, y = devicefy(batch, self.device, )\n",
        "\n",
        "                    pred = self.predict(x, mask)\n",
        "                    for i, p_i in enumerate(pred):\n",
        "                        for j, p_ij in enumerate(pred[i]):\n",
        "                            if y[i][j] == -1:\n",
        "                                break\n",
        "                            if p_ij == y[i][j]:\n",
        "                                TP[p_ij] += 1\n",
        "                            else:\n",
        "                                FP[p_ij] += 1\n",
        "                                FN[y[i][j]] += 1\n",
        "\n",
        "            recall = TP/(TP+FN)\n",
        "            precision = TP/(TP+FP)\n",
        "            f1_score = 2*(recall*precision)/(recall+precision)\n",
        "            print(tabulate([\n",
        "                ['Recall', recall[0], recall[1], recall[2]], \n",
        "                ['Precision', precision[0], precision[1], precision[2]], \n",
        "                ['F1 score', f1_score[0], f1_score[1], f1_score[2]]\n",
        "                ], \n",
        "                headers=['', self.idx2tag_dict[0], self.idx2tag_dict[1], self.idx2tag_dict[2]]\n",
        "            ))\n",
        "            return recall, precision, f1_score\n",
        "        \n",
        "        else:\n",
        "            print(\"Chosen opt doesn't exist\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIkm1jC95aW"
      },
      "source": [
        "model_maffei = LSTM_CRF(\n",
        "    embedding_dim=50,\n",
        "    num_tags=3,\n",
        "    hidden_dim=256,\n",
        "    pretrained_emb=emb, \n",
        "    idx2tag=idx2tag,\n",
        "    dump_path=DUMP_PATH,\n",
        ")\n",
        "\n",
        "\n",
        "model_maffei = model_maffei.to(model_maffei.device)\n",
        "\n",
        "# model_maffei.evaluate = model_jose.evaluate\n",
        "# model = model.to(model.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb_yRHMoM-dR",
        "outputId": "7f5a04af-f416-4299-fc6c-ab12d5f6b041"
      },
      "source": [
        "# model_jose.evaluate(test_dataloader, opt='f1')\n",
        "print(\"Test set loss:\", model_maffei.evaluate(test_dataloader, opt='loss'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "whoami?  <class '__main__.LSTM_CRF'>\n",
            "Test set loss: tensor(879064.0625, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTRbhSKC95aZ"
      },
      "source": [
        "# Parte 3 - Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYfLQ1QU95aZ"
      },
      "source": [
        "# print(torch.cuda.memory_allocated())\n",
        "# print(torch.cuda.memory_reserved())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "IWNjSpDT95aa",
        "outputId": "ddd6be73-75ed-4c33-d87a-41dbdbc3c94e"
      },
      "source": [
        "valid_loss = model_maffei.fit(\n",
        "    epoch=2, \n",
        "    train_loader = train_dataloader, \n",
        "    eval_loader = valid_dataloader, \n",
        "    lr=0.001, \n",
        "    weight_decay=1e-6,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 ...\n",
            "whoami?  <class '__main__.LSTM_CRF'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-43f900b24bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0meval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-36-d9b784ec1f7e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epoch, train_loader, eval_loader, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m               \u001b[0mst_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UUPS!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m               \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m               \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: UUPS!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rHFPQz9c95ab",
        "outputId": "0d45c3d6-413c-4fab-9122-122d64954afc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(valid_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbe7b3d5850>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKV0ZzVy95ac"
      },
      "source": [
        "# Parte 4 - Avaliacao do modelo no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtrHgXUJ95ac"
      },
      "source": [
        "# model.load_state_dict(torch.load(DUMP_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwdMqJnS95ad",
        "outputId": "cc659e82-3d5d-4162-8934-3b87d77ce2af"
      },
      "source": [
        "# model_jose.evaluate(test_dataloader, opt='f1')\n",
        "print(\"Test set loss:\", model_maffei.evaluate(test_dataloader, opt='loss'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WHOAM I <class '__main__.LSTM_CRF'>\n",
            "Test set loss: tensor(6079.5044, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMSfpd_r95ae"
      },
      "source": [
        "# Parte 5 - Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN5S3X1_95af"
      },
      "source": [
        "# To save trained pytorch model\n",
        "# torch.save(model.state_dict(), \"seg_model_256\")\n",
        "\n",
        "# # To load trained pytorch model\n",
        "# loaded_model = LSTM_CRF(embedding_dim=100, word2idx_dict=dic, num_tags=3, hidden_dim=128)\n",
        "# new_model.load_state_dict(torch.load(\"seg_model\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}