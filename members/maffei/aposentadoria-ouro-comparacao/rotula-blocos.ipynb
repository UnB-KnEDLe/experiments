{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ipykernel\n",
    "import re\n",
    "from notebook.notebookapp import list_running_servers\n",
    "from notebook import notebookapp\n",
    "\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "\n",
    "TOKEN = servers[0]['token']\n",
    "\n",
    "base_url = next(list_running_servers())['url']\n",
    "r = requests.get(\n",
    "    url=base_url + 'api/sessions',\n",
    "    headers={'Authorization': 'token {}'.format(TOKEN),})\n",
    "\n",
    "r.raise_for_status()\n",
    "response = r.json()\n",
    "\n",
    "kernel_id = re.search(\n",
    "    'kernel-(.*).json',\n",
    "    ipykernel.connect.get_connection_file()\n",
    ").group(1)\n",
    "\n",
    "NOTEBOOK_PATH = {\n",
    "    r['kernel']['id']: r['notebook']['path']\n",
    "    for r in response\n",
    "}[kernel_id]\n",
    "# print(NOTEBOOK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 ms, sys: 0 ns, total: 2.53 ms\n",
      "Wall time: 1.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fitz\n",
    "from dodfminer.extract.polished.acts.aposentadoria import Retirements\n",
    "import unidecode\n",
    "from utils import get_dodf_key\n",
    "\n",
    "METRICS = [\n",
    "    'f1_macro',\n",
    "    'f1_micro',\n",
    "    'f1_weighted',\n",
    "    'accuracy',\n",
    "    'balanced_accuracy'\n",
    "]\n",
    "PATH_PREDICT = 'marked_pdf/predict/'\n",
    "PATH_REGEX = 'marked_pdf/regex/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_blocks(doc):\n",
    "    lis = []\n",
    "    for idx, page in enumerate(doc, start=1):\n",
    "        bls = page.getTextBlocks()\n",
    "        bls = [(*i, idx) for i in bls]\n",
    "        lis.extend(bls)\n",
    "    return lis\n",
    "\n",
    "def get_dodfs_path():\n",
    "    return glob.glob('data/aposentadoria-ouro/pdfs/*.pdf')\n",
    "\n",
    "def wRetirements(s):\n",
    "    return Retirements(None, 'regex',\n",
    "                       txt= unidecode.unidecode_expect_ascii(s))\n",
    "\n",
    "INDEX_COL = ['data', 'num', 'tipo']\n",
    "NUM_FILES = 3\n",
    "NUM_FILES = len(get_dodfs_path())\n",
    "PATHS = np.random.choice(get_dodfs_path(), NUM_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega os dados em DataFrames e os rotula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train, files_test, _, _ = train_test_split(\n",
    "    np.array(PATHS).reshape(-1, 1), range(len(PATHS)), test_size=.20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def cond(s):\n",
    "    return len(s) > 40 and '\\n' in s\n",
    "\n",
    "\n",
    "def build_from_files(files):\n",
    "    data = {}\n",
    "    for fname in files:\n",
    "        doc = fitz.open(fname)\n",
    "        blocks = list(\n",
    "            chain(\n",
    "                *[ [(*i, pnum) for i in p.getTextBlocks()]\n",
    "                  for (pnum, p) in enumerate(doc, start=1)]\n",
    "            )\n",
    "        )\n",
    "        # dropa casos 99% probab. não ser aposentadoria\n",
    "        blocks = [i for i in blocks if cond(i[4])]\n",
    "        pars = [i[4] for i in blocks]\n",
    "        retirements = [wRetirements(i) for i in pars]\n",
    "        dt, num, tipo = get_dodf_key(fname)\n",
    "        df = pd.DataFrame({\n",
    "            'data':[dt] *len(pars),\n",
    "            'num':[num] *len(pars),\n",
    "            'tipo':[tipo] *len(pars),\n",
    "            'text': pars,\n",
    "            'pnum':[int(i[-1]) for i in blocks],\n",
    "            'x0': [i[0] for i in blocks],\n",
    "            'y0': [i[1] for i in blocks],\n",
    "            'x1': [i[2] for i in blocks],\n",
    "            'y1': [i[3] for i in blocks],\n",
    "            'y': [not i.data_frame.empty for i in retirements],\n",
    "            'qtd': [i.data_frame.shape[0] for i in retirements],\n",
    "        })\n",
    "        data[fname] = df\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 1.77 s, total: 3min 2s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = build_from_files(chain.from_iterable(files_train))\n",
    "test_data = build_from_files(chain.from_iterable(files_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 7.95 ms, total: 128 ms\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.concat(train_data.values(), axis=0)\n",
    "df_test = pd.concat(test_data.values(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>num</th>\n",
       "      <th>tipo</th>\n",
       "      <th>text</th>\n",
       "      <th>pnum</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>y</th>\n",
       "      <th>qtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>215</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>POLÍCIA MILITAR DO DISTRITO FEDERAL\\nEDITAL Nº...</td>\n",
       "      <td>30</td>\n",
       "      <td>418.110535</td>\n",
       "      <td>443.719147</td>\n",
       "      <td>765.502808</td>\n",
       "      <td>874.081909</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data  num    tipo  \\\n",
       "458  2018-11-12  215  NORMAL   \n",
       "\n",
       "                                                  text  pnum          x0  \\\n",
       "458  POLÍCIA MILITAR DO DISTRITO FEDERAL\\nEDITAL Nº...    30  418.110535   \n",
       "\n",
       "             y0          x1          y1      y  qtd  \n",
       "458  443.719147  765.502808  874.081909  False    0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.64 s, sys: 136 ms, total: 3.77 s\n",
      "Wall time: 3.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_train.to_csv('xgb_train.csv', sep='®', index=False)\n",
    "df_test.to_csv('xgb_test.csv', sep='®', index=False)\n",
    "\n",
    "prf = 'xgb_train'\n",
    "open(f'{prf}.txt', 'w').write(\n",
    "    f\"notebook de origem: {NOTEBOOK_PATH}\\n\\n\"\n",
    "    f\"O arquivo {prf}.csv contém a rotulação dos blocos de texto\\n\"\n",
    "    \"a respeito de aposentadoria, segundo a classe `Retirements` do\"\n",
    "    \"dodfminer. Espera-se sua utilização para TREINAMENTO.\"\n",
    ")\n",
    "\n",
    "prf = 'xgb_test'\n",
    "open(f'{prf}.txt', 'w').write(\n",
    "    f\"notebook de origem: {NOTEBOOK_PATH}\\n\\n\"\n",
    "    f\"O arquivo {prf}.csv contém a rotulação dos blocos de texto\\n\"\n",
    "    \"a respeito de aposentadoria, segundo a classe `Retirements` do\"\n",
    "    \"dodfminer. Espera-se sua utilização para TESTES.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83269, 8), (26036, 8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2724, 826)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.y].qtd.sum(), df_test[df_test.y].qtd.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump predictions to csv and marked PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def dump_predict(lis, dist_dir, c=(.23, .41, .88)):\n",
    "#     for fname in lis:    \n",
    "#         doc = fitz.open(fname)\n",
    "#         df = file_data[fname]\n",
    "#         clf = pipes[fname]\n",
    "#         X, y = df['text'], df['y']\n",
    "#         predict = clf.predict(X)\n",
    "#         trues = df[predict == True]\n",
    "#         [doc[int(i.pnum)].drawRect(i[2:6], color=c, width=1)\n",
    "#             for i in trues.iloc];\n",
    "#         doc.save(dist_dir + fname.split('/')[-1][:-4] + '_predict.pdf');\n",
    "\n",
    "# def dump_regex(lis, dist_dir, c=(0, .5, .26)):\n",
    "#     for fname in lis:    \n",
    "#         doc = fitz.open(fname)\n",
    "#         df = file_data[fname]\n",
    "#         clf = pipes[fname]\n",
    "#         trues = df[df.y == True]\n",
    "#         if not any(trues):\n",
    "#             print(\"skip\", fname)\n",
    "#         [doc[int(i.pnum)].drawRect(i[2:6], color=c, width=1)\n",
    "#             for i in trues.iloc];\n",
    "#         doc.save(dist_dir + fname.split('/')[-1][:-4] + '_regex.pdf');\n",
    "\n",
    "# def dump_csv():\n",
    "#     def pdf_csv(s):\n",
    "#         return s.split('/')[-1][:-3]+'csv'\n",
    "\n",
    "#     for fname in file_lis:    \n",
    "#         df = file_data[fname]\n",
    "#         prediction = preds[fname]\n",
    "\n",
    "#         df.to_csv(PATH_REGEX[:-1] + '_csv/' + pdf_csv(fname), index=False)\n",
    "#         pd.concat([df.iloc[:, :-1], pd.Series(prediction, name='y')], axis=1).to_csv(\n",
    "#             PATH_PREDICT[:-1] + '_csv/' + pdf_csv(fname), index=False\n",
    "#         )\n",
    "# dump_regex(file_lis, PATH_REGEX)\n",
    "# dump_predict(file_lis, PATH_PREDICT)\n",
    "# dump_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
