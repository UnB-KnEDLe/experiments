{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tem por objetivo testar a capacidade de um modelo de aprendizagem de máquina de acertar a seguinte pergunta:  \n",
    "  - Dado esse bloco de texto, extraído de algum Diário Oficial do Distrito Federal, ele possui ou não atos de pessoal?\n",
    "  \n",
    "Para isso será treinado um modelo de *boosting*, o XGB, e a estratégia de validação adotada foi a [*Leave One Out*](https://scikit-learn.org/stable/modules/cross_validation.html).  \n",
    "Como representação do texto será utilizado o clássico **tfidf** e não serão removidas *stop words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fitz\n",
    "import helper\n",
    "\n",
    "METRICS = [\n",
    "    'f1_macro',\n",
    "    'f1_micro',\n",
    "    'f1_weighted',\n",
    "    'accuracy',\n",
    "    'balanced_accuracy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICT = 'marked_pdf/predict/'\n",
    "PATH_REGEX = 'marked_pdf/regex/'\n",
    "\n",
    "os.makedirs(PATH_PREDICT, exist_ok=True)\n",
    "os.makedirs(PATH_REGEX, exist_ok=True)\n",
    "os.makedirs(PATH_PREDICT[:-1] + '_csv', exist_ok=True)\n",
    "os.makedirs(PATH_REGEX[:-1] + '_csv', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo é realizado a extração dos *blocos* de cada arquivo **.pdf** e, em seguida, cada bloco é rotulado:\n",
    "  - **True**, caso  haja ao menos um ato nesse bloco\n",
    "  - **False** caso não seja detectado nenhum ato\n",
    "\n",
    "Além disso, são salvos os seguintes metadados acerca desses blocos:\n",
    "  - coordenadas (x0, y0, x1, y1)\n",
    "  - número da página (todo bloco começa e termina numa só página)\n",
    "Por fim, cada linha do *dataframe* possui um campo de texto chamado *text*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "file_lis = ['pdf/'+i for i in os.listdir('pdf') if i.endswith('.pdf')]\n",
    "file_df_dict = {}\n",
    "\n",
    "cond = lambda x: len(x[4]) > 40 and '\\n' in x[4]\n",
    "for fname in file_lis:\n",
    "    doc = fitz.open(fname)\n",
    "    blocks = list(\n",
    "        chain(\n",
    "            *[ [(*i, pnum) for i in p.getTextBlocks() if cond(i)]\n",
    "              for (pnum, p) in enumerate(doc)]\n",
    "        )\n",
    "    )\n",
    "    pars = [i[4] for i in blocks]\n",
    "    file_df_dict[fname] = pd.DataFrame({\n",
    "        'text': pars,\n",
    "        'pnum':[int(i[-1]) for i in blocks],\n",
    "        'x0': [i[0] for i in blocks],\n",
    "        'y0': [i[1] for i in blocks],\n",
    "        'x1': [i[2] for i in blocks],\n",
    "        'y1': [i[3] for i in blocks],\n",
    "        'y': map(helper.has_act, pars)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado o número reduzido de documentos a serem usados nos experimentos, foi possível adotar a estratégia **LeaveOneOut** como projeto do experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "index_map_path= dict(enumerate(file_df_dict))\n",
    "\n",
    "\n",
    "pipes = {}\n",
    "preds = {}\n",
    "dfs = {}\n",
    "\n",
    "all_keys = set(file_df_dict)\n",
    "\n",
    "for train, test in LeaveOneOut().split(index_map_path):\n",
    "    pipe = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('model', xgb.XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            random_state=42,\n",
    "            num_class=2\n",
    "        ))\n",
    "    ])    \n",
    "    \n",
    "    df = pd.concat(map(lambda x: file_df_dict[x], [index_map_path[i] for i in train]))\n",
    "    pipe.fit(df.text, df.y);\n",
    "    \n",
    "    out = index_map_path[test[0]]\n",
    "    \n",
    "    pipes[out] = pipe\n",
    "    dfs[out] = file_df_dict[out].text\n",
    "    preds[out] = pipe.predict(file_df_dict[out].text)\n",
    "    df = file_df_dict[out]\n",
    "    X,y = df.text, df.y\n",
    "    disp = plot_confusion_matrix(pipe, X, y,\n",
    "                            cmap=plt.cm.Blues,\n",
    "                            normalize='true',\n",
    "                            xticks_rotation='vertical',\n",
    "                            )\n",
    "    f1 = f1_score(y, preds[out])\n",
    "    acc = accuracy_score(y, preds[out])\n",
    "    print(out)\n",
    "    print(f'\\tf1: {f1:.2f}, acc: {acc:.2f}')\n",
    "    disp.ax_.set_title(f'left out - {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os arquivos **.pdf** lidos pertencem à pasta **pdf**.  \n",
    "\n",
    "A seguir, são salvos versões dos arquivos lidos porém com a diferença que essas versões são **anotadas** com retângulos nos blocos cuja presença de algum ato foi detectada.  \n",
    "Os arquivos **.pdf** são salvos nos diretórios:\n",
    "  - PATH_PREDICT\n",
    "  - REGEX_PREDICT\n",
    "\n",
    "e seus \"análogos\" (seu blocos) no formato **csv** encontram-se em:\n",
    "  - PATH_PREDICT, com sufixo `csv`\n",
    "  - REGEX_PREDICT, com sufixo `csv`\n",
    "  \n",
    "> Nota: optou-se pela anotação em PDFs apenas para facilitar a inspeção visual dos resultados obtidos. Do ponto de vista computacional, os arquivos **.csv** fazem mais sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def dump_predict(lis, dist_dir, c=(.23, .41, .88)):\n",
    "    for fname in lis:    \n",
    "        doc = fitz.open(fname)\n",
    "        df = file_df_dict[fname]\n",
    "        clf = pipes[fname]\n",
    "        X, y = df['text'], df['y']\n",
    "        predict = clf.predict(X)\n",
    "        trues = df[predict == True]\n",
    "        [doc[int(i.pnum)].drawRect(i[2:6], color=c, width=1)\n",
    "            for i in trues.iloc];\n",
    "        doc.save(dist_dir + fname.split('/')[-1][:-4] + '_predict.pdf');\n",
    "\n",
    "def dump_regex(lis, dist_dir, c=(0, .5, .26)):\n",
    "    for fname in lis:    \n",
    "        doc = fitz.open(fname)\n",
    "        df = file_df_dict[fname]\n",
    "        clf = pipes[fname]\n",
    "        trues = df[df.y == True]\n",
    "        if not any(trues):\n",
    "            print(\"skip\", fname)\n",
    "        [doc[int(i.pnum)].drawRect(i[2:6], color=c, width=1)\n",
    "            for i in trues.iloc];\n",
    "        doc.save(dist_dir + fname.split('/')[-1][:-4] + '_regex.pdf');\n",
    "\n",
    "def dump_csv():\n",
    "    def pdf2csv(s):\n",
    "        return s.split('/')[-1][:-3]+'csv'\n",
    "\n",
    "    for fname in file_lis:    \n",
    "        df = file_df_dict[fname]\n",
    "        prediction = preds[fname]\n",
    "        dest = PATH_REGEX[:-1] + '_csv/' + pdf2csv(fname)\n",
    "        print(\"FILE_NAME:\", fname)\n",
    "        print(\"DEST_PATH:\", dest)\n",
    "#         input()\n",
    "        df.to_csv(dest, index=False)\n",
    "        pd.concat([df.iloc[:, :-1], pd.Series(prediction, name='y')], axis=1).to_csv(\n",
    "            PATH_PREDICT[:-1] + '_csv/' + pdf2csv(fname), index=False\n",
    "        )\n",
    "# dump_regex(file_lis, PATH_REGEX)\n",
    "# print(\"Dumped regex\")\n",
    "# dump_predict(file_lis, PATH_PREDICT)\n",
    "# print(\"Dumped predict\")\n",
    "# dump_csv()\n",
    "# print(\"Dumped csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões preliminares:\n",
    "  - XGB mostrou-se bastante eficaz em detectar blocos contendo atos\n",
    "  - XGB encontrou blocos que não tinham sido apontados como possuindo atos de pessoal mas que de fato os possuíam\n",
    "  - Promissora a ideia de detecção automatizada de blocos não capturados pelas expressões regulares\n",
    "\n",
    "Limitações:\n",
    "  - falta de dados anotados, o que permitiria comparação mais acurada entre ambas rotulações\n",
    "  - outros classificadores não foram testados. Por exemplo, o SVM poderia diminuir imensamente o tempo e talvez produzir resultados semelhantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
