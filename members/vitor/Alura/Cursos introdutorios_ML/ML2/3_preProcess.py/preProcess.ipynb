{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93b80ab-12fd-4a1e-a2da-b83d64f7b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6626e2-98f7-42f3-8693-937a5de57a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('rslp') # \"removedor de sufixo da lingua portuguesa\"\n",
    "#nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef97ca70-03e6-433e-9de5-889688f37511",
   "metadata": {},
   "source": [
    "Auxílios do nltk usados:\n",
    "    * stopwords\n",
    "    * stemmer\n",
    "    * wordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d8584f-5db0-48c2-a097-2dfab1e39d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer() \n",
    "\n",
    "\n",
    "#frase = \"bora ali compra um pão? bora bora!\"\n",
    "#x = tokenizer = nltk.tokenize.word_tokenize(frase)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfc6bb6-40e3-4a13-ace1-a9dbd850d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes = pd.read_csv('emails.csv')\n",
    "textosPuros = classificacoes['email']\n",
    "#Recuperando textos em tokens e em minúsculo\n",
    "frases = textosPuros.str.lower()\n",
    "textosQuebrados = [nltk.tokenize.word_tokenize(frase) for frase in frases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a591c793-b1ba-44d6-8cb6-e769ca0d2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a9c35-91a3-4857-b724-2cb1f6289777",
   "metadata": {},
   "source": [
    "* Utilizando o stemmer para recupear raízes das palavras e colocar no dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0208a320-0765-4042-a1c0-742acd32576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = set()\n",
    "for lista in textosQuebrados:\n",
    "    validas = [stemmer.stem(palavra) for palavra in lista if palavra not in stopwords and len(palavra) > 2]\n",
    "    dicionario.update(validas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06cc2ff-91fd-46a3-9d54-0c87350506d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de palavras: 230\n",
      "{'bas', 'antecipad', 'equip', 'play', 'pra', 'sit', 'trilh', 'virtu', 'moder', 'exist', 'premiun', 'faculdad', 'correç', 'cust', 'sobr', 'opt', 'via', 'premium', 'víde', 'val', 'desd', 'fic', 'laravel', 'maiúscul', 'escolh', 'gost', 'ob', 'real', 'lid', 'bom', 'comput', 'sent', 'sum', 'design', 'aqu', 'qualqu', 'ganh', 'cart', 'pag', 'inic', 'iníci', 'cs', 'term', 'program', 'curs', 'cobol', 'interess', 'window', 'expir', 'troc', 'antecip', 'cri', 'coloq', 'empr', 'recomend', 'exercíci', 'carr', 'ach', 'pouc', 'cadastr', 'mim', 'emit', 'tod', 'interfac', 'almej', 'confer', 'plan', 'email', 'us', 'googl', 'respost', 'pyqt', 'framework', 'boa', 'pro', 'avis', 'depend', 'compr', 'letr', 'part', 'io', 'qual', 'moip', 'proxim', 'mud', 'depo', 'form', 'poss', 'jav', 'torn', 'sab', 'cresc', 'nov', 'quant', 'desenvolv', 'pret', 'naveg', 'ajud', 'vist', 'faz', 'vers', 'qu', 'di', 'conhec', 'áre', 'conteúd', 'pert', 'brasil', 'fórum', 'algum', 'python', 'absorv', 'complet', 'lingu', 'nom', 'capaz', 'poi', 'trav', 'dev', 'dúv', 'alguém', 'ser', 'noit', 'lógic', 'mai', 'efetu', 'começ', 'colun', 'filh', 'convid', 'conheç', 'realiz', 'dep', 'dificuldad', 'cancel', 'sistem', 'termin', 'parabém', 'outr', 'necess', 'hav', 'seguint', 'trabalh', 'pal', 'cuid', 'encontr', 'olá', 'plu', 'alur', 'pai', 'própri', 'inform', 'aplic', 'err', 'javascrip', 'pesquis', 'comunidad', 'minut', 'ambi', 'faç', 'control', 'html', 'ótim', 'explic', 'seman', 'ano', 'bancár', 'caminh', 'ver', 'mac', 'inter', 'duvid', 'aind', 'porém', 'quer', 'tent', 'por', 'vai', 'ferrament', 'desej', 'use', 'gráf', 'possu', 'djang', 'imprim', 'pod', 'prát', 'marketing', 'ont', 'ond', 'digit', 'aprend', 'segund', 'payp', 'plataform', 'pass', 'distanc', 'dia', 'dess', 'independ', 'post', 'identifiq', 'vontad', 'renov', 'aul', 'transferenc', 'muit', 'favor', 'vez', 'envi', 'estud', 'agradeç', 'parec', 'acess', 'vou', 'cinc', 'cont', 'excel', 'indic', 'entend', 'web', 'além', 'melhor', 'nenhum', 'antig', 'fórmul', 'descont', 'desejo-t', 'certific', 'sei'}\n"
     ]
    }
   ],
   "source": [
    "totalDePalavras = len(dicionario)\n",
    "print(f'total de palavras: {totalDePalavras}')\n",
    "print(dicionario)\n",
    "tuplas = zip(dicionario, range(totalDePalavras))\n",
    "tradutor = {palavra: indice for palavra, indice in tuplas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c6a0cd-5fd5-47b0-b099-96fede60a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tradutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a4177-5591-44ab-8b33-7e4a8f908dbf",
   "metadata": {},
   "source": [
    "* Logo, na hora de vetorizar o tezto, devo pegar as raízes das palavras contidas nele, já que o tradutor contém as raízes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e79174a1-5760-420e-9899-51b7cf86f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2aabde-a376-4b0d-a8ea-f4238cf9b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetoresDeTexto = [vetorizar_texto(texto, tradutor, stemmer) for texto in textosQuebrados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b57d98-b931-4ad1-ba07-928dc8e82a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas = classificacoes['classificacao']\n",
    "\n",
    "X = vetoresDeTexto\n",
    "Y = marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd22432-1725-4834-8a39-79226d24bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "porcentagem_de_treino = 0.8\n",
    "\n",
    "tamanho_de_treino = int(porcentagem_de_treino * len(Y))\n",
    "tamanho_de_validacao = len(Y) - tamanho_de_treino\n",
    "\n",
    "print(tamanho_de_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e67aac9-348c-4a6c-b63c-4f9ca1146772",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_dados = X[0:tamanho_de_treino]\n",
    "treino_marcacoes = Y[0:tamanho_de_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_de_treino:]\n",
    "validacao_marcacoes = Y[tamanho_de_treino:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c06079-9dfc-4002-b97a-6a4a8e679eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    k = 10\n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv=k)\n",
    "    taxa_de_acerto = np.mean(scores)\n",
    "    msg = \"Taxa de acerto do {0}: {1}\".format(nome, taxa_de_acerto)\n",
    "    print(msg)\n",
    "    return taxa_de_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b563e5f5-58fb-46a3-bbf4-f63c47df448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "\n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "    msg = \"Taxa de acerto do vencedor entre os dois algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd2b15f-a412-4306-b1c4-46029cee4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto do OneVsRest: 0.7416666666666666\n",
      "Taxa de acerto do OneVsOne: 0.7416666666666667\n",
      "Taxa de acerto do MultinomialNB: 0.8\n",
      "Taxa de acerto do AdaBoostClassifier: 0.5833333333333333\n",
      "{0.7416666666666666: OneVsRestClassifier(estimator=LinearSVC(random_state=0)), 0.7416666666666667: OneVsOneClassifier(estimator=LinearSVC(random_state=0)), 0.8: MultinomialNB(), 0.5833333333333333: AdaBoostClassifier(random_state=0)}\n",
      "Vencerdor: \n",
      "MultinomialNB()\n",
      "Taxa de acerto do vencedor entre os dois algoritmos no mundo real: 77.77777777777777\n",
      "Taxa de acerto base: 44.444444\n",
      "Total de teste: 9\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "modeloAdaBoost = AdaBoostClassifier(random_state=0)\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost\n",
    "\n",
    "\n",
    "print(resultados)\n",
    "\n",
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "\n",
    "print(\"Vencerdor: \")\n",
    "print(vencedor)\n",
    "\n",
    "vencedor.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c7db6-59c0-4344-8153-be415a2482d0",
   "metadata": {},
   "source": [
    "APRENDIZADO:\n",
    "* Stop words\n",
    "* Como remover as stop words do dicionário\n",
    "* Como instalar o nltk e seus módulos\n",
    "* Como extrair as raízes das palavras\n",
    "* Como separar as palavras de uma frase com o tokenize\n",
    "* Como remover palavras com pontuações do dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fad39-d0c6-43d3-8b28-a9c7426999a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
