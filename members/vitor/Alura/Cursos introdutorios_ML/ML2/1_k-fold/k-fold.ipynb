{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d0d7c6-45d6-42cc-94fe-7453aad0b063",
   "metadata": {},
   "source": [
    "* Quando estamos alterando a ordem dos dados de treino e teste, podemos quebrar em k pedaços de tal forma que , caso sejam:\n",
    "    * 2 pedaços:: 1°: primeira metade treina e segunda testa && 2°: primeira metade testa e segunda treina\n",
    "    * 3 pedaços:: 1°: primeiro pedaço treina e resto testa && segundo pedaço treina e o resto testa && terceiro pedaço treina e o resto testa\n",
    "*  Ou seja, realizo os testes para CADA UMA DAS PARTIÇÕES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c651fcc-cd68-4b02-acd1-c1df3183bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score # já vai fazar o fit, predict e devolver as notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f373a2-df10-41ea-b825-b01587a93ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clientes.csv')\n",
    "X_df = df[['recencia','frequencia', 'semanas_de_inscricao']]\n",
    "Y_df = df['situacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1213017-40e0-4e5a-a514-d8311645b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e90f41-85d4-4b3a-8ba6-59e78d74b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e93cec-99b4-4b54-90c8-9d8d2911ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_de_treino_e_teste = 0.9\n",
    "\n",
    "tamanho_de_treino_e_teste = int(porcentagem_de_treino_e_teste * len(Y))\n",
    "\n",
    "treino_dados = X[:tamanho_de_treino_e_teste]\n",
    "treino_marcacoes = Y[:tamanho_de_treino_e_teste]\n",
    "\n",
    "validacao_dados = X[tamanho_de_treino_e_teste:]\n",
    "validacao_marcacoes = Y[tamanho_de_treino_e_teste:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9087f71b-0553-4e81-841e-70fd848ce1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes):\n",
    "    k = 10\n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv = k)\n",
    "    taxa_de_acerto = np.mean(scores)\n",
    "    msg = f'A taxa de acerto de {nome} foi: {taxa_de_acerto}'\n",
    "    print(msg)\n",
    "    return(taxa_de_acerto)\n",
    "\n",
    "def teste_real(modelo, validacao_dados, validacao_marcacoes):\n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    acertos = resultado == validacao_marcacoes\n",
    "\n",
    "    total_de_acertos = sum(acertos)\n",
    "    total_de_elementos = len(validacao_marcacoes)\n",
    "\n",
    "    taxa_de_acerto = 100.0 * total_de_acertos / total_de_elementos\n",
    "\n",
    "    msg = \"Taxa de acerto do vencedor entre os algoritmos no mundo real: {0}\".format(taxa_de_acerto)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa25525-0595-4d90-bc1d-537a68585122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto de OneVsRest foi: 0.9257142857142858\n",
      "A taxa de acerto de OneVsOne foi: 1.0\n",
      "A taxa de acerto de MultinomialNB foi: 0.8366666666666667\n",
      "A taxa de acerto de AdaBoostClassifier foi: 0.7528571428571429\n"
     ]
    }
   ],
   "source": [
    "resultados = {}\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "modeloOneVsRest = OneVsRestClassifier(LinearSVC(random_state = 0, max_iter=10000))\n",
    "resultadoOneVsRest = fit_and_predict(\"OneVsRest\", modeloOneVsRest, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsRest] = modeloOneVsRest\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "modeloOneVsOne = OneVsOneClassifier(LinearSVC(random_state = 0, max_iter=10000))\n",
    "resultadoOneVsOne = fit_and_predict(\"OneVsOne\", modeloOneVsOne, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoOneVsOne] = modeloOneVsOne\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", modeloMultinomial, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modeloAdaBoost = AdaBoostClassifier()\n",
    "resultadoAdaBoost = fit_and_predict(\"AdaBoostClassifier\", modeloAdaBoost, treino_dados, treino_marcacoes)\n",
    "resultados[resultadoAdaBoost] = modeloAdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb703638-a52d-42a9-9ef2-0885d2cc71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9257142857142858, OneVsRestClassifier(estimator=LinearSVC(max_iter=10000, random_state=0)))\n",
      "(1.0, OneVsOneClassifier(estimator=LinearSVC(max_iter=10000, random_state=0)))\n",
      "(0.8366666666666667, MultinomialNB())\n",
      "(0.7528571428571429, AdaBoostClassifier())\n",
      "Vencerdor: \n",
      "OneVsOneClassifier(estimator=LinearSVC(max_iter=10000, random_state=0))\n",
      "Taxa de acerto do vencedor entre os algoritmos no mundo real: 100.0\n",
      "Taxa de acerto base: 82.608696\n",
      "Total de teste: 23\n"
     ]
    }
   ],
   "source": [
    "for r in resultados.items():\n",
    "    print(r)\n",
    "\n",
    "\n",
    "maximo = max(resultados)\n",
    "vencedor = resultados[maximo]\n",
    "\n",
    "print(\"Vencerdor: \")\n",
    "print(vencedor)\n",
    "\n",
    "vencedor.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "teste_real(vencedor, validacao_dados, validacao_marcacoes)\n",
    "\n",
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)\n",
    "\n",
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68758333-46e8-4660-bc5c-eaf3377909e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
