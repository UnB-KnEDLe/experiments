{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('result.csv')\n",
    "result = pd.DataFrame(df)\n",
    "result.tokenized_text = result.tokenized_text.apply(lambda x: x.encode('ascii','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 1168)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for row in range(len(result)):\n",
    "    if pd.notna(result['treated_text'][row]):\n",
    "        text_iob = result['tokenized_text'][row].decode(\"utf-8\").replace(\"', '\", '').replace(\"[' \", '').replace(\"']\", '')\n",
    "        x.append(word_tokenize(result['treated_text'][row]))\n",
    "        y.append(text_iob.split())\n",
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tirando os rotulos que nao batem com os dados\n",
    "continua = True\n",
    "while continua == True:\n",
    "    continua = False\n",
    "    for i in range(len(x)):\n",
    "        if len(x[i]) > len(y[i]):\n",
    "            x[i].pop()\n",
    "            continua = True\n",
    "\n",
    "        if len(x[i]) < len(y[i]):\n",
    "            y[i].pop()\n",
    "            continua = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(sentence):\n",
    "        \"\"\"Create features for each word in act.\n",
    "        Create a list of dict of words features to be used in the predictor module.\n",
    "        Args:\n",
    "            act (list): List of words in an act.\n",
    "        Returns:\n",
    "            A list with a dictionary of features for each of the words.\n",
    "        \"\"\"\n",
    "        sent_features = []\n",
    "        for i in range(len(sentence)):\n",
    "            # print(sentence[i])\n",
    "            word_feat = {\n",
    "                'word': sentence[i].lower(),\n",
    "                'capital_letter': sentence[i][0].isupper(),\n",
    "                'all_capital': sentence[i].isupper(),\n",
    "                'isdigit': sentence[i].isdigit(),\n",
    "                'word_before': sentence[i].lower() if i == 0 else sentence[i-1].lower(),\n",
    "                'word_after:': sentence[i].lower() if i+1 >= len(sentence) else sentence[i+1].lower(),\n",
    "                'BOS': i == 0,\n",
    "                'EOS': i == len(sentence)-1\n",
    "            }\n",
    "            sent_features.append(word_feat)\n",
    "        return sent_features\n",
    "    \n",
    "for i in range(len(x)):\n",
    "    x[i] = get_features(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 234, 934)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "split_idx = math.floor(0.8*len(x))\n",
    "x_train = x[0:split_idx]\n",
    "y_train = y[0:split_idx]\n",
    "x_test = x[split_idx:]\n",
    "y_test = y[split_idx:]\n",
    "len(x_train),  len(x_test), len(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thais/Documentos/Knedle/venv/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [nan nan nan nan nan]\n",
      "Precision: [nan nan nan nan nan]\n",
      "Acuracy: [nan nan nan nan nan]\n",
      "f1_score: [nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thais/Documentos/Knedle/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thais/Documentos/Knedle/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thais/Documentos/Knedle/venv/lib/python3.8/site-packages/sklearn_crfsuite/estimator.py\", line 314, in fit\n",
      "    trainer.append(xseq, yseq)\n",
      "  File \"pycrfsuite/_pycrfsuite.pyx\", line 312, in pycrfsuite._pycrfsuite.BaseTrainer.append\n",
      "  File \"stringsource\", line 48, in vector.from_py.__pyx_convert_vector_from_py_std_3a__3a_string\n",
      "  File \"stringsource\", line 15, in string.from_py.__pyx_convert_string_from_py_std__in_string\n",
      "TypeError: expected bytes, numpy.int64 found\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# mb = MultiLabelBinarizer()\n",
    "# y_train = mb.fit_transform(y_train)\n",
    "\n",
    "# recall = cross_val_score(crf, x_train, y_train, cv=5, scoring='recall')\n",
    "# precision = cross_val_score(crf, x_train, y_train, cv=5, scoring='precision')\n",
    "# accuracy = cross_val_score(crf, x_train, y_train, cv=5, scoring='accuracy')\n",
    "# f1_score = cross_val_score(crf, x_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Acuracy: {accuracy}\")\n",
    "# print(f\"f1_score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(crf.classes_)\n",
    "classes.remove('O')\n",
    "print(classes)\n",
    "y_pred = crf.predict(x_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=classes, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85a52d88f0aa1e50edcac7a8fa01ec2de1ab2b3c7a457090e250a76047dc0c3e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
