{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os atos de Licitação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "path_data = pd.read_csv('/home/thais/Downloads/licitacao_dodf_watcher.csv')\n",
    "data_train = pd.DataFrame(path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "\n",
    "with open('licitacao.pkl' , 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(sentence):\n",
    "    \"\"\"Create features for each word in act.\n",
    "    Create a list of dict of words features to be used in the predictor module.\n",
    "    Args:\n",
    "        act (list): List of words in an act.\n",
    "    Returns:\n",
    "        A list with a dictionary of features for each of the words.\n",
    "    \"\"\"\n",
    "    sent_features = []\n",
    "    for i in range(len(sentence)):\n",
    "        word_feat = {\n",
    "            'word': sentence[i].lower(),\n",
    "            'word[-3:]': sentence[i][-3:],\n",
    "            'word[-2:]': sentence[i][-2:],\n",
    "            'capital_letter': sentence[i][0].isupper(),\n",
    "            'word_istitle': sentence[i].istitle(),\n",
    "            'all_capital': sentence[i].isupper(),\n",
    "            'word_isdigit': sentence[i].isdigit(),\n",
    "            # Uma palavra antes\n",
    "            'word_before': '' if i == 0 else sentence[i-1].lower(),\n",
    "            'word_before_isdigit': '' if i == 0 else sentence[i-1].isdigit(),\n",
    "            'word_before_isupper': '' if i == 0 else sentence[i-1].isupper(),\n",
    "            'word_before_istitle': '' if i == 0 else sentence[i-1].istitle(),\n",
    "            # Duas palavras antes\n",
    "            'word_before2': '' if i in [0, 1] else sentence[i-2].lower(),\n",
    "            'word_before_isdigit2': '' if i in [0, 1] else sentence[i-1].isdigit(),\n",
    "            'word_before_isupper2': '' if i in [0, 1] else sentence[i-1].isupper(),\n",
    "            'word_before_istitle2': '' if i in [0, 1] else sentence[i-1].istitle(),\n",
    "            # Uma palavra depois\n",
    "            'word_after': '' if i+1 >= len(sentence) else sentence[i+1].lower(),\n",
    "            'word_after_isdigit': '' if i+1 >= len(sentence) else sentence[i+1].isdigit(),\n",
    "            'word_after_isupper': '' if i+1 >= len(sentence) else sentence[i+1].isupper(),\n",
    "            'word_after_istitle': '' if i+1 >= len(sentence) else sentence[i+1].istitle(),\n",
    "            # Duas palavras depois\n",
    "            'word_after2': '' if i+2 >= len(sentence) else sentence[i+2].lower(),\n",
    "            'word_after_isdigit2': '' if i+2 >= len(sentence) else sentence[i+2].isdigit(),\n",
    "            'word_after_isupper2': '' if i+2 >= len(sentence) else sentence[i+2].isupper(),\n",
    "            'word_after_istitle2': '' if i+2 >= len(sentence) else sentence[i+2].istitle(),\n",
    "            \n",
    "            'BOS': i == 0,\n",
    "            'EOS': i == len(sentence)-1\n",
    "        }\n",
    "        sent_features.append(word_feat)\n",
    "    return sent_features\n",
    "\n",
    "# Concatena cada palavra do texto do ato com sua respectiva anotação de entidade\n",
    "\n",
    "def concatenaPredicao(ato,  predicao):\n",
    "    print (\"{:<15} {:<10}\".format('Entidade','Predição'))\n",
    "    for i in range(len(ato)):\n",
    "        print (\"{:<15} {:<10}\".format( ato[i], predicao[i]))\n",
    "        # print(ato[i] + '------' + predicao[i])\n",
    "        # print(predicao[i]) + '[' + predicao[i] + ']' , end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predictions_dict(model, act, prediction):\n",
    "    \"\"\"Create dictionary of proprieties.\n",
    "    Create dictionary of tags to save predicted entities.\n",
    "    Args:\n",
    "        sentence (list): List of words and tokens in the act.\n",
    "        prediction ([type]): The correspondent predicitons for each\n",
    "                             word in the sentence.\n",
    "    Returns:\n",
    "        A dictionary of the proprieties found.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    dict_ato = {}\n",
    "    for klass in model.classes_:\n",
    "        if klass == 'O':\n",
    "            continue\n",
    "        dict_ato[klass[2:]] = []\n",
    "\n",
    "    current = ''\n",
    "    count = 0\n",
    "    pred_start = 0\n",
    "\n",
    "    for i,_ in enumerate(prediction):\n",
    "\n",
    "        if prediction[i][0] == 'I':\n",
    "            count += 1\n",
    "\n",
    "        elif prediction[i][0] == 'B':\n",
    "            pred_start = i\n",
    "\n",
    "        elif prediction[i][0] == 'O' and pred_start:\n",
    "            current = prediction[pred_start][2:]\n",
    "            entidade = ' '.join(act[pred_start:i])\n",
    "            dict_ato[current] = entidade\n",
    "            pred_start = 0\n",
    "            count = 0\n",
    "        else:\n",
    "            continue\n",
    "           \n",
    "    for key, val in dict_ato.items():\n",
    "        if len(val) == 0:\n",
    "            dict_ato[key] = np.nan\n",
    "        elif len(val) == 1:\n",
    "            dict_ato[key] = val[0]\n",
    "    return dict_ato\n",
    "\n",
    "def add_standard_props(act, capitalize=False):\n",
    "    standard_props = _standard_props()\n",
    "\n",
    "    if capitalize:\n",
    "        standard_props = {(key.capitalize()):val for key, val in standard_props.items()}\n",
    "\n",
    "    act = {**act, **(standard_props)}\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tokens = [str(data_train['texto'][i]) for i in range(len(data_train['texto']))]\n",
    "\n",
    "atos_tokens_lista = [word_tokenize(tokens[i]) for i in range(len(tokens))]\n",
    "\n",
    "# atos_tokens_lista = [word_tokenize(data_train['texto'][i]) for i in range(len(data_train['texto']))]\n",
    "atos_features_lista = [get_features(atos_tokens_lista[i]) for i in range(len(atos_tokens_lista))]\n",
    "\n",
    "predicao = lr.predict(atos_features_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_acts = []\n",
    "\n",
    "for i in range(len(predicao)):\n",
    "    predicted_dict = predictions_dict(lr, atos_tokens_lista[i], predicao[i])\n",
    "    predicted_dict['TEXTO'] = tokens[i] \n",
    "    _acts.append(predicted_dict)\n",
    "\n",
    "data_frame = pd.DataFrame.from_dict(_acts)\n",
    "\n",
    "# data_frame.to_csv('licitacoes_previstas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2076 entries, 0 to 2075\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   MODALIDADE_LICITACAO    293 non-null    object\n",
      " 1   NUM_LICITACAO           1187 non-null   object\n",
      " 2   ORGAO_LICITANTE         244 non-null    object\n",
      " 3   SISTEMA_COMPRAS         1083 non-null   object\n",
      " 4   OBJ_LICITACAO           1898 non-null   object\n",
      " 5   VALOR_ESTIMADO          1233 non-null   object\n",
      " 6   DATA_ABERTURA           1318 non-null   object\n",
      " 7   PROCESSO                606 non-null    object\n",
      " 8   IOB                     1583 non-null   object\n",
      " 9   NOME_RESPONSAVEL        10 non-null     object\n",
      " 10  CODIGO_SISTEMA_COMPRAS  886 non-null    object\n",
      " 11  TEXTO                   2076 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 194.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "338c0a9803ff480ccc07b31115e580da2ab36b78b341bf47b00822fe62e3912b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
