{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/thais/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    inside = False\n",
    "    start = False\n",
    "    text_lines_mod = []\n",
    "    \n",
    "    text_lines = word_tokenize(text)\n",
    "    \n",
    "    for line in text_lines:\n",
    "        if \"B__B-\" in line:\n",
    "            start = True\n",
    "            inside = True\n",
    "            token = line.split(\"B__B\")[1].split(\"-\")[1]\n",
    "        elif \"E__E-\" in line:\n",
    "            inside = False\n",
    "        else:\n",
    "            if not inside:\n",
    "                line = \" O\"\n",
    "            else:\n",
    "                if start:\n",
    "                    line = \" B-\" + token\n",
    "                else:\n",
    "                    line = \" I-\" + token\n",
    "                start = False\n",
    "\n",
    "            text_lines_mod.append(line)\n",
    "            \n",
    "    return text_lines_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_text_lines(base_df, base_text_df):\n",
    "    marked_texts = []\n",
    "\n",
    "    for arquivo in base_df[\"arquivo_rast\"].unique():\n",
    "        entidades_df = base_df[base_df[\"arquivo_rast\"] == arquivo].copy().reset_index(drop=True)[[\"entidade\", \"ner_token\", \"loc_begin\", \"loc_end\", \"arquivo_rast\"]]\n",
    "        text = base_text_df[base_text_df[\"arquivo_rast\"] == arquivo][\"text\"].iloc[0]\n",
    "\n",
    "        entidades_df = entidades_df.sort_values([\"loc_end\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        for token, begin, end in entidades_df[[\"ner_token\", \"loc_begin\", \"loc_end\"]].itertuples(index=False):\n",
    "            mark_token_begin = \" B__B-\" + token + \"-B__B \"\n",
    "            mark_token_end = \" E__E-\" + token + \"-E__E \"\n",
    "\n",
    "            text = text[:end] + mark_token_end +  text[end:]\n",
    "            text = text[:begin] + mark_token_begin +  text[begin:]\n",
    "\n",
    "        marked_texts.append(text)\n",
    "        \n",
    "    marked_texts_df = pd.DataFrame(pd.Series(marked_texts), columns=[\"marked_text\"])\n",
    "    marked_texts_df[\"arquivo_rast\"] = base_df[\"arquivo_rast\"].unique()\n",
    "    \n",
    "    #return marked_texts_df\n",
    "\n",
    "    marked_texts_df[\"treated_text\"] = clean_text_dodfs(marked_texts_df[\"marked_text\"])\n",
    "    marked_texts_df[\"treated_text\"] = marked_texts_df.apply(lambda row: clean_text_by_word(row[\"treated_text\"]), axis=1)\n",
    "    \n",
    "    marked_texts_df[\"tokenized_text\"] = marked_texts_df.apply(lambda row: tokenize_text(row[\"treated_text\"]), axis=1)\n",
    "    \n",
    "    return marked_texts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_text_lines_geral(base_df, base_text_df):\n",
    "    marked_texts = []\n",
    "\n",
    "    for arquivo in base_df[\"arquivo_rast\"].unique():\n",
    "        entidades_df = base_df[base_df[\"arquivo_rast\"] == arquivo].copy().reset_index(drop=True)[[\"entidade\", \"ner_token\", \"loc_begin\", \"loc_end\", \"arquivo_rast\"]]\n",
    "        text = base_text_df[base_text_df[\"arquivo_rast\"] == arquivo][\"text\"].iloc[0]\n",
    "\n",
    "        entidades_df = entidades_df.sort_values([\"loc_end\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        for token, begin, end in entidades_df[[\"ner_token\", \"loc_begin\", \"loc_end\"]].itertuples(index=False):\n",
    "            mark_token_begin = \" B__B-\" + token + \"-B__B \"\n",
    "            mark_token_end = \" E__E-\" + token + \"-E__E \"\n",
    "\n",
    "            text = text[:end] + mark_token_end +  text[end:]\n",
    "            text = text[:begin] + mark_token_begin +  text[begin:]\n",
    "\n",
    "        marked_texts.append(text)\n",
    "        \n",
    "    marked_texts_df = pd.DataFrame(pd.Series(marked_texts), columns=[\"marked_text\"])\n",
    "    marked_texts_df[\"arquivo_rast\"] = base_df[\"arquivo_rast\"].unique()\n",
    "    \n",
    "    #return marked_texts_df\n",
    "\n",
    "    marked_texts_df[\"treated_text\"] = clean_text_dodfs(marked_texts_df[\"marked_text\"])\n",
    "    marked_texts_df[\"treated_text\"] = marked_texts_df.apply(lambda row: clean_text_by_word(row[\"treated_text\"]), axis=1)\n",
    "    \n",
    "    tokenized_texts = marked_texts_df.apply(lambda row: [tokenize_text(row[\"treated_text\"]), row[\"arquivo_rast\"]], axis=1)\n",
    "    \n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_dodfs(dodfs_texts):\n",
    "\n",
    "    start_page_patterns = [r\"\\nPÁGINA\\s([0-9]{1,5})\", r\"\\nDIÁRIO\\sOFICIAL\\sDO\\sDISTRITO\\sFEDERAL\",\n",
    "                           r\"\\nNº(.+?)2([0-9]{3})\", r\"\\nxx([a-z]{0,10}) Diário Oficial do Distrito Federal xx([a-z]{0,10})\",\n",
    "                           r\"\\nDiário Oficial do Distrito Federal\"]\n",
    "\n",
    "    end_page_patterns = [r\"Documento assinado digitalmente conforme MP nº 2.200-2 de 24/08/2001, que institui a\",\n",
    "                            r\"Infraestrutura de Chaves Públicas Brasileira ICP-Brasil\",\n",
    "                            r\"Este documento pode ser verificado no endereço eletrônico\",\n",
    "                            r\"http://wwwin.gov.br/autenticidade.html\",\n",
    "                            r\"pelo código ([0-9]{15,18})\",\n",
    "                            r\"\\nDocumento assinado digitalmente, original em https://www.dodf.df.gov.br\",\n",
    "                        r\"http:/Awwwin.gov.br/autenticidade.html\",\n",
    "                        r\"Documento assinado digitalmente conforme MP nº 2.200-2 de 24/08/2001,\",\n",
    "                        r\"\\nque institui a\\n\",\n",
    "                        r\"\\nhttp://www.in.gov.br/autenticidade.html\",\n",
    "                        r\"\\nhttp://www.in.gov.brautenticidade html\",\n",
    "                        r\"Documento assinado digitalmente conforme MP n 2.200-2 de 24/08/2001, que institui a .\",\n",
    "                        r\"http://www.in.gov.brautenticidade html,\"]\n",
    "\n",
    "    middle_page_patterns = [r\"xx([a-z]{1,10}) \", r\" xx([a-z]{1,10})\", r\"xx([a-z]{1,10})\"]\n",
    "    \n",
    "    special_middle_page_patterns = [r\"\\n-\\n\", r\"\\n- -\\n\", r\"\\n- - -\\n\", r\"\\n[\\.\\,\\-\\—]\\n\", r\"— -\", r\". -\",\n",
    "                                   r\"\\r[\\.\\,\\-\\—]\\r\", r\"\\n-\\r\", r\"\\r\"]\n",
    "    \n",
    "    start_page_patterns = \"|\".join(start_page_patterns)\n",
    "    middle_page_patterns = \"|\".join(middle_page_patterns)\n",
    "    end_page_patterns = \"|\".join(end_page_patterns)\n",
    "    \n",
    "    page_patterns = [start_page_patterns, middle_page_patterns, end_page_patterns]\n",
    "    page_patterns = \"|\".join(page_patterns)\n",
    "    \n",
    "    return dodfs_texts.str.replace(page_patterns, \"\", regex=True).replace(special_middle_page_patterns, \"\\n\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_by_word(text):\n",
    "    a = \"\\n\".join([l for l in text.split(\"\\n\") if l != \"\"])\n",
    "    words = a.replace(\"\\n\", \" \").split(\" \")\n",
    "    words = [w for w in words if w != \"\"]\n",
    "    \n",
    "    m_words = []\n",
    "    dash_cut = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "\n",
    "        if (word[-1] == \"-\") and (i+1)<len(words):\n",
    "            word = word[:-1] + words[i+1]\n",
    "            i += 1\n",
    "\n",
    "        m_words.append(word)\n",
    "        \n",
    "    return \" \".join(m_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_parse(base_df, func=None):\n",
    "    if func == None:\n",
    "        return base_df\n",
    "    else:\n",
    "        return func(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação dos rótulos dados no LabelBox para os rótulos que serão usados no modelo NER\n",
    "\n",
    "ner_tokens_extrato_contrato = {\n",
    "    \"Número do ajuste\": \"NUM_AJUSTE\",\n",
    "    \"Órgão contratante\": \"CONTRATANTE\",\n",
    "    \"Entidade contratada\": \"CONTRATADA\",\n",
    "    \"Entidades convenentes\": \"CONVENENTE\",\n",
    "    \"Processo do GDF\": \"PROCESSO\",\n",
    "    \"Objeto do ajuste\": \"OBJ_AJUSTE\",\n",
    "    \"Data de assinatura do ajuste\": \"DATA_ASSINATURA\",\n",
    "    \"Vigência do ajuste\": \"VIGENCIA\",\n",
    "    \"Valor do ajuste\": \"VALOR\",\n",
    "    \"Código da unidade orçamentária\": \"CODIGO_UO\",\n",
    "    \"Programa de trabalho\": \"PT\",\n",
    "    \"Natureza da despesa\": \"ND\",\n",
    "    \"Nota de empenho\": \"NE\",\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação que gerou o contrato\": \"NUM_LICITACAO\",\n",
    "    \"Órgão gerenciador da ata\": \"OG_ATA\",\n",
    "    \"Identificação de dispensa\": \"IDENT_DISPENSA\",\n",
    "    \"Fundamento legal da dispensa ou inexigibilidade\": \"FUND_DISPENSA\"\n",
    "}\n",
    "\n",
    "ner_tokens_aditamento_contratual = {\n",
    "    \"Órgão contratante\": \"CONTRATANTE\",\n",
    "    \"Número do contrato\": \"NUM_CONTRATO\",\n",
    "    \"Número do termo aditivo\": \"NUM_ADITIVO\",\n",
    "    \"Objeto do aditamento contratual\": \"OBJ_ADITIVO\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_licitacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Objeto da licitação\": \"OBJ_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Processo do GDF\": \"PROCESSO\",\n",
    "    \"Valor estimado da contratação\": \"VALOR_ESTIMADO\",\n",
    "    \"Data de abertura da licitação\": \"DATA_ABERTURA\",\n",
    "    \"Sistema de compras utilizado\": \"SISTEMA_COMPRAS\",\n",
    "    \"Código da licitação no sistema de compras utilizado\": \"CODIGO_SISTEMA_COMPRAS\",\n",
    "    \"Tipo de objeto\": \"TIPO_OBJ\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_revogacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Identificação revogação/anulação\": \"IDENT_REVOGACAO_ANULACAO\"\n",
    "}\n",
    "\n",
    "ner_tokens_aviso_suspensao_licitacao = {\n",
    "    \"Órgão/entidade licitante\": \"ORGAO_LICITANTE\",\n",
    "    \"Número da licitação\": \"NUM_LICITACAO\",\n",
    "    \"Modalidade de licitação\": \"MODALIDADE_LICITACAO\",\n",
    "    \"Prazo da suspensão\": \"PRAZO_SUSPENSAO\",\n",
    "    \"Decisão do TCDF que determinou a suspensão\": \"DECISAO_TCDF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"contratos_filtrados_v2\"\n",
    "path_data = \"./parquets_labelbox_data/\"\n",
    "base_path_samples = \"../atos_revisados/samples_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../atos_revisados/samples_3/contratos_filtrados_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158923/575440670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpath_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../atos_revisados/samples_3/contratos_filtrados_v2'"
     ]
    }
   ],
   "source": [
    "os.mkdir(base_path_samples + dataset)\n",
    "path_samples = base_path_samples + dataset + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_samples = base_path_samples + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data = []\n",
    "atos_data_text = []\n",
    "\n",
    "for arquivo in os.listdir(path_data):\n",
    "    if \".parquet\" in arquivo:\n",
    "        file_path = path_data + arquivo\n",
    "        file_df = pd.read_parquet(file_path)\n",
    "\n",
    "        if \"data_text\" in arquivo:\n",
    "            atos_data_text.append(file_df)\n",
    "        else:\n",
    "            atos_data.append(file_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df = pd.concat(atos_data, ignore_index=True)\n",
    "atos_data_text_df = pd.concat(atos_data_text, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar texto\n",
    "atos_data_text_df[\"treated_text\"] = clean_text_dodfs(atos_data_text_df[\"text\"])\n",
    "atos_data_text_df[\"treated_text\"] = atos_data_text_df.apply(lambda row: clean_text_by_word(row[\"treated_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbcet AVISO DE LICITAÇÃO xxecet\n",
      "xxbcet PREGÃO ELETRÔNICO (SRP) Nº 02/2021 xxecet\n",
      "xxbcet (AMPLA CONCORRÊNCIA) xxecet\n",
      "O Distrito Federal, representado pela Secretaria de Estado da A gricultura, A bastecimento\n",
      "e Desenvolvimento Rural SEAGRI/DF toma público que realizará licitação do tipo\n",
      "-\n",
      "xxeob\n",
      "\n",
      "xxbob\n",
      "MENOR PREÇO, na modalidade de PREGÃO na forma ELETRÔNICA, por meio de\n",
      "Sistema de Registro de Preços, com previsão de abertura do certame para 21/01/2021, às\n",
      "09:30 HS, Processo nº 00070-00004150/2020-93 (SEI). OBJETO: A presente licitação\n",
      "tem como objeto, Registro de Preços para a eventual aquisição de tratores agrícolas de no\n",
      "mínimo 120 e 140 cvs a fim de atender a Secretaria de Estado da Agricultura,\n",
      "Abastecimento e Desenvolvimento Rural SEAGRI, de acordo com o detalhamento\n",
      "xxbcet - xxecet\n",
      "descrito no item 3 do Termo de Referência, Anexo I do Edital e demais obrigações e\n",
      "informações constantes dos Anexos do Edital, com valor Total estimado de R$\n",
      "1.346.049,80 (um milhão, trezentos e quarenta e seis mil quarenta e nove reais e oitenta\n",
      "centavos). O Edital poderá ser retiraddo a partiir da publicação no Portal\n",
      "WWwW.comprasgovernamentais.gov.br ou no portal da SEAGRI-DF, “Licitação”, a partir\n",
      "da sua publicação e/ou divulgação.\n",
      "xxbcet Brasília/DF, 04 de janeiro de 2021 xxecet\n",
      "xxbcet NATANAEL FELIX DOS SANTOS xxecet\n",
      "xxbcet Pregoeiro xxecet\n",
      "xxeo\n"
     ]
    }
   ],
   "source": [
    "print(atos_data_text_df.iloc[3][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO (SRP) Nº 02/2021 (AMPLA CONCORRÊNCIA) O Distrito Federal, representado pela Secretaria de Estado da A gricultura, A bastecimento e Desenvolvimento Rural SEAGRI/DF toma público que realizará licitação do tipo MENOR PREÇO, na modalidade de PREGÃO na forma ELETRÔNICA, por meio de Sistema de Registro de Preços, com previsão de abertura do certame para 21/01/2021, às 09:30 HS, Processo nº 00070-00004150/2020-93 (SEI). OBJETO: A presente licitação tem como objeto, Registro de Preços para a eventual aquisição de tratores agrícolas de no mínimo 120 e 140 cvs a fim de atender a Secretaria de Estado da Agricultura, Abastecimento e Desenvolvimento Rural SEAGRI, de acordo com o detalhamento descrito no item 3 do Termo de Referência, Anexo I do Edital e demais obrigações e informações constantes dos Anexos do Edital, com valor Total estimado de R$ 1.346.049,80 (um milhão, trezentos e quarenta e seis mil quarenta e nove reais e oitenta centavos). O Edital poderá ser retiraddo a partiir da publicação no Portal WWwW.comprasgovernamentais.gov.br ou no portal da SEAGRI-DF, “Licitação”, a partir da sua publicação e/ou divulgação. Brasília/DF, 04 de janeiro de 2021 NATANAEL FELIX DOS SANTOS Pregoeiro\n"
     ]
    }
   ],
   "source": [
    "print(atos_data_text_df.iloc[3][\"treated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispensa de inexigibilidade e dispensa de licitação podem ser agrupados em um único rótulo de identificação\n",
    "atos_data_df[\"titulo_entidade\"] = atos_data_df[\"titulo_entidade\"].replace(\"Dispensa de inexigibilidade\", \"Identificação de dispensa\")\n",
    "atos_data_df[\"titulo_entidade\"] = atos_data_df[\"titulo_entidade\"].replace(\"Dispensa de licitação\", \"Identificação de dispensa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_atos = {\n",
    "    \"extrato_de_aditamento_contratual\": \"aviso_de_aditamento_contratual\",\n",
    "    \"aviso_de_anulacao_e_revogacao\": \"aviso_de_revogacao_anulacao_de_licitacao\"\n",
    "}\n",
    "\n",
    "atos_data_df[\"ato\"] = atos_data_df[\"ato\"].replace(rep_atos)\n",
    "atos_data_text_df[\"ato\"] = atos_data_text_df[\"ato\"].replace(rep_atos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df[\"ner_token\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"extrato_de_contrato_ou_convenio\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"ato\"].isin([\"extrato_de_contrato_ou_convenio\"]), \"titulo_entidade\"].replace(ner_tokens_extrato_contrato)\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_aditamento_contratual\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_aditamento_contratual\"]), \"titulo_entidade\"].replace(ner_tokens_aditamento_contratual)\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_licitacao\"]), \"titulo_entidade\"].replace(ner_tokens_aviso_licitacao)\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_revogacao_anulacao_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_revogacao_anulacao_de_licitacao\"]), \"titulo_entidade\"].replace(ner_tokens_aviso_revogacao)\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_suspensao_de_licitacao\"]), \"ner_token\"] = atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_suspensao_de_licitacao\"]), \"titulo_entidade\"].replace(ner_tokens_aviso_suspensao_licitacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"extrato_de_contrato_ou_convenio\"]) & ~atos_data_df[\"ner_token\"].isin(ner_tokens_extrato_contrato.values()), \"ner_token\"] = \"\"\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_aditamento_contratual\"]) & ~atos_data_df[\"ner_token\"].isin(ner_tokens_aditamento_contratual.values()), \"ner_token\"] = \"\"\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_licitacao\"]) & ~atos_data_df[\"ner_token\"].isin(ner_tokens_aviso_licitacao.values()), \"ner_token\"] = \"\"\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_revogacao_anulacao_de_licitacao\"]) & ~atos_data_df[\"ner_token\"].isin(ner_tokens_aviso_revogacao.values()), \"ner_token\"] = \"\"\n",
    "atos_data_df.loc[atos_data_df[\"ato\"].isin([\"aviso_de_suspensao_de_licitacao\"]) & ~atos_data_df[\"ner_token\"].isin(ner_tokens_aviso_suspensao_licitacao.values()), \"ner_token\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_erros = atos_data_df.loc[atos_data_df[\"ner_token\"] == \"\", \"arquivo_rast\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df = atos_data_df[~atos_data_df[\"arquivo_rast\"].isin(arquivos_erros)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_text_df = atos_data_text_df[~atos_data_text_df[\"arquivo_rast\"].isin(arquivos_erros)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os atos com base em tratamento específico (pegar só aditamento, só extrato, geral)\n",
    "filt_atos_data_df = specific_parse(atos_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokenized_texts = get_tokenized_text_lines(filt_atos_data_df, atos_data_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokenized_texts[\"treated_text\"] = full_tokenized_texts[\"tokenized_text\"].apply(lambda row: \" \".join([w.split()[0] for w in row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert full_tokenized_texts[\"arquivo_rast\"].duplicated().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extrato_de_contrato_ou_convenio             4381\n",
       "aviso_de_aditamento_contratual              1780\n",
       "aviso_de_licitacao                          1699\n",
       "aviso_de_revogacao_anulacao_de_licitacao      53\n",
       "aviso_de_suspensao_de_licitacao               33\n",
       "Name: ato, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atos_data_df[\"ato\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviso_de_aditamento_contratual              463\n",
       "extrato_de_contrato_ou_convenio             442\n",
       "aviso_de_licitacao                          235\n",
       "aviso_de_revogacao_anulacao_de_licitacao     16\n",
       "aviso_de_suspensao_de_licitacao              12\n",
       "Name: ato, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atos_data_text_df[\"ato\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aviso_de_aditamento_contratual              463\n",
       "extrato_de_contrato_ou_convenio             442\n",
       "aviso_de_licitacao                          235\n",
       "aviso_de_revogacao_anulacao_de_licitacao     16\n",
       "aviso_de_suspensao_de_licitacao              12\n",
       "Name: ato, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atos_data_text_df[\"ato\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tokenized_texts = full_tokenized_texts[[\"arquivo_rast\", \"tokenized_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "atos_data_df.to_parquet(\"/home/thais/Documentos/Knedle/experiments/members/thais/contrato-licitações/estudo_crf/result/labelbox_entidades.parquet\")\n",
    "atos_data_text_df.to_parquet(\"/home/thais/Documentos/Knedle/experiments/members/thais/contrato-licitações/estudo_crf/result/labelbox_atos.parquet\")\n",
    "full_tokenized_texts.to_parquet(\"/home/thais/Documentos/Knedle/experiments/members/thais/contrato-licitações/estudo_crf/result/tokenized_texts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação entre os dados precisa ser feita baseada em textos, e não em palavras\n",
    "train_set_files = full_tokenized_texts[\"arquivo_rast\"].sample(frac=0.8)\n",
    "not_train_set_files = full_tokenized_texts.drop(train_set_files.index)\n",
    "\n",
    "test_set_files = not_train_set_files[\"arquivo_rast\"].sample(frac=0.5)\n",
    "valid_set_files = not_train_set_files[\"arquivo_rast\"].drop(test_set_files.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_df = full_tokenized_texts.loc[train_set_files.index].reset_index(drop=True)\n",
    "test_set_df = full_tokenized_texts.loc[test_set_files.index].reset_index(drop=True)\n",
    "valid_set_df = full_tokenized_texts.loc[valid_set_files.index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISÃO GERAL DOS CONJUNTOS:\n",
      "Conjunto de treinamento: 934\n",
      "Conjunto de teste: 117\n",
      "Conjunto de validação: 117\n"
     ]
    }
   ],
   "source": [
    "print(\"VISÃO GERAL DOS CONJUNTOS:\")\n",
    "print(\"Conjunto de treinamento: {}\".format(len(train_set_df)))\n",
    "print(\"Conjunto de teste: {}\".format(len(test_set_df)))\n",
    "print(\"Conjunto de validação: {}\".format(len(valid_set_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_texts = list(train_set_df[\"tokenized_text\"])\n",
    "test_tokenized_texts = list(test_set_df[\"tokenized_text\"])\n",
    "valid_tokenized_texts = list(valid_set_df[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../atos_revisados/samples_3/contratos_filtrados_v2/./result/_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158923/2794151662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tokenized_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../atos_revisados/samples_3/contratos_filtrados_v2/./result/_train.txt'"
     ]
    }
   ],
   "source": [
    "with open(path_samples + \"/\" + dataset + \"_train.txt\", \"w\") as f:\n",
    "    for group in train_tokenized_texts:\n",
    "        for line in group:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write('\\n')\n",
    "    \n",
    "with open(path_samples + \"/\" + dataset + \"_testa.txt\", \"w\") as f:\n",
    "    for group in valid_tokenized_texts:\n",
    "        for line in group:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write('\\n')\n",
    "    \n",
    "with open(path_samples + \"/\" + dataset + \"_testb.txt\", \"w\") as f:\n",
    "    for group in test_tokenized_texts:\n",
    "        for line in group:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquivo_rast</th>\n",
       "      <th>text</th>\n",
       "      <th>ato</th>\n",
       "      <th>dodf</th>\n",
       "      <th>treated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_aviso_de_licitacao_DODF_010_15-01-2021.txt</td>\n",
       "      <td>xxbcet AVISO DE LICITAÇÃO xxecet\\nxxbcet PREGÃ...</td>\n",
       "      <td>aviso_de_licitacao</td>\n",
       "      <td>DODF_010_15-01-2021</td>\n",
       "      <td>AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO Nº 01/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_aviso_de_licitacao_DODF_093_20-05-2019.txt</td>\n",
       "      <td>xxbcet AVISO DE LICITAÇÃO xxecet\\r\\nxxbcet PRE...</td>\n",
       "      <td>aviso_de_licitacao</td>\n",
       "      <td>DODF_093_20-05-2019</td>\n",
       "      <td>AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO Nº 50/201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_aviso_de_licitacao_DODF_010_15-01-2021.txt</td>\n",
       "      <td>xxbcet PREGÃO ELETRÔNICO Nº 14/2021 xxecet\\nPr...</td>\n",
       "      <td>aviso_de_licitacao</td>\n",
       "      <td>DODF_010_15-01-2021</td>\n",
       "      <td>PREGÃO ELETRÔNICO Nº 14/2021 Processo: 092.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_aviso_de_licitacao_DODF_002_05-01-2021.txt</td>\n",
       "      <td>xxbcet AVISO DE LICITAÇÃO xxecet\\nxxbcet PREGÃ...</td>\n",
       "      <td>aviso_de_licitacao</td>\n",
       "      <td>DODF_002_05-01-2021</td>\n",
       "      <td>AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO (SRP) Nº ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_extrato_de_contrato_ou_convenio_DODF_004_07-...</td>\n",
       "      <td>xxbcet EXTRATO DE CONTRATO SIMPLIFICADO Nº 6/2...</td>\n",
       "      <td>extrato_de_contrato_ou_convenio</td>\n",
       "      <td>DODF_004_07-01-2016</td>\n",
       "      <td>EXTRATO DE CONTRATO SIMPLIFICADO Nº 6/2015 Esp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        arquivo_rast  \\\n",
       "0       0_aviso_de_licitacao_DODF_010_15-01-2021.txt   \n",
       "1       0_aviso_de_licitacao_DODF_093_20-05-2019.txt   \n",
       "2       2_aviso_de_licitacao_DODF_010_15-01-2021.txt   \n",
       "3       6_aviso_de_licitacao_DODF_002_05-01-2021.txt   \n",
       "4  9_extrato_de_contrato_ou_convenio_DODF_004_07-...   \n",
       "\n",
       "                                                text  \\\n",
       "0  xxbcet AVISO DE LICITAÇÃO xxecet\\nxxbcet PREGÃ...   \n",
       "1  xxbcet AVISO DE LICITAÇÃO xxecet\\r\\nxxbcet PRE...   \n",
       "2  xxbcet PREGÃO ELETRÔNICO Nº 14/2021 xxecet\\nPr...   \n",
       "3  xxbcet AVISO DE LICITAÇÃO xxecet\\nxxbcet PREGÃ...   \n",
       "4  xxbcet EXTRATO DE CONTRATO SIMPLIFICADO Nº 6/2...   \n",
       "\n",
       "                               ato                 dodf  \\\n",
       "0               aviso_de_licitacao  DODF_010_15-01-2021   \n",
       "1               aviso_de_licitacao  DODF_093_20-05-2019   \n",
       "2               aviso_de_licitacao  DODF_010_15-01-2021   \n",
       "3               aviso_de_licitacao  DODF_002_05-01-2021   \n",
       "4  extrato_de_contrato_ou_convenio  DODF_004_07-01-2016   \n",
       "\n",
       "                                        treated_text  \n",
       "0  AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO Nº 01/202...  \n",
       "1  AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO Nº 50/201...  \n",
       "2  PREGÃO ELETRÔNICO Nº 14/2021 Processo: 092.041...  \n",
       "3  AVISO DE LICITAÇÃO PREGÃO ELETRÔNICO (SRP) Nº ...  \n",
       "4  EXTRATO DE CONTRATO SIMPLIFICADO Nº 6/2015 Esp...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = \"/home/thais/Documentos/Knedle/experiments/members/thais/contrato-licitações/estudo_crf/result/labelbox_atos.parquet\"\n",
    "texts = \"/home/thais/Documentos/Knedle/experiments/members/thais/contrato-licitações/estudo_crf/result/tokenized_texts.parquet\"\n",
    "df1 = pd.read_parquet(entities)\n",
    "df2 = pd.read_parquet(texts)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
