{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = KeyedVectors.load_word2vec_format(\"cbow_s100.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionary with index of words from pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-c5ce54884470>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  for j in emb.wv.index2word:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866822\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for j in emb.wv.index2word:\n",
    "    num = emb.vocab[j].index\n",
    "    word = unicodedata.normalize('NFKD', j).encode('ascii', 'ignore').decode('utf8')\n",
    "    dic[word] = emb.vocab[j].index\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the LSTM-CRF model\n",
    "\n",
    "All words in a sentence pass through the LSTM and output of hidden layers are used as the encoding passed to the CRF for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CRF(nn.Module):\n",
    "    def __init__(self, embedding_dim, word2idx_dict, num_tags, hidden_dim):\n",
    "        super(LSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = 100\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_tags = num_tags\n",
    "        self.word2idx_dict = word2idx_dict\n",
    "        # Dictionaries to convert tags (labels) to indexes (integers) and vice-versa\n",
    "        self.tag2idx_dict = {}\n",
    "        self.idx2tag_dict = {}\n",
    "        \n",
    "        # Defining all the nn layers\n",
    "        self.embed_layer  = nn.Embedding.from_pretrained(torch.FloatTensor(emb.vectors))\n",
    "        self.embed_layer.weight[0] = 0\n",
    "        self.word_LSTM_layer   = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.sent_LSTM_layer   = nn.LSTM(hidden_dim, hidden_dim//2, num_layers=1, batch_first=True)\n",
    "        self.linear_layer      = nn.Linear(hidden_dim//2, num_tags)\n",
    "        self.crf_layer         = CRF(num_tags, batch_first=True)\n",
    "        \n",
    "    def preprocess_input(self, batch):\n",
    "        \"\"\" \n",
    "        Method to preprocess the sentences switching words for their embedding indexes and padding sentences\n",
    "        input: sequence of sentences to be preprocessed | \n",
    "               shape: (batch_size)x(len_sequence)x(len_sentence)\n",
    "        output: Preprocessed batch of sequences of sentences and mask for the CRF layer (ignore padded inputs)\n",
    "        \"\"\"\n",
    "        # Find sentence with max length\n",
    "        max_len = 0\n",
    "        for seq in batch:\n",
    "            for sentence in seq:\n",
    "                max_len = max(max_len, len(sentence))\n",
    "                \n",
    "        # Pad sentences according to max_len        \n",
    "        for i in range(len(batch)):\n",
    "            for j in range(len(batch[i])):\n",
    "                for k in range(len(batch[i][j])):\n",
    "                    if batch[i][j][k] in self.word2idx_dict:\n",
    "                        batch[i][j][k] = self.word2idx_dict[batch[i][j][k]]\n",
    "                    else:\n",
    "                        batch[i][j][k] = 0\n",
    "                for k in range(max_len - len(batch[i][j])):\n",
    "                    batch[i][j].append(0)\n",
    "        \n",
    "        # Find sequence of sentences with max length\n",
    "        max_seq = 0\n",
    "        for seq in batch:\n",
    "            max_seq = max(max_seq, len(seq))\n",
    "            \n",
    "        # Create mask for the crf to ignore padded part of sequences\n",
    "        mask_pad = np.ones((len(batch), max_seq))\n",
    "        \n",
    "        # Pad sequence of sentences\n",
    "        pad_sentence = [1 for i in range(max_len)]\n",
    "        for i in range(len(batch)):\n",
    "            idx = -1\n",
    "            for j in range(max_seq - len(batch[i])):\n",
    "                batch[i].append(pad_sentence)\n",
    "                mask_pad[i][idx] = 0\n",
    "                idx -= 1\n",
    "                \n",
    "        return torch.LongTensor(batch), torch.ByteTensor(mask_pad)\n",
    "        \n",
    "    def preprocess_label(self, batch_y):\n",
    "        \"\"\" \n",
    "        Method to preprocess the labels switching words for their one-hot encoding and padding sentences\n",
    "        input: sequence of labels to be preprocessed | \n",
    "               shape: (batch_size)x(len_seq)\n",
    "        output: Preprocessed batch of labels\n",
    "        \"\"\"\n",
    "        # Creates tag to index dictionary\n",
    "        tag2idx = {}\n",
    "        for seq in batch_y:\n",
    "            for tag in seq:\n",
    "                if tag not in tag2idx:\n",
    "                    tag2idx[tag] = len(tag2idx)\n",
    "                    \n",
    "        # Creates index to tag dictionary\n",
    "        idx2tag = {}\n",
    "        for tag in tag2idx:\n",
    "            idx2tag[tag2idx[tag]] = tag\n",
    "        \n",
    "        self.tag2idx_dict = tag2idx\n",
    "        self.idx2tag_dict = idx2tag\n",
    "        \n",
    "        # Sub tags for their index\n",
    "        for i in range(len(batch_y)):\n",
    "            for j in range(len(batch_y[i])):\n",
    "                batch_y[i][j] = tag2idx[batch_y[i][j]]\n",
    "        \n",
    "        # Pad sequence of tags\n",
    "        max_len = 0\n",
    "        for i in batch_y:\n",
    "            max_len = max(max_len, len(i))\n",
    "        for i in range(len(batch_y)):\n",
    "            for j in range(max_len -len(batch_y[i])):\n",
    "                batch_y[i].append(-1)\n",
    "                \n",
    "        return torch.LongTensor(batch_y)\n",
    "    \n",
    "    def forward(self, batch_input, batch_tags, mask_pad):\n",
    "        \"\"\"\n",
    "        Method to compute the forward pass of the LSTM_CRF model\n",
    "        Input: (x) shape:        (batch_size) x (sequence_length) x (sentence_length)\n",
    "               (y) shape:        (batch_size) x (sequence_length)\n",
    "               (mask_pad) shape: (batch_size) x (sequence_length)\n",
    "        output: log_likelihood  of the probability of the expected sequence of tags\n",
    "        \"\"\"\n",
    "        batch_size = batch_input.shape[0]\n",
    "        sequence_pad_size = batch_input.shape[1]\n",
    "        sentence_pad_size = batch_input.shape[2]\n",
    "        # Embedding Layer\n",
    "        emb_out = model.embed_layer(batch_input)\n",
    "        # Word level LSTM layer\n",
    "        word_lstm_out, (hn, cn) = model.word_LSTM_layer(emb_out.view(batch_size*sequence_pad_size, sentence_pad_size, 100))\n",
    "        # Sentence level LSTM layer\n",
    "        sent_lstm_out, (hn, cn) = model.sent_LSTM_layer(hn.view(batch_size, sequence_pad_size, 128))\n",
    "        # Linear (fully-connected) layer\n",
    "        lin_out = model.linear_layer(sent_lstm_out.reshape(batch_size * sequence_pad_size, 64))\n",
    "        # CRF layer\n",
    "        return model.crf_layer(lin_out.view(batch_size, sequence_pad_size, self.num_tags), batch_tags)\n",
    "\n",
    "    def fit(self, x, y, epoch):\n",
    "        \"\"\" \n",
    "        Method to train the LSTM_CRF model \n",
    "        Input: (x) shape: (number of batches) x (batch_size) x (sequence_length) x (sentence_length)\n",
    "               (y) shape: (number of batches) x (batch_size) x (sequence_length)\n",
    "        output: \n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "        masks = []\n",
    "        for i in range(len(x)):\n",
    "            x[i], mask_pad = self.preprocess_input(x[i])\n",
    "            y[i] = self.preprocess_label(y[i])\n",
    "            masks.append(mask_pad)\n",
    "        for it in range(epoch):\n",
    "            for batch_x, batch_y, mask in zip(x, y, masks):\n",
    "                self.zero_grad()\n",
    "                loss = -self.forward(batch_x, batch_y, mask)\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    def predict(self, sequence):\n",
    "        \"\"\" \n",
    "        Method to predict segmentation tags\n",
    "        Input: sequence - shape:(batch_size)x(sequence_size)x(sentence_size)\n",
    "        output: Predicted tags - shape: (batch_size)x(sequence_size)\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get indexes for word embeddings and pad both sentences and sequences (not yet)\n",
    "            sequence, mask_pad = self.preprocess_input(sequence)\n",
    "            batch_size = sequence.shape[0]\n",
    "            sequence_pad_size = sequence.shape[1]\n",
    "            sentence_pad_size = sequence.shape[2]\n",
    "            # Embedding Layer\n",
    "            emb_out = model.embed_layer(sequence)\n",
    "            # Word level LSTM layer\n",
    "            word_lstm_out, (hn, cn) = model.word_LSTM_layer(emb_out.view(batch_size*sequence_pad_size, sentence_pad_size, 100))\n",
    "            # Sentence level LSTM layer\n",
    "            sent_lstm_out, (hn, cn) = model.sent_LSTM_layer(hn.view(batch_size, sequence_pad_size, 128))\n",
    "            # Linear (fully-connected) layer\n",
    "            lin_out = model.linear_layer(sent_lstm_out.reshape(batch_size * sequence_pad_size, 64))\n",
    "            print(lin_out.view(batch_size, sequence_pad_size, self.num_tags).shape)\n",
    "            # CRF layer\n",
    "            return model.crf_layer.decode(lin_out.view(batch_size, sequence_pad_size, self.num_tags), mask=mask_pad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_CRF(embedding_dim=100, word2idx_dict=dic, num_tags=5, hidden_dim=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes a partir daki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[['quem', 'disse', 'que', 'eu', 'nao', 'sei', 'nadar'],\n",
       "    ['cara', 'tu', 'nao', 'sabe', 'o', 'que', 'eu', 'falei'],\n",
       "    ['eu', 'gosto', 'de', 'jogar', 'tenis'],\n",
       "    ['amanha', 'eu', 'vou', 'correr'],\n",
       "    ['nao', 'quero', 'voltar', 'no', 'tempo']],\n",
       "   [['ola', 'hoje', 'eu', 'quero', 'nadar'],\n",
       "    ['cara', 'tu', 'nao', 'sabe', 'o', 'que', 'eu', 'falei'],\n",
       "    ['eu', 'gosto', 'de', 'jogar', 'tenis']],\n",
       "   [['ola', 'hoje', 'eu', 'quero', 'nadar'],\n",
       "    ['quem', 'disse', 'que', 'eu', 'nao', 'sei', 'nadar'],\n",
       "    ['eu', 'gosto', 'de', 'jogar', 'tenis']],\n",
       "   [['ola', 'hoje', 'eu', 'quero', 'nadar'],\n",
       "    ['quem', 'disse', 'que', 'eu', 'nao', 'sei', 'nadar']]],\n",
       "  [[['ola', 'hoje', 'eu', 'quero', 'nadar'],\n",
       "    ['cara', 'tu', 'nao', 'sabe', 'o', 'que', 'eu', 'falei'],\n",
       "    ['eu', 'gosto', 'de', 'jogar', 'tenis']],\n",
       "   [['ola', 'hoje', 'eu', 'quero', 'nadar'],\n",
       "    ['quem', 'disse', 'que', 'eu', 'nao', 'sei', 'nadar']]],\n",
       "  [[['quem', 'disse', 'que', 'eu', 'nao', 'sei', 'nadar'],\n",
       "    ['cara', 'tu', 'nao', 'sabe', 'o', 'que', 'eu', 'falei'],\n",
       "    ['eu', 'gosto', 'de', 'jogar', 'tenis'],\n",
       "    ['amanha', 'eu', 'vou', 'correr'],\n",
       "    ['nao', 'quero', 'voltar', 'no', 'tempo']]]],\n",
       " [[['B', 'I', 'O', 'O', 'O'], ['B', 'O', 'O'], ['O', 'O', 'O'], ['B', 'I']],\n",
       "  [['B', 'O', 'O'], ['B', 'I']],\n",
       "  [['B', 'I', 'O', 'O', 'O']]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = [\n",
    "    [\"quem\", \"disse\", \"que\", \"eu\", \"nao\", \"sei\", \"nadar\"],\n",
    "    [\"cara\", \"tu\", \"nao\", \"sabe\", \"o\", \"que\", \"eu\", \"falei\"],\n",
    "    [\"eu\", \"gosto\", \"de\", \"jogar\", \"tenis\"], \n",
    "    [\"amanha\", \"eu\", \"vou\", \"correr\"],\n",
    "    [\"nao\", \"quero\", \"voltar\", \"no\", \"tempo\"]\n",
    "]\n",
    "label1 = [\n",
    "    \"B\",\n",
    "    \"I\", \n",
    "    \"O\", \n",
    "    \"O\",\n",
    "    \"O\"\n",
    "]\n",
    "sample2 = [\n",
    "    [\"ola\", \"hoje\", \"eu\", \"quero\", \"nadar\"],\n",
    "    [\"cara\", \"tu\", \"nao\", \"sabe\", \"o\", \"que\", \"eu\", \"falei\"],\n",
    "    [\"eu\", \"gosto\", \"de\", \"jogar\", \"tenis\"]\n",
    "]\n",
    "label2 = [\n",
    "    \"B\", \n",
    "    \"O\",\n",
    "    \"O\"\n",
    "]\n",
    "sample3 = [\n",
    "    [\"ola\", \"hoje\", \"eu\", \"quero\", \"nadar\"],\n",
    "    [\"quem\", \"disse\", \"que\", \"eu\", \"nao\", \"sei\", \"nadar\"],\n",
    "    [\"eu\", \"gosto\", \"de\", \"jogar\", \"tenis\"]\n",
    "]\n",
    "label3 = [ \n",
    "    \"O\",\n",
    "    \"O\",\n",
    "    \"O\"\n",
    "]\n",
    "sample4 = [\n",
    "    [\"ola\", \"hoje\", \"eu\", \"quero\", \"nadar\"],\n",
    "    [\"quem\", \"disse\", \"que\", \"eu\", \"nao\", \"sei\", \"nadar\"]\n",
    "]\n",
    "label4 = [\n",
    "    \"B\",\n",
    "    \"I\"\n",
    "]\n",
    "sample = [[sample1, sample2, sample3, sample4], [sample2, sample4], [sample1]]\n",
    "labels = [[label1, label2, label3, label4], [label2, label4], [label1]]\n",
    "sample, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.4487, grad_fn=<NegBackward>)\n",
      "tensor(15.8243, grad_fn=<NegBackward>)\n",
      "tensor(7.5577, grad_fn=<NegBackward>)\n",
      "tensor(30.8805, grad_fn=<NegBackward>)\n",
      "tensor(15.0480, grad_fn=<NegBackward>)\n",
      "tensor(7.0387, grad_fn=<NegBackward>)\n",
      "tensor(29.5492, grad_fn=<NegBackward>)\n",
      "tensor(14.3930, grad_fn=<NegBackward>)\n",
      "tensor(6.5929, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "model.fit(sample, labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 2, 2]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 1, 2, 1], [1, 2, 1, 2, 1], [1, 2, 1, 2, 1], [1, 2, 1, 2, 1]]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
