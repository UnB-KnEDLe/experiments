{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notacao IOB para NER (preprocess 2/2)\n",
    "\n",
    "Notebook para incluir labels de entidades no esquema IOB para cada trecho de texto extraido em extract_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"verif_data.csv\")\n",
    "data = pd.read_csv(\"verif_dataV1.csv\")\n",
    "data['labels'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REF_ANOMES', 'DATA_DODF', 'NUM_DODF', 'PAGINA_DODF', 'TIPO_DODF',\n",
       "       'ATO', 'COD_EMPRESA', 'EMPRESA_ATO', 'COD_MATRICULA_ATO',\n",
       "       'COD_MATRICULA_SIGRH', 'CPF', 'NOME_ATO', 'NOME_SIGRH', 'CARGO',\n",
       "       'CLASSE', 'PADRAO', 'QUADRO', 'PROCESSO', 'FUND_LEGAL', 'text',\n",
       "       'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colunas a serem utilizadas: 'ATO', 'EMPRESA_ATO', 'COD_MATRICULA_ATO', 'CPF', 'NOME_ATO', 'CARGO', 'CLASSE',                                   'PADRAO', 'QUADRO', 'PROCESSO', 'FUND_LEGAL'\n",
    "\n",
    "Colunas descartadas: 'Unnamed: 0', 'REF_ANOMES', 'DATA_DODF', 'NUM_DODF', 'PAGINA_DODF',\n",
    "       'TIPO_DODF', 'COD_EMPRESA', 'COD_MATRICULA_SIGRH', 'NOME_SIGRH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[ \n",
    "    'REF_ANOMES', \n",
    "#     'DATA_DODF', \n",
    "    'NUM_DODF', \n",
    "    'PAGINA_DODF', \n",
    "    'TIPO_DODF', \n",
    "    'COD_EMPRESA', \n",
    "    'COD_MATRICULA_SIGRH', \n",
    "    'NOME_SIGRH', \n",
    "    'CPF'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATA_DODF', 'ATO', 'EMPRESA_ATO', 'COD_MATRICULA_ATO', 'NOME_ATO',\n",
       "       'CARGO', 'CLASSE', 'PADRAO', 'QUADRO', 'PROCESSO', 'FUND_LEGAL', 'text',\n",
       "       'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOS TERMOS DO ARTIGO 3º, INCISOS I, II E III, E PARAGRAFO UNICO DA EMENDA CONSTITUCIONAL N.º 47 DE 05/07/2005, COMBINADO COM O ARTIGO 44 DA LEI COMPLEMENTAR N.º 769, DE 30/06/2008, COM A VANTAGEM PESSOAL PREVISTA NO ARTIGO 5º DA LEI Nº 4.584, DE 08/07/2011 \n",
      "\n",
      "\n",
      "NOS TERMOS DO ARTIGO 3o, INCISOS I, II E III, E PARAGRAFO UNICO DA EMENDA CONSTITUCIONAL N.o 47 DE 05/07/2005, COMBINADO COM O ARTIGO 44 DA LEI COMPLEMENTAR N.o 769, DE 30/06/2008, COM A VANTAGEM PESSOAL PREVISTA NO ARTIGO 5o DA LEI No 4.584, DE 08/07/2011\n"
     ]
    }
   ],
   "source": [
    "print(data['FUND_LEGAL'][0], '\\n\\n')\n",
    "\n",
    "# for row in range(len(data)):\n",
    "#     for col in data.drop(columns=['text', 'labels']).columns:\n",
    "#         if pd.notna(data[col][row]):\n",
    "#             data.loc[row, col] = str(data.loc[row, col]).replace('º', 'o')\n",
    "\n",
    "for row in range(len(data)):\n",
    "    for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns:\n",
    "        if pd.notna(data.loc[row, col]):\n",
    "            data.loc[row, col] = unicodedata.normalize('NFKD', str(data.loc[row, col])).encode('ascii', 'ignore').decode('utf8')\n",
    "\n",
    "print(data['FUND_LEGAL'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 - Funcoes para identificar entidades e anotar no padrao IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regex(data, col, idx):\n",
    "    entity = str(data.loc[idx, col])\n",
    "    re_entity = \"\"\n",
    "    if col == \"COD_MATRICULA_ATO\":\n",
    "        while entity[0] == '0':\n",
    "            entity = entity[1:]\n",
    "        re_entity += '[0oO]*?'\n",
    "    for i in entity:\n",
    "        if (i >= 'a' and i <= 'z') or (i>='A' and i<='Z'):\n",
    "            re_entity += f\"[{i.lower()}{i.upper()}]\" + \"[-,.\\s\\\"]*?\"\n",
    "        elif i == '(' or i == ')':\n",
    "            re_entity += '\\\\' + i + \"[-,.\\s\\\"]*?\"\n",
    "        else:\n",
    "            re_entity += i + \"[-,.\\s\\\"]*?\"\n",
    "    return re_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOBify_text(text, entities):\n",
    "    labels = [\"O\" for _ in range(len(text.split()))]\n",
    "    word_start_position = []\n",
    "    number_of_word = []\n",
    "    for i in range(len(text)):\n",
    "        if (i == 0):\n",
    "            if (text[i] == ' '):\n",
    "                continue\n",
    "            else:\n",
    "                number_of_word.append(len(word_start_position))\n",
    "                word_start_position.append(i)\n",
    "        elif text[i] != ' ' and text[i-1] == ' ':\n",
    "            number_of_word.append(len(word_start_position))\n",
    "            word_start_position.append(i)\n",
    "    i = 0\n",
    "    for entity in entities:\n",
    "        entity_begin = entity_end = -1\n",
    "        # Find initial position of entity\n",
    "        if entity[0] in word_start_position:\n",
    "            entity_begin = word_start_position.index(entity[0])\n",
    "        # Find final position of entity\n",
    "        for pos, idx in zip(word_start_position, number_of_word):\n",
    "            if pos > entity[1]:\n",
    "                entity_end = idx-1\n",
    "                break\n",
    "        if entity_end == -1:\n",
    "            entity_end = number_of_word[-1]\n",
    "            \n",
    "        if entity_begin != -1:\n",
    "            for i in range(entity_begin, entity_end+1):\n",
    "                if i==entity_begin:\n",
    "                    labels[i] = \"B-\"+entity[2]\n",
    "                else:\n",
    "                    labels[i] = \"I-\"+entity[2]\n",
    "    return labels\n",
    "                \n",
    "def find_entities(data, idx):\n",
    "    list_entities = []\n",
    "    for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns:\n",
    "        if pd.notna(data[col][idx]):\n",
    "            re_entity = get_regex(data, col, idx)\n",
    "            aux = re.search(re_entity, data['text'][idx])\n",
    "            if aux:\n",
    "                found_entities[col]  += 1\n",
    "                list_entities.append([aux.span()[0], aux.span()[1], col])\n",
    "            else:\n",
    "                missed_entities[col][0] += 1\n",
    "                missed_entities[col][1].append(idx)\n",
    "    return list_entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Identificando entidades e anotando-as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ATO: 5167 \t\t Missed ATO: 2\n",
      "Found EMPRESA_ATO: 2206 \t\t Missed EMPRESA_ATO: 2963\n",
      "Found COD_MATRICULA_ATO: 5157 \t\t Missed COD_MATRICULA_ATO: 12\n",
      "Found NOME_ATO: 5165 \t\t Missed NOME_ATO: 4\n",
      "Found CARGO: 5162 \t\t Missed CARGO: 6\n",
      "Found CLASSE: 2383 \t\t Missed CLASSE: 39\n",
      "Found PADRAO: 4873 \t\t Missed PADRAO: 6\n",
      "Found QUADRO: 4908 \t\t Missed QUADRO: 44\n",
      "Found PROCESSO: 5169 \t\t Missed PROCESSO: 0\n",
      "Found FUND_LEGAL: 4568 \t\t Missed FUND_LEGAL: 600\n"
     ]
    }
   ],
   "source": [
    "found_entities  = {col: 0 for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns}\n",
    "missed_entities = {col: [0, []] for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns}\n",
    "\n",
    "for row in range(len(data)):\n",
    "    if pd.notna(data.loc[row, 'text']):\n",
    "        entities = find_entities(data, row)\n",
    "        entities.sort()\n",
    "        labels = IOBify_text(data.loc[row, 'text'], entities)\n",
    "        s = \"\"\n",
    "        for l in labels:\n",
    "            s += l + ' '\n",
    "        data.loc[row, 'labels'] = s\n",
    "\n",
    "for col in found_entities:\n",
    "    print(f\"Found {col}: {found_entities[col]}\", f\"\\t\\t Missed {col}: {missed_entities[col][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4 - Corrigindo entidades nao identificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados originais anotados\n",
    "data_og = pd.read_csv('TCDF_data/Atos_Aposentadoria_validados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\n",
      "\n",
      "Col:QUADRO -> [104, 138, 269, 270, 271, 272, 273, 280, 282, 526, 528, 529, 530, 531, 532, 571, 975, 976, 977, 978, 980, 981, 983, 984, 985, 987, 988, 3855, 3927, 4474, 4496, 4505, 4509, 4527, 4529, 4531, 4532, 4533, 4545, 4550, 4571, 5476, 5477, 5512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\\n\")\n",
    "for col in data.drop(columns=['text', 'labels']).columns:\n",
    "#     print(f\"Col:{col} -> {missed_entities[col][1]}\")\n",
    "#     if len(missed_entities[col][1]) <= 100:\n",
    "    if col == 'QUADRO':\n",
    "        print(f\"Col:{col} -> {missed_entities[col][1]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual de trechos de texto identificados erroneamente\n",
    "\n",
    "Trechos de texto que nao condizem com as entidades anotadas sao corrigidos aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matricula(DONE) | NOME(DONE) | CARGO(DONE) | CLASSE(DONE) | PADRAO(DONE) | QUADRO() | \n",
    "\n",
    "# Fix row 138\n",
    "data.loc[138, 'text'] = \"CONCEDER aposentadoria voluntaria com proventos integrais a servidora a seguir nominada: MARIA AUXILIADORA PE- REIRA, matricula 101.008-5, processo SEI n 00070- 00011305/2018-23, no cargo de Au- xiliar de Desenvolvimento e Fiscalizacao Agropecuaria, Classe Unica, Padrao X, do Quadro de Pessoal do Distrito Federal, com fundamento no Art. 6, incisos I, II, III e IV, da EC n 41/ 2003, combinado com o artigo 2 da EC n 47/2005, c/c a Lei Complementar no 769/08.\"\n",
    "\n",
    "# Fix row 481\n",
    "data.loc[481, 'text'] = \"CONCEDER APOSENTADORIA a IZAAC NEWTON DA SILVA, matricula 38.950-1, no Cargo de Professor de Educacao Basica, Padrao 22, Etapa IV, do Quadro de Pessoal do Distrito Federal, nos termos do artigo 6o da Emenda Constitucional no 41, de 31 de dezembro de 2003, combinado com o artigo 2o da Emenda Constitucional no 47, de 06 de julho de 2005. Processo 00080-00033434/2017-54.\"\n",
    "\n",
    "# Fix row 506\n",
    "data.loc[506, 'text'] = \"CONCEDER aposentadoria voluntaria com proventos integrais ao servidor a seguir nominado: AMISAEL GONCALVES BI- NACETT, matricula 100.453-0, processo SEI n 00070-00013097/2018-05, no cargo de Auxiliar de Desenvolvimento e Fiscalizacao Agropecuaria, Classe Unica, Padrao X, do Quadro de Pessoal do Distrito Federal, com fundamento no Art. 3, incisos I, II, III e paragrafo unico da EC no 47/2005, c/c a LC no 769/2008.\"\n",
    "data.loc[506, 'PROCESSO'] = \"00070-00013097/2018-05\"\n",
    "data.loc[506, 'CARGO'] = \"Auxiliar de Desenvolvimento e Fiscalizacao Agropecuaria\"\n",
    "\n",
    "# Fix row 537\n",
    "data.loc[537, 'text'] = \"CONCEDER APOSENTADORIA a VERA LUCIA FERREIRA DE SOUSA, matricula 40.787-9, no Cargo de Agente de Gestao Educacional/Servicos Gerais, Nivel 10, Padrao 02, Etapa III, do Quadro de Pessoal do Distrito Federal, nos termos do artigo 3o da Emenda Constitucional no 47, de 06 de julho de 2005 e o Paragrafo unico do mesmo artigo. Processo 0 0 0 8 0 - 0 0 0 0 3 4 3 2 / 2 0 1 8 - 11 .\"\n",
    "data.loc[537, 'PROCESSO'] = \"0 0 0 8 0 - 0 0 0 0 3 4 3 2 / 2 0 1 8 - 11\"\n",
    "\n",
    "#Fix row 571\n",
    "data.loc[571, 'text'] = \"CONCEDER APOSENTADORIA, nos termos do artigo 6o da Emenda Constitucional no 41/2003, combinado com o artigo 2o da Emenda Constitucional no 47/2005, combinados com o artigo 43, da Lei Complementar no 769, de 30/06/2008, a MARIA DE LOURDES SOUSA, matricula no 0143048-3, na Carreira de Assistencia Publica a Saude, no Cargo de Tecnico em Saude - TEC. LAB. HEMAT. E HEMOT, Primeira Classe, Padrao II, do Quadro de Pessoal da Secretaria de Estado de Saude do Distrito Federal. Lotacao: ADMC. Processo no 00060- 00247085/2017-21.\"\n",
    "\n",
    "# Fix row 2763\n",
    "data.loc[2763, 'text'] = \"APOSENTAR MARIA ESTER BATISTA DE MEDEIROS, matricula 204.859-0, no Cargo de Professor de Educacao Basica, Padrao 19, Etapa IV, do Quadro de Pessoal do Distrito Federal, nos termos do artigo 40, 1o, inciso I, da Constituicao da Republica Federativa do Brasil, na redacao dada pela Emenda Constitucional no 41, de 31 de dezembro de 2003, combinado com o artigo 6o-A da Emenda Constitucional no 41, de 31 de dezembro de 2003, incluido pela Emenda Constitucional no 70, de 29 de marco de 2012. Processo 00040-00015628/2019-89.\"\n",
    "\n",
    "# Fix row 5512\n",
    "data.loc[5512, 'text'] = \"APOSENTAR, nos termos do artigo 6o da Emenda Constitucional no 41/2003, combinado com o artigo 2o da Emenda Constitucional no 47/2005, combinados com o artigo 43, da Lei Complementar no 769, de 30/06/2008, a MARIA DE LOURDES SOUSA, matricula no 0143048-3, na Carreira de Assistencia Publica a Saude, no Cargo de Tecnico em Saude - TEC. LAB. HEMAT. E HEMOT, Primeira Classe, Padrao II, do Quadro de Pessoal da Secretaria de Estado de Saude do Distrito Federal. Lotacao: ADMC. Processo no 00060- 00247085/2017-21.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de MATRICULA\n",
    "\n",
    "utilizando as matriculas SIGRH quando matriculas ATO nao sao encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01793403 01010085\n",
      "01010085 01010085\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[138, 'COD_MATRICULA_ATO'], data_og.loc[138, 'COD_MATRICULA_SIGRH'])\n",
    "\n",
    "#Fix row 138\n",
    "data.loc[138, 'COD_MATRICULA_ATO'] = data_og.loc[138, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "#Fix row 422\n",
    "data.loc[422, 'COD_MATRICULA_ATO'] = data_og.loc[422, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "#Fix row 506\n",
    "data.loc[506, 'COD_MATRICULA_ATO'] = data_og.loc[506, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "#Fix row 537\n",
    "data.loc[537, 'COD_MATRICULA_ATO'] = data_og.loc[537, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "#Fix row 719\n",
    "data.loc[719, 'COD_MATRICULA_ATO'] = data_og.loc[719, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "# FIx row 761\n",
    "data.loc[761, 'COD_MATRICULA_ATO'] = data_og.loc[761, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "# Fix row 3199\n",
    "data.loc[3199, 'COD_MATRICULA_ATO'] = \"209.913-6\"\n",
    "\n",
    "# Fix row 3610\n",
    "data.loc[3610, 'COD_MATRICULA_ATO'] = data_og.loc[3610, 'COD_MATRICULA_SIGRH']\n",
    "\n",
    "# Fix row 4449\n",
    "data.loc[4449, 'COD_MATRICULA_ATO'] = \"42.299-1\"\n",
    "\n",
    "print(data.loc[138, 'COD_MATRICULA_ATO'], data_og.loc[138, 'COD_MATRICULA_SIGRH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de NOME\n",
    "\n",
    "Diferenca no processamento de acentos e apostrofos entre o DODFminer e as anotacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fixes needed here\n",
    "\n",
    "# # Fix row 201\n",
    "# data.loc[201, 'NOME_ATO'] = \"ROSELI DE MOURA GONZALES D ALMEIDA\"\n",
    "\n",
    "# # Fix row 604\n",
    "# data.loc[604, 'NOME_ATO'] = \"MARIA FLORA CALVINO MARQUES\"\n",
    "\n",
    "# # Fix row 5199\n",
    "# data.loc[5199, 'NOME_ATO'] = \"LORIVANDA D ABADIA DOS SANTOS\"\n",
    "\n",
    "# # Fix row 5229\n",
    "# data.loc[5229, 'NOME_ATO'] = \"ELZA LUCIA MENDES MUNIZ\"\n",
    "\n",
    "# # Fix row 5310\n",
    "# data.loc[5310, 'NOME_ATO'] = \"MARIA D ARC PEREIRA\"\n",
    "\n",
    "# # Fix row 5427\n",
    "# data.loc[5427, 'NOME_ATO'] = \"MARCIA CRISTINA TOMAZ MULLER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de CARGO\n",
    "\n",
    "Algumas anotacoes erroneas (apresentadas abaixo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix row 719\n",
    "data.loc[719, 'CARGO'] = \"agente de transito\"\n",
    "\n",
    "# Fix row 4141\n",
    "data.loc[4141, 'CARGO'] = \"Gestor em Politicas Publicas e Gestao Governamental\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de CLASSE\n",
    "\n",
    "Em grande parte diferenca entre numeros ordinais e suas escritas por extenso (1a classe == primeira classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missed_entities['CLASSE'][1]:\n",
    "    a = data.iloc[i]['CLASSE']\n",
    "    a = a.split()\n",
    "    s = \"\"\n",
    "    if a[0].lower() == 'primeira':\n",
    "        s = \"1a Classe\"\n",
    "    elif a[0].lower() == 'segunda':\n",
    "        s = \"2a Classe\"\n",
    "    elif a[0].lower() == 'terceira':\n",
    "        s = \"3a Classe\"\n",
    "    elif a[0].lower() == 'quarta':\n",
    "        s = \"4a Classe\"\n",
    "    if s:\n",
    "        data.loc[i, 'CLASSE'] = s\n",
    "        \n",
    "# Fix row 506\n",
    "data.loc[506, 'CLASSE'] = \"Classe Unica\"\n",
    "\n",
    "# Fix row 571\n",
    "data.loc[571, 'CLASSE'] = \"Primeira Classe\"\n",
    "\n",
    "# Fix row 947\n",
    "data.loc[947, 'CLASSE'] = \"Classe Unica\"\n",
    "\n",
    "# Fix row 5512\n",
    "data.loc[5512, 'CLASSE'] = \"Primeira Classe\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de PADRAO\n",
    "\n",
    "Entidades da classe PADRAO foram anotadas erroneamente (casos abaixo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix row 3199\n",
    "data.loc[3199, 'PADRAO'] = \"Padrao 15\"\n",
    "\n",
    "# Fix row 4449\n",
    "data.loc[4449, 'PADRAO'] = \"Padrao 25\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de QUADRO\n",
    "\n",
    "Ainda nao sei qual o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\n",
      "\n",
      "Col:QUADRO -> [104, 138, 269, 270, 271, 272, 273, 280, 282, 526, 528, 529, 530, 531, 532, 571, 975, 976, 977, 978, 980, 981, 983, 984, 985, 987, 988, 3855, 3927, 4474, 4496, 4505, 4509, 4527, 4529, 4531, 4532, 4533, 4545, 4550, 4571, 5476, 5477, 5512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\\n\")\n",
    "for col in data.drop(columns=['text', 'labels']).columns:\n",
    "#     print(f\"Col:{col} -> {missed_entities[col][1]}\")\n",
    "#     if len(missed_entities[col][1]) <= 100:\n",
    "    if col == 'QUADRO':\n",
    "        print(f\"Col:{col} -> {missed_entities[col][1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/04/2018 68\n",
      "DINA MARIA PIRES DE MIRANDA ||| QUADRO DE PESSOAL DO DISTRITO FEDERAL \n",
      "||| 00361.00004000/201835 ||| 68 ||| 10/04/2018\n",
      "CLASSE ESPECIAL ||| PADRAO V ||| QUADRO DE PESSOAL DO DISTRITO FEDERAL\n",
      "\n",
      "CONCEDER Aposentadoria a DINA MARIA PIRES DE MIRANDA, matricula 25.293-X, no cargo de Auditor Fiscal de Atividades Urbanas, Classe Especial, Padrao V, do Quadro de Diario Oficial do Distrito Federal No 68, terca-feira, 10 de abril de 2018 PAGINA 20 Este documento pode ser verificado no endereco eletronico http://www.in.gov.br/autenticidade.html , pelo codigo 50012018041000020 Documento assinado digitalmente conforme MP n 2.200-2 de 24/08/2001, que institui a Infraestrutura de Chaves Publicas Brasileira - ICP-Brasil. Pessoal do Distrito Federal, nos termos do artigo 3o, incisos I, II, III, paragrafo unico da Emenda Constitucional no 47, de 06 de julho de 2005, combinado com o artigo 44, da Lei Complementar no 769, de 30 de junho de 2008. Processo SEI n o 00361.00004000/2018- 35\n"
     ]
    }
   ],
   "source": [
    "# Celula utilizada para ver quais as entidades e o trecho de texto identificado para uma linha do dataframe (row)\n",
    "# [506, 537]\n",
    "row = 104\n",
    "print(data_og.loc[row, 'DATA_DODF'], data_og.loc[row, 'NUM_DODF'])\n",
    "print(data.loc[row, 'NOME_ATO'], \"|||\", data['QUADRO'][row], \"\\n|||\", data['PROCESSO'][row], \"|||\", data_og['NUM_DODF'][row], \"|||\", data_og['DATA_DODF'][row])\n",
    "print(data['CLASSE'][row], \"|||\", data['PADRAO'][row], \"|||\", data['QUADRO'][row])\n",
    "print()\n",
    "print(data['text'][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missed_entities['QUADRO'][1]:\n",
    "    if data.loc[i, 'QUADRO'] == 'QUADRO DE PESSOAL DO SERVICO DE LIMPEZA URBANA':\n",
    "        data.loc[i, 'QUADRO'] = \"QP/SLU\"\n",
    "        \n",
    "# Fix row 3927 (DODFminer pulou parte do texto do DODF)\n",
    "data.loc[3927, 'QUADRO'] = \"Quadro de Pessoal do Governo do Distrito\"\n",
    "\n",
    "# Fix row 104 (DODFminer pulou parte do texto do DODF)\n",
    "data.loc[104, 'QUADRO'] = \"Quadro de\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de EMPRESA_ATO\n",
    "\n",
    "Algumas anotacoes nao aparecem no DODF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows em que entidades EMPRESA_ATO nao aparecem no DODF\n",
    "# no_entity = [70, 71, ]\n",
    "\n",
    "# for i in no_entity:\n",
    "#     data.loc[i, 'EMPRESA_ATO'] = \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcao manual das entidades de FUND_LEGAL\n",
    "\n",
    "Ainda nao sei qual o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\n",
      "\n",
      "Numero de entidades FUND_LEGAL nao encontradas: 600\n"
     ]
    }
   ],
   "source": [
    "print(\"Entidades nao identificadas e as linhas do dataframe em que elas aparecem:\\n\")\n",
    "print(\"Numero de entidades FUND_LEGAL nao encontradas:\", len(missed_entities['FUND_LEGAL'][1]))\n",
    "# for col in data.drop(columns=['text', 'labels']).columns:\n",
    "# #     print(f\"Col:{col} -> {missed_entities[col][1]}\")\n",
    "# #     if len(missed_entities[col][1]) <= 100:\n",
    "#     if col == 'FUND_LEGAL':\n",
    "#         print(f\"Col:{col} -> {missed_entities[col][1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOS TERMOS DO ARTIGO 40,  1o, INCISO III, ALINEA AE  3o, 5o,8o E 17, DA CONSTITUICAO DA REPUBLICA FEDERATIVA DO BRASIL, NA REDACAO DADA PELA EMENDA CONSTITUCIONAL No 41, DE 31 DE DEZEMBRO DE 2003, E ARTIGOS 46 E 51 DA LEI COMPLEMENTAR No 769, DE 01 DE JULHO DE 2008\n",
      "nos termos do artigo 40,  1o, inciso III, alinea \"a\"e 3o, 5o,8o e 17, da Constituicao da Republica Federativa do Brasil, na redacao dada pelaEmenda Constitucional no 41, de 31 de dezembro de 2003, e artigos 46 e 51 da LeiComplementar no 769, de 01 de julho de 2008\n"
     ]
    }
   ],
   "source": [
    "# Utilizando as tres primeiras e tres ultimas palavras da entidade anotada (ao inves de a entidade completa) com regex\n",
    "\n",
    "print(data.loc[290, 'FUND_LEGAL'])\n",
    "for sample in missed_entities['FUND_LEGAL'][1]:\n",
    "    s = data.loc[sample, 'FUND_LEGAL'].split()\n",
    "    beg = ' '.join(s[:4])\n",
    "    end = ' '.join(s[-3:len(s)])\n",
    "        \n",
    "    # Criando regex para a entidade FUND_LEGAL (utilizando as primeiras 3 e as ultimas 3 palavras de data.loc[sample, 'FUND_LEGAL'])\n",
    "    re_FUND_LEGAL = \"\"\n",
    "    for i in beg:\n",
    "        if (i >= 'a' and i <= 'z') or (i>='A' and i<='Z'):\n",
    "            re_FUND_LEGAL += f\"[{i.lower()}{i.upper()}]\" + \"[-,.\\s]*?\"\n",
    "        else:\n",
    "            re_FUND_LEGAL += i + \"[-,.\\s]*?\"\n",
    "    re_FUND_LEGAL += '.*?'\n",
    "    for i in end:\n",
    "        if (i >= 'a' and i <= 'z') or (i>='A' and i<='Z'):\n",
    "            re_FUND_LEGAL += f\"[{i.lower()}{i.upper()}]\" + \"[-,.\\s]*?\"\n",
    "        else:\n",
    "            re_FUND_LEGAL += i + \"[-,.\\s]*?\"\n",
    "            \n",
    "    # Busca do regex no trecho de texto que deve conter esta entidade\n",
    "    result = re.search(re_FUND_LEGAL, data.loc[sample, 'text'])\n",
    "    if result:\n",
    "        if abs(len(data.loc[sample, 'text'][result.span()[0]:result.span()[1]].split()) - len(data.loc[sample, 'FUND_LEGAL'].split())) < 3:\n",
    "            data.loc[sample, 'FUND_LEGAL'] = result[0]\n",
    "            \n",
    "print(data.loc[290, 'FUND_LEGAL'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5 - Reanotando entidades corrigidas\n",
    "\n",
    "Similar a Parte 3, mas agora utilizando os dados corrigidos na Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ATO: 5167 \t\t Missed ATO: 2\n",
      "Found EMPRESA_ATO: 2208 \t\t Missed EMPRESA_ATO: 2961\n",
      "Found COD_MATRICULA_ATO: 5169 \t\t Missed COD_MATRICULA_ATO: 0\n",
      "Found NOME_ATO: 5169 \t\t Missed NOME_ATO: 0\n",
      "Found CARGO: 5168 \t\t Missed CARGO: 0\n",
      "Found CLASSE: 2422 \t\t Missed CLASSE: 0\n",
      "Found PADRAO: 4879 \t\t Missed PADRAO: 0\n",
      "Found QUADRO: 4952 \t\t Missed QUADRO: 0\n",
      "Found PROCESSO: 5169 \t\t Missed PROCESSO: 0\n",
      "Found FUND_LEGAL: 5069 \t\t Missed FUND_LEGAL: 99\n"
     ]
    }
   ],
   "source": [
    "found_entities  = {col: 0 for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns}\n",
    "missed_entities = {col: [0, []] for col in data.drop(columns=['text', 'labels', 'DATA_DODF']).columns}\n",
    "data['labels'] = \"\"\n",
    "for row in range(len(data)):\n",
    "    if pd.notna(data['text'][row]):\n",
    "        entities = find_entities(data, row)\n",
    "        entities.sort()\n",
    "        labels = IOBify_text(data['text'][row], entities)\n",
    "        s = \"\"\n",
    "        for l in labels:\n",
    "            s += l + ' '\n",
    "        data['labels'][row] = s\n",
    "    \n",
    "for col in found_entities:\n",
    "    print(f\"Found {col}: {found_entities[col]}\", f\"\\t\\t Missed {col}: {missed_entities[col][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final - salvando os dados preprocessados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando no formato CoNLL03 \n",
    "\n",
    "Salva os trechos de texto e labels, separando em conjuntos \"nao rotulado\" e \"rotulado\" para teste com active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treinamento\n",
      "unlabeled set size: 3581 labeled set size: 37\n",
      "\n",
      "Tamanho do conjunto de teste\n",
      "test set size: 1551\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "t = []\n",
    "\n",
    "# Separa conjuntos de dados de forma cronológica\n",
    "def func(a):\n",
    "    a = a.split('/')\n",
    "    return a[2], a[1], a[0]\n",
    "for row in data.index:\n",
    "    if pd.notna(data['text'][row]) and pd.notna(data['labels'][row]):\n",
    "        x.append(data.loc[row, 'text'])\n",
    "        y.append(data.loc[row, 'labels'])\n",
    "        t.append(' '.join((lambda x: x[::-1])(data.loc[row, 'DATA_DODF'].split('/'))))\n",
    "idx = np.argsort(t)\n",
    "test_split_idx = math.floor(len(idx)*0.7)\n",
    "t1 = [-1 for _ in range(len(t))]\n",
    "for i, j in enumerate(idx):\n",
    "    t1[i] = t[j]\n",
    "x_train = [x[i] for i in idx[:test_split_idx]]\n",
    "y_train = [y[i] for i in idx[:test_split_idx]]\n",
    "x_test = [x[i] for i in idx[test_split_idx:]]\n",
    "y_test = [y[i] for i in idx[test_split_idx:]]\n",
    "\n",
    "initial_labeled_set_idx = math.floor(len(x_train)*0.99)\n",
    "labeled_x = x_train[initial_labeled_set_idx:]\n",
    "labeled_y = y_train[initial_labeled_set_idx:]\n",
    "unlabeled_x = x_train[:initial_labeled_set_idx]\n",
    "unlabeled_y = y_train[:initial_labeled_set_idx]\n",
    "print(\"Tamanho do conjunto de treinamento\")\n",
    "print(\"unlabeled set size:\", len(unlabeled_x), \"labeled set size:\",  len(labeled_x))\n",
    "print(\"\\nTamanho do conjunto de teste\")\n",
    "print(\"test set size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CONCEDER aposentadoria voluntaria ao servidor MANOEL FRANCISCO DOS SANTOS, matricula no 101.644-X, Tecnico Socioeducativo - Classe Especial, Padrao V, fundamentada nos termos do artigo 3o, incisos I, II, III e paragrafo unico, da Emenda Constitucional no 47/2005, combinado com o artigo 44 da Lei Complementar no 769/2008, com as vantagens do artigo 5o da Lei no 4.584/11. Processo SEI no 00417-00013797/2018-32'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conll(x, y, nome_arquivo):\n",
    "    ptr = open(nome_arquivo, 'w')\n",
    "    for i in range(len(x)):\n",
    "        text = x[i]\n",
    "        label = y[i]\n",
    "        assert len(text.split()) == len(label.split()), f\"Erro em {text}\"\n",
    "        for word, label in zip(text.split(), label.split()):\n",
    "            ptr.write(word + ' ' + label + '\\n')\n",
    "        ptr.write('\\n')\n",
    "save_conll(labeled_x,   labeled_y,   \"labeled_set.txt\"  )\n",
    "save_conll(unlabeled_x, unlabeled_y, \"unlabeled_set.txt\")\n",
    "save_conll(x_test,      y_test,      \"test_set.txt\"     )\n",
    "save_conll(x_train,     y_train,     \"train_set.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o dataframe completo \n",
    "\n",
    "Salva dataframe contendo anotacoes de entidades, trechos de texto contendo as anotacoes e as labels (IOB) para cada palavra no texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('labeled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
