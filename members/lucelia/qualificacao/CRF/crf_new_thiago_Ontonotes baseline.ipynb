{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "source": [
    "Let's use CoNLL 2003 data to build a NER system\n",
    "\n",
    "We use English data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conll2003\n",
    "with open('/home/82068895153/POS/skweak/data/conll2003_dataset/train.txt', 'r') as file:\n",
    "  sentences = list(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print (sentences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria os tokens dentro das sentencas -- quebra a setenca em uma lista\n",
    "def preprocess(sentences):\n",
    "    l_sentences = []\n",
    "    l1_ = []\n",
    "    for token in sentences[5:]: #a partir da quinta posicao\n",
    "    #for token in sentences:\n",
    "        cls = token.split()    \n",
    "        if len(cls) != 0:\n",
    "            l1_.append(cls)\n",
    "        else:\n",
    "            l_sentences.append(l1_)\n",
    "            l1_ = []\n",
    "    return l_sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quebra a sentença em lista\n",
    "sentences=preprocess(sentences)\n",
    "\n",
    "# print (sentences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    \n",
    "    word = sent[i][0]\n",
    "    #print ('word', word)\n",
    "    postag = sent[i][1]\n",
    "    #print ('postag', postag)\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]        \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2featuresO(sent, i):\n",
    "    #word = sent[i][0]\n",
    "    word = sent[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()  \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]       \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2featuresO(sent):\n",
    "    #print('sent ==', sent)\n",
    "    #teste = [word2featuresO(sent, i) for i in range(len(sent))]\n",
    "    #print('teste ==', teste)\n",
    "    return [word2featuresO(sent, i) for i in range(len(sent))]\n",
    "    #return teste\n",
    "\n",
    "\n",
    "def sent2labelsO(sent):\n",
    "    return [label for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, __, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, __, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in sentences]\n",
    "\n",
    "y_train = [sent2labels(s) for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "Carrega o X_test --> dataset do Ontonotes sem rótulos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Abre o Ontonotes sem rotulos\n",
    "#with open('/home/82068895153/POS/skweak/data/wiki/wikigold.conll.txt', 'r') as file:\n",
    "with open('/home/82068895153/POS/skweak/data/Ontonotes/train_out_1.txt', 'r') as file:\n",
    "    test_sentences = list(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma a sentença em lista\n",
    "test_sentences_1=preprocess(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_sentences_1[0])"
   ]
  },
  {
   "source": [
    "X_test = features so texto a ser rotulado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extrai as fetatures de X_test \n",
    "X_test = [[sent2featuresO(s) for s in text] for text in test_sentences_1]\n",
    "\n",
    "#https://stackoverflow.com/questions/41829323/attributeerror-list-object-has-no-attribute-lower-gensim\n",
    "#data = [line.strip() for line in open(\"C:\\corpus\\TermList.txt\", 'r')]\n",
    "#texts = [[word.lower() for word in text.split()] for text in data]\n",
    "#X_test=test_sentences_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(X_test[0]))\n",
    "print(X_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_text = [i for i in X_test_1] \n",
    "#import copy\n",
    "#X_text = [copy.copy(X_test_1)]\n",
    "#nova_lista is lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retira de dentro da lista aninhada (o dataset está com uma lista a mais)\n",
    "for i in range(len(X_test)):\n",
    "        X_test[i] = [i[0] for i in X_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "source": [
    "y_pred = rotulos preditos para o texto não rotulado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplica o modelo treinado no dataset sem rotulos\n",
    "y_pred = crf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred "
   ]
  },
  {
   "source": [
    "Dataset Ontonotes com rótulos reais para gerar o y_test\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Abre o Ontonotes para carregar o y_test = DATASET com rótulos reais\n",
    "#with open('/home/82068895153/POS/skweak/data/BERT/train_out_trat.txt', 'r') as file:\n",
    "with open('/home/82068895153/POS/skweak/data/Ontonotes/ner_train_trat_1.txt', 'r') as file:\n",
    "    test_sentences_label = list(file.readlines())\n",
    "    print (test_sentences_label[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retira os espaços em branco e as words maiores que duas posições\n",
    "for i in range(len(test_sentences_label) - 1):\n",
    "    atual = test_sentences_label[i].split()\n",
    "    proximo = test_sentences_label[i+1].split()\n",
    "    if len(atual) == 0:\n",
    "        continue\n",
    "    while len(proximo) > 2:\n",
    "        print(f'Convertendo ({atual}) e ({proximo}) para ', end = '')\n",
    "        atual[0] += proximo[0]\n",
    "        test_sentences_label[i] = '\\t'.join(atual)\n",
    "        proximo = proximo[1:]\n",
    "        test_sentences_label[i+1] = '\\t'.join(proximo)\n",
    "        print(f'({atual}) e ({proximo})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (test_sentences_label[0:3])\n",
    "\n",
    "test_sentences_label_1=preprocess(test_sentences_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_sentences_label_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o dataset tem mais elementos que a chamado do métoddo sent2labels\n",
    "for sentences in test_sentences_label_1:\n",
    "    try: \n",
    "        _ = sent2labelsO(sentences)\n",
    "    except ValueError:\n",
    "        for word in sentences:\n",
    "            if len(word)!= 2:\n",
    "                print(f' {word} possui {len(word)} elementos.')  \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retira elementos de uma lista aninhada\n",
    "#for i in range(len(test_sentences_label_1)):\n",
    "#    test_sentences_label_1[i] = [i[0] for i in test_sentences_label_1[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retira elementos de uma lista aninhada\n",
    "#matrix = test_sentences_label_1\n",
    "#sentencesOL = [] \n",
    "#for sublist in matrix: \n",
    "#    for val in sublist: \n",
    "#        sentencesOL.append(val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(sentencesOL[0]) "
   ]
  },
  {
   "source": [
    "Extrai os rótulos reais y_test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = DATASET com rótulos reais \n",
    "y_test = [sent2labelsO(s) for s in test_sentences_label_1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['O', 'O', 'O', 'DATE', 'DATE', 'DATE', 'DATE', 'DATE', 'B-PER', 'O'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Qtde labels preditos 155\ntamanho y_pred 9891\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i,x in enumerate(y_pred):\n",
    "        ss=set(x)\n",
    "        if len(ss) > 1:\n",
    "            count+=1\n",
    "print(\"Qtde labels preditos\", count)\n",
    "print(\"tamanho y_pred\", len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##está dentro de duas uma lista = test_sentences_1 = texto sem rotulo\n",
    "test_sentences_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##está dentro de apenas uma lista = y_pred = rotulos preditos de test_sentences_1\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Muda o label na lista para o formato do Ontonotes  \n",
    "lista = []\n",
    "for p in y_pred:\n",
    "  for x in t:\n",
    "    #print(x)\n",
    "    if (x=='B-LOC'):\n",
    "        print(x)\n",
    "        lista.append('LOC')\n",
    "    if (x=='B-PER'):\n",
    "        print(x)\n",
    "        lista.append('PER')\n",
    "        print(lista) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retira os espaços em branco da lista y_pred\n",
    "lista_y=[]\n",
    "for t in lista:\n",
    "    #print('t==>',t)\n",
    "    #if len(t)!=0:\n",
    "     #   lista_y.append([i[0] for i in t])\n",
    "        #print(lista_y)\n",
    "    for x in t:\n",
    "            #if (x == 'B-LOC'):\n",
    "        if (x=='LOC'):\n",
    "            print(x)\n",
    "        elif (x == 'B-PER'):\n",
    "            print(x)\n",
    "                #lista_y[x] = [x[0] for x in lista_y[x]]   \n",
    "                #print('x==>',x, 'lista_y',lista_y)\n",
    "            #if x!=('O'): \n",
    "            #    print('x==>',x, 'lista_y',lista_y)\n",
    "            \n",
    "            \n",
    "#for i in range(len(X_test)):\n",
    "#        X_test[i] = [i[0] for i in X_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retira os espaços em branco da lista test_sentences_1\n",
    "lista=[]\n",
    "for t in test_sentences_1:\n",
    "    if len(t)!=0:\n",
    "        lista.append([i[0] for i in t])\n",
    "    #else:\n",
    "    #    lista.append('\\n')\n",
    "#lista[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setenca=(zip(t[0],t[1])) for t in zip(test_sentences_1, y_pred)\n",
    "#zip(test_sentences_1[],y_pred[])\n",
    "#substantivo = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "#print(substantivo)\n",
    "#adjetivo = ['be', 'closed', 'for', 'the', 'rest', 'of', 'the', 'week', 'Anderson', '.']\n",
    "#print(adjetivo)\n",
    "#['%s %s' % (s, a) for s in substantivo for a in adjetivo ]\n",
    "#['pão pequeno', 'pé pequeno', 'carro caro', 'bolo bonito', 'bolo bom']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #t=list('%s %s' % (s, a) for s in lista[0] for a in y_pred[0])\n",
    " #t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Concatena a palavra e o rotulo predito\n",
    "l = [list(zip(x, y)) for x, y in zip(lista, lista_y)]\n",
    "#print(l[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for t in l:\n",
    "    for x in t:\n",
    "        if x !=('O',):\n",
    "            print(x[1:5])\n",
    "            if x[1]==('B-'): \n",
    "                print(Lu)\n",
    "        #    print('rotulo ==>',x[1:3], 'lista ==>',l[1:3])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encontra o índice da lista\n",
    "indices_to_replace = [i for i,x in enumerate(y_pred) if x=='B-LOC']\n",
    "#print(x)\n",
    "print(indices_to_replace)\n",
    "#indices_to_replace\n",
    "for s in indices_to_replace:\n",
    "    y_pred[s] = 'LOC'\n",
    "    print(y_pred[s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in y_pred:\n",
    "    for r in p:\n",
    "#        #print(r)\n",
    "        if (r=='LOC' or r=='PER'):\n",
    "            #n=[i for i,x in enumerate(r)]\n",
    "            a=[list(zip(lista, lista_y))]\n",
    "            print(a)\n",
    "            #Concatena a palavra e o rotulo predito\n",
    "\n",
    "#print(l[0:20]\n",
    "#transforma a lista em sentenca\n",
    "texto_1 = ''\n",
    "for linha in a:\n",
    "    for z in linha:\n",
    "        texto_1='sentenca'+ (texto_1) +(z) + '\\n'\n",
    "# Write the file out again\n",
    "with open('/home/82068895153/POS/skweak/data/Ontonotes/train_labeled_comp.txt', 'wt') as fileout:\n",
    "  fileout.write(texto_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforma a lista em sentenca\n",
    "texto = ''\n",
    "for linha in l:\n",
    "    for z,t in linha:\n",
    "        texto=texto + str(z)+' '+ t + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file out again\n",
    "with open('/home/82068895153/POS/skweak/data/Ontonotes/train_labeled.txt', 'wt') as fileout:\n",
    "  fileout.write(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = texto.replace('I-','').replace('O-','')\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto = 'who was tagged for a pair of homers by Mike Devereaux and Brady Anderson and three runs in the ninth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [Texto.split()]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percorre a letra dentro da word dentro da sentenca\n",
    "X_t1 = [[sent2featuresO(s) for s in text] for text in tokenized]\n",
    "X_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percorre a word dentro da sentença, mas sem criar uma nova lista\n",
    "X_t1 =  [sent2featuresO(s) for s in tokenized]\n",
    "X_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = crf.predict(X_t1)\n",
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega apenas a word da\n",
    "for i in range(len(X_t1)):\n",
    "        X_t1[i] = [i[0] for i in X_t1[i]]"
   ]
  },
  {
   "source": [
    "Avaliação\n",
    "\n",
    "There is much more O entities in data set, but we’re more interested in other entities. To account for this we’ll use averaged F1 score computed for all labels except for O. sklearn-crfsuite.metrics package provides some useful metrics for sequence classification task, including this one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'B-ORG', 'I-ORG', 'I-MISC', 'I-LOC']"
      ]
     },
     "metadata": {},
     "execution_count": 289
    }
   ],
   "source": [
    "#PERSON == 'B-PER' 'I-PER' (CONLL), ORG == 'B-ORG', GPE == 'B-LOC' 'I-LOC' (CONLL), MISC == TUDO QUE NAO AS OUTRAS 3 NO CONLL\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26337/3055361137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'predicao'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'rotulos reais'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print ('predicao', l[0] )\n",
    "print ('rotulos reais', y_test[0], test_sentences_label[0])\n",
    "\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imprime os Labels do Y_pred diferentes de 'O'\n",
    "\n",
    "#for i in range(len(y_pred)):\n",
    "#    if y_pred[i]!= ('O'): \n",
    "#        print(y_pred[i])    \n",
    "\n",
    "for linha in y_pred:        \n",
    "    #print(list(linha))\n",
    "    for palavra in linha:\n",
    "          if palavra!= ('O'): \n",
    "                print(palavra)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Qtde labels preditos 155\ntamanho y_pred 9891\ntamanho y_test 3120\n"
     ]
    }
   ],
   "source": [
    "#Imprime o tamanho do y_test e y_pred e qtde de label predita\n",
    "count = 0\n",
    "for i,x in enumerate(y_pred):\n",
    "        ss=set(x)\n",
    "        if len(ss) > 1:\n",
    "            count+=1\n",
    "print(\"Qtde labels preditos\", count)\n",
    "print(\"tamanho y_pred\", len(y_pred))\n",
    "print(\"tamanho y_test\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.07118034822383563"
      ]
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "source": [
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "source": [
    "Inspect per-class results in more detail:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n       B-LOC      0.787     0.074     0.135      1502\n       I-LOC      0.000     0.000     0.000         0\n      B-MISC      0.000     0.000     0.000         0\n      I-MISC      0.000     0.000     0.000         0\n       B-ORG      0.000     0.000     0.000         0\n       I-ORG      0.000     0.000     0.000         0\n       B-PER      0.381     0.005     0.010      1571\n       I-PER      0.000     0.000     0.000         0\n\n   micro avg      0.696     0.039     0.073      3073\n   macro avg      0.146     0.010     0.018      3073\nweighted avg      0.580     0.039     0.071      3073\n\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "source": [
    "Hyperparameter Optimization\n",
    "\n",
    "To improve quality try to select regularization parameters using randomized search and 3-fold cross-validation.\n",
    "\n",
    "I takes quite a lot of CPU time and RAM (we’re fitting a model 50 * 3 = 150 times), so grab a tea and be patient, or reduce n_iter in RandomizedSearchCV, or fit model only on a subset of training data.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "Best result:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check parameter space\n",
    "\n",
    "A chart which shows which c1 and c2 values have RandomizedSearchCV checked. Red color means better results, blue means worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = [s.parameters['c1'] for s in rs.grid_scores_]\n",
    "_y = [s.parameters['c2'] for s in rs.grid_scores_]\n",
    "_c = [s.mean_validation_score for s in rs.grid_scores_]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 12)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C1')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
    "    min(_c), max(_c)\n",
    "))\n",
    "\n",
    "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
    "\n",
    "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
   ]
  },
  {
   "source": [
    "Check best estimator on our test data\n",
    "\n",
    "As you can see, quality is improved."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n"
   ]
  },
  {
   "source": [
    "Let’s check what classifier learned"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s check what classifier learned\n",
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "source": [
    "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized.\n",
    "\n",
    "Check the state features:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## carregar a base ontonotes - ok\n",
    "## fazer mapeamento das labels - ok\n",
    "## fazer a predição - ok\n",
    "## fazer a comparação entre y_predito e y_real - ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Manipulando lista\n",
    "l = [1,2,3,4,5]\n",
    "\n",
    "#criando listas\n",
    "l = [[w] for w in \"We dont like it\".split()]\n",
    "l\n",
    "\n",
    "def sum(i):\n",
    "        return i+20\n",
    "[sum(x) for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(test_sentences_label_1[0]).strip('[]')\n",
    "#t=','.join(test_sentences_label_1)\n",
    "cars = (['rav4'], ['td5'], ['yaris'], ['land rover tdi']) \n",
    "\n",
    "print(\"I like the \"+cars[0][0]+\" ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}