{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "source": [
    "Let's use CoNLL 2003 data to build a NER system\n",
    "\n",
    "We use English data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n[nltk_data]     /home/82068895153/nltk_data...\n[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.07 s, sys: 76.2 ms, total: 1.15 s\nWall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "#test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "#train_sents[0]\n",
    "\n",
    "\n",
    "[('rejects', 'NNS'), ('VBZ', 'NNP'), ('B-VP', 'NNP'), ('O', 'NNP')]"
   ]
  },
  {
   "source": [
    "Features\n",
    "\n",
    "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used.\n",
    "\n",
    "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
    "\n",
    "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "source": [
    "This is what word2features extracts:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'melbourne',\n",
       " 'word[-3:]': 'rne',\n",
       " 'word[-2:]': 'ne',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isdigit()': False,\n",
       " 'postag': 'NP',\n",
       " 'postag[:2]': 'NP',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': '(',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'Fpa',\n",
       " '+1:postag[:2]': 'Fp'}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "source": [
    "Extract features from the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 633 ms, sys: 27.7 ms, total: 661 ms\nWall time: 660 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "source": [
    "Training\n",
    "\n",
    "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 29.3 s, sys: 0 ns, total: 29.3 s\nWall time: 29.4 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "#try:\n",
    "#    crf.fit(X_train, y_train)\n",
    "#except AttributeError:\n",
    "#    pass\n",
    "#predictions = crf.predict(X_test)"
   ]
  },
  {
   "source": [
    "Evaluation\n",
    "\n",
    "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. sklearn-crfsuite.metrics package provides some useful metrics for sequence classification task, including this one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-LOC', 'B-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-ORG', 'I-LOC', 'I-MISC']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7964686316443963"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/82068895153/POS/skweak/data/conll2003_dataset/train_out.txt\", 'r') as file :\n",
    " X_test = file.readlines()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/82068895153/POS/skweak/data/conll2003_dataset/train.txt\", 'r') as file :\n",
    " y_test = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  'postag': 'AQ',\n",
       "   'postag[:2]': 'AQ',\n",
       "   '-1:word.lower()': 'm.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'VMI',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'w.',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': True,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'w.',\n",
       "   'word[-3:]': 'W.',\n",
       "   'word[-2:]': 'W.',\n",
       "   'word.isupper()': True,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'w.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'AQ',\n",
       "   '-1:postag[:2]': 'AQ',\n",
       "   '+1:word.lower()': 'se',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'P0',\n",
       "   '+1:postag[:2]': 'P0'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'se',\n",
       "   'word[-3:]': 'se',\n",
       "   'word[-2:]': 'se',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'P0',\n",
       "   'postag[:2]': 'P0',\n",
       "   '-1:word.lower()': 'w.',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': True,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'citaron',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMI',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'citaron',\n",
       "   'word[-3:]': 'ron',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMI',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'se',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'P0',\n",
       "   '-1:postag[:2]': 'P0',\n",
       "   '+1:word.lower()': 'con',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'con',\n",
       "   'word[-3:]': 'con',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'citaron',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMI',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'pedro',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMN',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'pedro',\n",
       "   'word[-3:]': 'dro',\n",
       "   'word[-2:]': 'ro',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMN',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'con',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'corbella',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'corbella',\n",
       "   'word[-3:]': 'lla',\n",
       "   'word[-2:]': 'la',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'pedro',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMN',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'con',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'con',\n",
       "   'word[-3:]': 'con',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'corbella',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'el',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DA',\n",
       "   '+1:postag[:2]': 'DA'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'el',\n",
       "   'word[-3:]': 'el',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DA',\n",
       "   'postag[:2]': 'DA',\n",
       "   '-1:word.lower()': 'con',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'propósito',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'propósito',\n",
       "   'word[-3:]': 'ito',\n",
       "   'word[-2:]': 'to',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'el',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DA',\n",
       "   '-1:postag[:2]': 'DA',\n",
       "   '+1:word.lower()': 'de',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'de',\n",
       "   'word[-3:]': 'de',\n",
       "   'word[-2:]': 'de',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'propósito',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'tomar',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMN',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'tomar',\n",
       "   'word[-3:]': 'mar',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMN',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'de',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'unas',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DI',\n",
       "   '+1:postag[:2]': 'DI'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'unas',\n",
       "   'word[-3:]': 'nas',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DI',\n",
       "   'postag[:2]': 'DI',\n",
       "   '-1:word.lower()': 'tomar',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMN',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'copas',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'copas',\n",
       "   'word[-3:]': 'pas',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'unas',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DI',\n",
       "   '-1:postag[:2]': 'DI',\n",
       "   '+1:word.lower()': 'y',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'CC',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'y',\n",
       "   'word[-3:]': 'y',\n",
       "   'word[-2:]': 'y',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CC',\n",
       "   'postag[:2]': 'CC',\n",
       "   '-1:word.lower()': 'copas',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'Fc',\n",
       "   '+1:postag[:2]': 'Fc'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'Fc',\n",
       "   'postag[:2]': 'Fc',\n",
       "   '-1:word.lower()': 'y',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'CC',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:word.lower()': 'tras',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'tras',\n",
       "   'word[-3:]': 'ras',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'Fc',\n",
       "   '-1:postag[:2]': 'Fc',\n",
       "   '+1:word.lower()': 'quedar',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMN',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'quedar',\n",
       "   'word[-3:]': 'dar',\n",
       "   'word[-2:]': 'ar',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMN',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'tras',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'en',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'en',\n",
       "   'word[-3:]': 'en',\n",
       "   'word[-2:]': 'en',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'quedar',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMN',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'lascercanías',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'lascercanías',\n",
       "   'word[-3:]': 'ías',\n",
       "   'word[-2:]': 'as',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'en',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'del',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'del',\n",
       "   'word[-3:]': 'del',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'lascercanías',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'pub',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'pub',\n",
       "   'word[-3:]': 'pub',\n",
       "   'word[-2:]': 'ub',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'del',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': '\"',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'Fe',\n",
       "   '+1:postag[:2]': 'Fe'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\"',\n",
       "   'word[-3:]': '\"',\n",
       "   'word[-2:]': '\"',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'Fe',\n",
       "   'postag[:2]': 'Fe',\n",
       "   '-1:word.lower()': 'pub',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'la',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DA',\n",
       "   '+1:postag[:2]': 'DA'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'la',\n",
       "   'word[-3:]': 'La',\n",
       "   'word[-2:]': 'La',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DA',\n",
       "   'postag[:2]': 'DA',\n",
       "   '-1:word.lower()': '\"',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'Fe',\n",
       "   '-1:postag[:2]': 'Fe',\n",
       "   '+1:word.lower()': 'cama',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'cama',\n",
       "   'word[-3:]': 'ama',\n",
       "   'word[-2:]': 'ma',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'la',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DA',\n",
       "   '-1:postag[:2]': 'DA',\n",
       "   '+1:word.lower()': '\"',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'Fe',\n",
       "   '+1:postag[:2]': 'Fe'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '\"',\n",
       "   'word[-3:]': '\"',\n",
       "   'word[-2:]': '\"',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'Fe',\n",
       "   'postag[:2]': 'Fe',\n",
       "   '-1:word.lower()': 'cama',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'de',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'de',\n",
       "   'word[-3:]': 'de',\n",
       "   'word[-2:]': 'de',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': '\"',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'Fe',\n",
       "   '-1:postag[:2]': 'Fe',\n",
       "   '+1:word.lower()': 'barcelona',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'barcelona',\n",
       "   'word[-3:]': 'ona',\n",
       "   'word[-2:]': 'na',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'de',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': ',',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'Fc',\n",
       "   '+1:postag[:2]': 'Fc'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': ',',\n",
       "   'word[-3:]': ',',\n",
       "   'word[-2:]': ',',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'Fc',\n",
       "   'postag[:2]': 'Fc',\n",
       "   '-1:word.lower()': 'barcelona',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'los',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DA',\n",
       "   '+1:postag[:2]': 'DA'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'los',\n",
       "   'word[-3:]': 'los',\n",
       "   'word[-2:]': 'os',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DA',\n",
       "   'postag[:2]': 'DA',\n",
       "   '-1:word.lower()': ',',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'Fc',\n",
       "   '-1:postag[:2]': 'Fc',\n",
       "   '+1:word.lower()': 'tres',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'PN',\n",
       "   '+1:postag[:2]': 'PN'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'tres',\n",
       "   'word[-3:]': 'res',\n",
       "   'word[-2:]': 'es',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PN',\n",
       "   'postag[:2]': 'PN',\n",
       "   '-1:word.lower()': 'los',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DA',\n",
       "   '-1:postag[:2]': 'DA',\n",
       "   '+1:word.lower()': 'decidieron',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMI',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'decidieron',\n",
       "   'word[-3:]': 'ron',\n",
       "   'word[-2:]': 'on',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMI',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'tres',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'PN',\n",
       "   '-1:postag[:2]': 'PN',\n",
       "   '+1:word.lower()': 'desplazarse',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'VMN',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'desplazarse',\n",
       "   'word[-3:]': 'rse',\n",
       "   'word[-2:]': 'se',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VMN',\n",
       "   'postag[:2]': 'VM',\n",
       "   '-1:word.lower()': 'decidieron',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMI',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'a',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'a',\n",
       "   'word[-3:]': 'a',\n",
       "   'word[-2:]': 'a',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'desplazarse',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'VMN',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:word.lower()': 'castelldefels',\n",
       "   '+1:word.istitle()': True,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'castelldefels',\n",
       "   'word[-3:]': 'els',\n",
       "   'word[-2:]': 'ls',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': True,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'a',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'en',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'en',\n",
       "   'word[-3:]': 'en',\n",
       "   'word[-2:]': 'en',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'castelldefels',\n",
       "   '-1:word.istitle()': True,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'el',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'DA',\n",
       "   '+1:postag[:2]': 'DA'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'el',\n",
       "   'word[-3:]': 'el',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'DA',\n",
       "   'postag[:2]': 'DA',\n",
       "   '-1:word.lower()': 'en',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': 'coche',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'coche',\n",
       "   'word[-3:]': 'che',\n",
       "   'word[-2:]': 'he',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'el',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'DA',\n",
       "   '-1:postag[:2]': 'DA',\n",
       "   '+1:word.lower()': 'del',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'SP',\n",
       "   '+1:postag[:2]': 'SP'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'del',\n",
       "   'word[-3:]': 'del',\n",
       "   'word[-2:]': 'el',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'SP',\n",
       "   'postag[:2]': 'SP',\n",
       "   '-1:word.lower()': 'coche',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:word.lower()': 'acusado',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': 'acusado',\n",
       "   'word[-3:]': 'ado',\n",
       "   'word[-2:]': 'do',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   '-1:word.lower()': 'del',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'SP',\n",
       "   '-1:postag[:2]': 'SP',\n",
       "   '+1:word.lower()': '.',\n",
       "   '+1:word.istitle()': False,\n",
       "   '+1:word.isupper()': False,\n",
       "   '+1:postag': 'Fp',\n",
       "   '+1:postag[:2]': 'Fp'},\n",
       "  {'bias': 1.0,\n",
       "   'word.lower()': '.',\n",
       "   'word[-3:]': '.',\n",
       "   'word[-2:]': '.',\n",
       "   'word.isupper()': False,\n",
       "   'word.istitle()': False,\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'Fp',\n",
       "   'postag[:2]': 'Fp',\n",
       "   '-1:word.lower()': 'acusado',\n",
       "   '-1:word.istitle()': False,\n",
       "   '-1:word.isupper()': False,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   'EOS': True}],\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3283493, 1134030]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24986/2144564245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m metrics.flat_f1_score(y_test, y_pred, \n\u001b[0m\u001b[1;32m      3\u001b[0m                       average='weighted', labels=labels)\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn_crfsuite/metrics.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_true_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my_pred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn_crfsuite/metrics.py\u001b[0m in \u001b[0;36mflat_f1_score\u001b[0;34m(y_true, y_pred, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \"\"\"\n\u001b[0;32m-> 1044\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \"\"\"\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1169\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1434\u001b[0m                                     pos_label)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3283493, 1134030]"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "source": [
    "Inspect per-class results in more detail:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n       B-LOC      0.810     0.784     0.797      1084\n       I-LOC      0.690     0.637     0.662       325\n      B-MISC      0.731     0.569     0.640       339\n      I-MISC      0.699     0.589     0.639       557\n       B-ORG      0.807     0.832     0.820      1400\n       I-ORG      0.852     0.786     0.818      1104\n       B-PER      0.850     0.884     0.867       735\n       I-PER      0.893     0.943     0.917       634\n\n   micro avg      0.813     0.787     0.799      6178\n   macro avg      0.791     0.753     0.770      6178\nweighted avg      0.809     0.787     0.796      6178\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "#print(sklearn.metrics.classification_report(\n",
    "#    y_test, y_pred, labels=sorted_labels\n",
    "#))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}