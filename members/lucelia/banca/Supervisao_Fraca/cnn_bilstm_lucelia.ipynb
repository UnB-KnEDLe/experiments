{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkprJ1eMu3F"
      },
      "source": [
        "### Instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qlZ-12rZLxHO",
        "outputId": "0221d9a4-b2de-4371-f627-5f58a263dd5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/lucelia/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2023-07-11 23:01:33.086438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Sequential\n",
        "from keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Dropout, Conv1D, MaxPooling1D, Embedding, TimeDistributed, Bidirectional,GlobalMaxPooling1D\n",
        "\n",
        "#!pip install -U gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "#!pip install livelossplot\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "\n",
        "#!pip install seqeval\n",
        "from seqeval.metrics import f1_score, classification_report, precision_score, recall_score, accuracy_score\n",
        "from seqeval.scheme import IOB2\n",
        "#! pip install plot_keras_history\n",
        "from plot_keras_history import plot_history\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./CSVs/V2/DODFCorpus_contratos_licitacoes_v2.csv', dtype=str)\n",
        "df = df.drop(['Unnamed: 0','Unnamed: 0.1'], axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Insere um espaço entre as entidade e insere um espaco apos :  : -> Processo:0...\n",
        "import re\n",
        "def correct_space_before_numeric_entities(string):\n",
        "    result = re.sub(r'([A-Za-z]:)[0-9]', r'\\1 ', string)\n",
        "    result = result.replace(\"\\n\", \" \")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['texto']= df['texto'].map(correct_space_before_numeric_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['REL_AVISO_LICITACAO', 'REL_SUSPENSAO_LICITACAO',\n",
              "       'REL_EXTRATO_CONTRATO', 'REL_ADITAMENTO_CONTRATO',\n",
              "       'REL_ANUL_REVOG_LICITACAO', 'REL_EXTRATO_CONVENIO'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tipo_rel.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Concatena o id_ato com o id_dodf\n",
        "df['id_ato'] = df['id_dodf'] + '-' + df['id_rel']\n",
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tipo_rel\n",
            "REL_EXTRATO_CONTRATO        1734\n",
            "REL_ADITAMENTO_CONTRATO     1551\n",
            "REL_AVISO_LICITACAO          639\n",
            "REL_SUSPENSAO_LICITACAO       82\n",
            "REL_ANUL_REVOG_LICITACAO      52\n",
            "REL_EXTRATO_CONVENIO          32\n",
            "Name: id_ato, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Lista o tipo de relatório\n",
        "result =df.groupby('tipo_rel')['id_ato'].nunique()\n",
        "print(result.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "tipo_ato = df.query(\"tipo_rel == 'REL_EXTRATO_CONTRATO'\").reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tipo_ent\n",
            "EXTRATO_CONTRATO            1734\n",
            "cnpj_entidade_contratada     479\n",
            "cnpj_orgao_contratante       135\n",
            "codigo_siggo                 175\n",
            "data_assinatura_contrato    1286\n",
            "entidade_contratada         1721\n",
            "fonte_recurso               1317\n",
            "natureza_despesa            1068\n",
            "nome_responsavel             185\n",
            "nota_empenho                1214\n",
            "numero_contrato             1714\n",
            "objeto_contrato             1724\n",
            "orgao_contratante           1700\n",
            "processo_gdf                1721\n",
            "programa_trabalho           1280\n",
            "unidade_orcamentaria        1045\n",
            "valor_contrato              1566\n",
            "vigencia_contrato           1664\n",
            "Name: id_ato, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Lista as entidades do tipo de ato\n",
        "result = tipo_ato.groupby('tipo_ent')['id_ato'].nunique()\n",
        "print(result)\n",
        "#print(result.sort_values(ascending=False))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Geração do IOB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucelia/Documents/GitHub/experiments/members/lucelia/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#Carrega o modelo do spacy em portugues\n",
        "from mimetypes import init\n",
        "import re\n",
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences \n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "class spacy_tokenizer():\n",
        "    def __init__(self):\n",
        "        #self.nlp = spacy.load('pt_core_news_sm', disable=[\"ner\", \"lemmatizer\"])\n",
        "        self.nlp = spacy.load('pt_core_news_sm', disable = ['parser','ner'])\n",
        "    \n",
        "    def tokenize(self, texto):\n",
        "            \n",
        "        doc = self.nlp(texto)\n",
        "        return[t.text.strip() for t in doc if t.text.strip()]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class iob_transformer():\n",
        "    \n",
        "    def __init__(self, coluna_id_ato: str, coluna_texto_entidade: str,\n",
        "                 coluna_tipo_entidade: str, keep_punctuation: bool = False,\n",
        "                 return_df: bool = False, tokenizer_tipo: str = \"Função\"):\n",
        "        self.coluna_id_ato = coluna_id_ato\n",
        "        self.coluna_texto_entidade = coluna_texto_entidade\n",
        "        self.coluna_tipo_entidade = coluna_tipo_entidade\n",
        "        self.tokenizer_tipo = tokenizer_tipo\n",
        "        if not keep_punctuation: #False\n",
        "            #self.tokenizer = RegexpTokenizer('\\w+')\n",
        "            self.tokenizer = spacy_tokenizer()\n",
        "        else:\n",
        "            self.tokenizer = False\n",
        "        self.return_df = return_df\n",
        "\n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def gera_listas_atos_iobs(self, df):\n",
        "        \n",
        "        def _inclui_tags_vazias(texto_iob):\n",
        "            texto_ato_iob = texto_iob.copy()\n",
        "            for idx, token in enumerate(texto_ato_iob):\n",
        "                if token[0:2] == 'B-':# in token:\n",
        "                    pass\n",
        "                elif token[0:2] == 'I-':# in token:\n",
        "                    pass\n",
        "                else:\n",
        "                    texto_ato_iob[idx] = 'O'\n",
        "            \n",
        "            return texto_ato_iob\n",
        "        \n",
        "        def _constroi_iob(texto_ent, tipo_ent):\n",
        "            if self.tokenizer:\n",
        "                texto_ent_tok = self.tokenizer.tokenize(texto_ent)\n",
        "                \n",
        "                \n",
        "            else:\n",
        "                texto_ent_tok = word_tokenize(texto_ent)\n",
        "            iob_entidade = []\n",
        "            for index_token, token in enumerate(texto_ent_tok):\n",
        "                # primeiro token?\n",
        "                if index_token == 0:\n",
        "                    palavra = 'B-'+ tipo_ent\n",
        "                    iob_entidade.append(palavra)\n",
        "                # é o segundo token?\n",
        "                else:\n",
        "                    palavra = 'I-'+ tipo_ent\n",
        "                    iob_entidade.append(palavra)\n",
        "            # salva tupla contendo texto tokenizado e iob correspondente\n",
        "            if self.tokenizer:\n",
        "                tup_entidade = (self.tokenizer.tokenize(texto_ent), iob_entidade)\n",
        "            \n",
        "            else:\n",
        "                tup_entidade = (word_tokenize(texto_ent), iob_entidade)\n",
        "            return tup_entidade\n",
        "        \n",
        "        def _match_iob_texto_ato(texto_entidade_tok, iob_ato):\n",
        "            texto_ato_iob = texto_entidade_tok.copy()\n",
        "            #print(iob_ato)\n",
        "            for tupla in iob_ato:\n",
        "                 # checa se o texto de referência existe\n",
        "                if tupla[0]:\n",
        "                    for i in range(len(texto_entidade_tok)):\n",
        "                        # checa se a tag existe\n",
        "                        if tupla[0][0]:\n",
        "                            # match primeiro token\n",
        "                            if texto_entidade_tok[i] == tupla[0][0]:\n",
        "                                # a sequência de tokens de texto_entidade_token na\n",
        "                                # posição encontrada é igual aos tokens da entidade?\n",
        "                                if texto_entidade_tok[i:i+len(tupla[0])] == tupla[0]:\n",
        "                                    texto_ato_iob[i:i+len(tupla[0])] = tupla[1]\n",
        "            \n",
        "            return texto_ato_iob\n",
        "\n",
        "        atos = []\n",
        "        lista_labels = []\n",
        "        id_atos = set()\n",
        "        for row in df.iterrows():\n",
        "            id_ato = df.iloc[row[0]][self.coluna_id_ato]\n",
        "            texto_ato = []\n",
        "            texto_ato_iob = []\n",
        "            if id_ato not in id_atos:\n",
        "                id_atos.add(id_ato)\n",
        "                lista_ids = list(df.query(f'{self.coluna_id_ato} == \"{id_ato}\"').index)\n",
        "                # print(lista_ids)\n",
        "                iob_ato = []\n",
        "                # todas as anotações que não são o ato inteiro\n",
        "                for index in lista_ids:\n",
        "                    texto_entidade = df.iloc[index][self.coluna_texto_entidade]\n",
        "                    tipo_entidade = df.iloc[index][self.coluna_tipo_entidade]\n",
        "                    #Lucelia if isinstance(self.tokenizer, RegexpTokenizer):\n",
        "                    if self.tokenizer_tipo == \"Função\":\n",
        "                        texto_entidade_tok = self.tokenizer.tokenize(texto_entidade)\n",
        "\n",
        "                    else:\n",
        "                        texto_entidade_tok = word_tokenize(texto_entidade)\n",
        "                    if not tipo_entidade.isupper():\n",
        "                        tup_entidade = _constroi_iob(texto_entidade, tipo_entidade)\n",
        "                        iob_ato.append(tup_entidade)\n",
        "                # anotação do ato inteiro\n",
        "                for index in lista_ids:\n",
        "                    texto_entidade = df.iloc[index][self.coluna_texto_entidade]\n",
        "                    tipo_entidade = df.iloc[index][self.coluna_tipo_entidade]\n",
        "                    #Lucelia if self.tokenizer:\n",
        "                    if self.tokenizer_tipo == \"Função\":\n",
        "                        texto_entidade_tok = self.tokenizer.tokenize(texto_entidade)\n",
        "                    else:\n",
        "                        texto_entidade_tok = word_tokenize(texto_entidade)\n",
        "                    if tipo_entidade.isupper():\n",
        "                        texto_ato = texto_entidade_tok\n",
        "                        texto_ato_iob = _match_iob_texto_ato(texto_entidade_tok, iob_ato)\n",
        "                texto_ato_iob = _inclui_tags_vazias(texto_ato_iob)\n",
        "                atos.append(texto_ato)\n",
        "                lista_labels.append(texto_ato_iob)\n",
        "        \n",
        "        return atos, lista_labels\n",
        "\n",
        "    def create_iob_df(self, atos, lista_labels):\n",
        "        rows_list = []\n",
        "        dict1 = {\n",
        "                'Sentence_idx': -1,\n",
        "                'Word': 'UNK',\n",
        "                'Tag': 'O'\n",
        "            }\n",
        "        rows_list.append(dict1)\n",
        "        id_ato = 0\n",
        "        for ato, labels in zip(atos, lista_labels):\n",
        "            for word, label in zip(ato, labels):\n",
        "                dict1 = {\n",
        "                    'Sentence_idx': id_ato,\n",
        "                    'Word': word,\n",
        "                    'Tag': label\n",
        "                }\n",
        "                rows_list.append(dict1)\n",
        "                #print(word, label)\n",
        "            id_ato += 1\n",
        "        new_df = pd.DataFrame(rows_list)\n",
        "\n",
        "        return new_df    \n",
        "    \n",
        "    def transform(self, df, **transform_params):\n",
        "        dataframe = df.copy()\n",
        "        dataframe = dataframe.reset_index(drop=True)\n",
        "        atos, lista_labels = self.gera_listas_atos_iobs(dataframe)\n",
        "        if self.return_df:\n",
        "            iob_df = self.create_iob_df(atos, lista_labels)\n",
        "            return iob_df\n",
        "        else:\n",
        "            return atos, lista_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lucelia/Documents/GitHub/experiments/members/lucelia/venv/lib/python3.9/site-packages/spacy/language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "iob = iob_transformer('id_ato','texto','tipo_ent', keep_punctuation=False, return_df=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "acts, labels = iob.transform(tipo_ato)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "#acts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3peOoU2IaZWI"
      },
      "outputs": [],
      "source": [
        "act_name = 'EXTRATO_CONVENIO' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "37jvHNfpjBuA"
      },
      "outputs": [],
      "source": [
        "max_length = 400"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QT1bvQEraCHm"
      },
      "source": [
        "### Ajustes das labels e dicionários"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Hpss6yIoal1L"
      },
      "outputs": [],
      "source": [
        "def remove_wrong_tags(label_list):\n",
        "  for label in label_list:\n",
        "    for idx,w in enumerate(label):\n",
        "      if w in ['B-11','B-12','B-50', 'B-60', 'I-2']:\n",
        "        label[idx] = 'O'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_wrong_tags(labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D6ZO2gIjcaUq"
      },
      "outputs": [],
      "source": [
        "words = set()\n",
        "\n",
        "for act in acts:\n",
        "    for word in act:\n",
        "        words.add(word)\n",
        "#convertendo o set em uma lista\n",
        "words = list(words)\n",
        "\n",
        "words.append(\"ENDPAD\")\n",
        "words.append(\"UNK\")\n",
        "\n",
        "words_amt = len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EhTG_ChofhKx"
      },
      "outputs": [],
      "source": [
        "tags = set()\n",
        "\n",
        "for label in labels:\n",
        "    for tag in label:\n",
        "        tags.add(tag)\n",
        "tags = list(tags)\n",
        "tags_amt = len(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Kcj8wAE6gqZM"
      },
      "outputs": [],
      "source": [
        "lab_enc = LabelEncoder()\n",
        "\n",
        "lab_enc.fit(words)\n",
        "words_i = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
        "\n",
        "i_words = {}\n",
        "\n",
        "for key in words_i:\n",
        "  i_words[words_i[key]] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PRkZ7eiphH5v"
      },
      "outputs": [],
      "source": [
        "lab_enc = LabelEncoder()\n",
        "\n",
        "lab_enc.fit(tags)\n",
        "tags_i = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
        "\n",
        "i_tags = {}\n",
        "\n",
        "for key in tags_i:\n",
        "  i_tags[tags_i[key]] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_data(x,y):\n",
        "    X,Y = [],[]\n",
        "\n",
        "    for act in x:\n",
        "        aux = []\n",
        "        for word in act:\n",
        "            aux.append(words_i[word])\n",
        "        X.append(aux)\n",
        "\n",
        "    for label in y:\n",
        "        aux = []\n",
        "        for word in label:\n",
        "            aux.append(tags_i[word])\n",
        "        Y.append(aux)\n",
        "\n",
        "    return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs, targets = transform_data(acts,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = pad_sequences(maxlen=max_length, sequences=inputs, padding=\"post\", value=words_i['ENDPAD'])\n",
        "targets = pad_sequences(maxlen=max_length, sequences=targets, padding=\"post\", value=tags_i[\"O\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZS0Whbtkuc7"
      },
      "source": [
        "### Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9GdbjRdJjdOJ"
      },
      "outputs": [],
      "source": [
        "def convert_values(index_array,y_test):\n",
        "  pred_tags = []\n",
        "  real_tags = []\n",
        "\n",
        "  for act in index_array:\n",
        "    act_tags = []\n",
        "    for w in act:\n",
        "      act_tags.append(i_tags[w])\n",
        "    pred_tags.append(act_tags)\n",
        "\n",
        "  for ato in y_test:\n",
        "    tags_ato = []\n",
        "    for palavra in ato:\n",
        "      tags_ato.append(i_tags[palavra])\n",
        "    real_tags.append(tags_ato)\n",
        "\n",
        "  return real_tags, pred_tags"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state = 42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6u6YTfgrqRSi"
      },
      "source": [
        "### CNN-BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Aditamento Contratual\n",
        "#cnnbilstm_lr = 0.001\n",
        "#cnnbilstm_units = 180\n",
        "#cnnbatch_size = 12\n",
        "#cnnepochs = 50\n",
        "'''\n",
        "#Aviso de Licitação\n",
        "cnnbilstm_lr = 0.0055\n",
        "cnnbilstm_units = 140\n",
        "cnnbatch_size = 5\n",
        "cnnepochs = 50\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Suspensão\n",
        "cnnbilstm_lr = 0.0065\n",
        "cnnbilstm_units = 200\n",
        "cnnbatch_size = 5\n",
        "cnnepochs = 50 \n",
        "\n",
        "#Revogação\n",
        "cnnbilstm_lr = 0.008\n",
        "cnnbilstm_units = 105\n",
        "cnnbatch_size = 5\n",
        "cnnepochs = 20\n",
        "\n",
        "\n",
        "#Extrato de Convenio\n",
        "cnnbilstm_lr = 0.003\n",
        "cnnbilstm_units = 340\n",
        "cnnbatch_size = 12\n",
        "cnnepochs = 50'''\n",
        "\n",
        "#Extrato de Contrato\n",
        "cnnbilstm_lr = 0.003\n",
        "cnnbilstm_units = 340\n",
        "cnnbatch_size = 12\n",
        "cnnepochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'EXTRATO_CONVENIO'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "act_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgJi4xoHrMCx",
        "outputId": "d268de3f-d90b-4910-f9cf-cab9adb2f45a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-11 23:12:39.292658: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "116/116 [==============================] - 264s 2s/step - loss: 0.3796 - accuracy: 0.9024\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 270s 2s/step - loss: 0.0715 - accuracy: 0.9805\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 273s 2s/step - loss: 0.0432 - accuracy: 0.9878\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 311s 3s/step - loss: 0.0311 - accuracy: 0.9912\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 268s 2s/step - loss: 0.0259 - accuracy: 0.9925\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 266s 2s/step - loss: 0.0222 - accuracy: 0.9935\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 276s 2s/step - loss: 0.0205 - accuracy: 0.9938\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 258s 2s/step - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 252s 2s/step - loss: 0.0174 - accuracy: 0.9947\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 2091s 18s/step - loss: 0.0172 - accuracy: 0.9946\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 258s 2s/step - loss: 0.0246 - accuracy: 0.9925\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 2069s 18s/step - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 252s 2s/step - loss: 0.0167 - accuracy: 0.9947\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 236s 2s/step - loss: 0.0139 - accuracy: 0.9957\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 2076s 18s/step - loss: 0.0119 - accuracy: 0.9964\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 251s 2s/step - loss: 0.0107 - accuracy: 0.9967\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 2059s 18s/step - loss: 0.0096 - accuracy: 0.9969\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 249s 2s/step - loss: 0.0097 - accuracy: 0.9970\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 247s 2s/step - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 3007s 26s/step - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 248s 2s/step - loss: 0.0082 - accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 2039s 18s/step - loss: 0.0085 - accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 263s 2s/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 244s 2s/step - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 2065s 18s/step - loss: 0.0071 - accuracy: 0.9978\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 249s 2s/step - loss: 0.0090 - accuracy: 0.9972\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 239s 2s/step - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 2076s 18s/step - loss: 0.0088 - accuracy: 0.9972\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 249s 2s/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 2063s 18s/step - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 253s 2s/step - loss: 0.0051 - accuracy: 0.9985\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 239s 2s/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 2076s 18s/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 250s 2s/step - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 2078s 18s/step - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 248s 2s/step - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 237s 2s/step - loss: 0.0071 - accuracy: 0.9978\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 2078s 18s/step - loss: 0.0088 - accuracy: 0.9972\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 250s 2s/step - loss: 0.0115 - accuracy: 0.9965\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 1519s 13s/step - loss: 0.0082 - accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 311s 3s/step - loss: 0.0065 - accuracy: 0.9982\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 338s 3s/step - loss: 0.0051 - accuracy: 0.9985\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0042 - accuracy: 0.9988\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 278s 2s/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 1251s 11s/step - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 319s 3s/step - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 330s 3s/step - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 454s 4s/step - loss: 0.0041 - accuracy: 0.9986\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 348s 3s/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 465s 4s/step - loss: 0.3937 - accuracy: 0.8963\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 340s 3s/step - loss: 0.0714 - accuracy: 0.9803\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 268s 2s/step - loss: 0.0423 - accuracy: 0.9883\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 250s 2s/step - loss: 0.0333 - accuracy: 0.9908\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 2044s 18s/step - loss: 0.0317 - accuracy: 0.9910\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 256s 2s/step - loss: 0.0244 - accuracy: 0.9933\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 252s 2s/step - loss: 0.0197 - accuracy: 0.9941\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 2042s 18s/step - loss: 0.0158 - accuracy: 0.9952\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 263s 2s/step - loss: 0.0149 - accuracy: 0.9955\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 2037s 18s/step - loss: 0.0138 - accuracy: 0.9957\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 255s 2s/step - loss: 0.0137 - accuracy: 0.9959\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 253s 2s/step - loss: 0.0131 - accuracy: 0.9960\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 1544s 13s/step - loss: 0.0120 - accuracy: 0.9963\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 293s 3s/step - loss: 0.0117 - accuracy: 0.9964\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 1120s 10s/step - loss: 0.0117 - accuracy: 0.9963\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0107 - accuracy: 0.9968\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 303s 3s/step - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 2093s 18s/step - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 301s 3s/step - loss: 0.0091 - accuracy: 0.9971\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 2084s 18s/step - loss: 0.0167 - accuracy: 0.9948\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0177 - accuracy: 0.9946\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 1678s 15s/step - loss: 0.0124 - accuracy: 0.9959\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 456s 4s/step - loss: 0.0109 - accuracy: 0.9964\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 457s 4s/step - loss: 0.0094 - accuracy: 0.9970\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 465s 4s/step - loss: 0.0076 - accuracy: 0.9976\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 276s 2s/step - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 400s 3s/step - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 328s 3s/step - loss: 0.0070 - accuracy: 0.9977\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0055 - accuracy: 0.9982\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 303s 3s/step - loss: 0.0058 - accuracy: 0.9981\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 322s 3s/step - loss: 0.0065 - accuracy: 0.9979\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 292s 3s/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 262s 2s/step - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 303s 3s/step - loss: 0.0088 - accuracy: 0.9971\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 331s 3s/step - loss: 0.0062 - accuracy: 0.9979\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.0061 - accuracy: 0.9982\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 305s 3s/step - loss: 0.0058 - accuracy: 0.9982\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 332s 3s/step - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 321s 3s/step - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0047 - accuracy: 0.9985\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 2106s 18s/step - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 325s 3s/step - loss: 0.0049 - accuracy: 0.9985\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 2113s 18s/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 323s 3s/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 2107s 18s/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 320s 3s/step - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 2107s 18s/step - loss: 0.0046 - accuracy: 0.9986\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 322s 3s/step - loss: 0.0202 - accuracy: 0.9947\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 1335s 12s/step - loss: 0.0101 - accuracy: 0.9967\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 289s 2s/step - loss: 0.3832 - accuracy: 0.9013\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 288s 2s/step - loss: 0.0749 - accuracy: 0.9799\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 2078s 18s/step - loss: 0.0431 - accuracy: 0.9886\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 324s 3s/step - loss: 0.0317 - accuracy: 0.9912\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 2101s 18s/step - loss: 0.0245 - accuracy: 0.9931\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 325s 3s/step - loss: 0.0222 - accuracy: 0.9936\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 1287s 11s/step - loss: 0.0228 - accuracy: 0.9935\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 324s 3s/step - loss: 0.0229 - accuracy: 0.9933\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 300s 3s/step - loss: 0.0190 - accuracy: 0.9944\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 2129s 3s/step - loss: 0.0182 - accuracy: 0.9946\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 305s 3s/step - loss: 0.0161 - accuracy: 0.9952\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 2115s 18s/step - loss: 0.0132 - accuracy: 0.9961\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 308s 3s/step - loss: 0.0116 - accuracy: 0.9965\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 2076s 18s/step - loss: 0.0112 - accuracy: 0.9967\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 272s 2s/step - loss: 0.0090 - accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 1338s 12s/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 351s 3s/step - loss: 0.0102 - accuracy: 0.9969\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 258s 2s/step - loss: 0.0235 - accuracy: 0.9931\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 255s 2s/step - loss: 0.0208 - accuracy: 0.9943\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 980s 9s/step - loss: 0.0131 - accuracy: 0.9960\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 284s 2s/step - loss: 0.0090 - accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 258s 2s/step - loss: 0.0077 - accuracy: 0.9977\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 259s 2s/step - loss: 0.0069 - accuracy: 0.9979\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 258s 2s/step - loss: 0.0068 - accuracy: 0.9980\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 257s 2s/step - loss: 0.0063 - accuracy: 0.9981\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 280s 2s/step - loss: 0.0054 - accuracy: 0.9983\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 260s 2s/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 253s 2s/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 259s 2s/step - loss: 0.0052 - accuracy: 0.9985\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 255s 2s/step - loss: 0.0048 - accuracy: 0.9986\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 259s 2s/step - loss: 0.0047 - accuracy: 0.9987\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 262s 2s/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 257s 2s/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 268s 2s/step - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 257s 2s/step - loss: 0.0057 - accuracy: 0.9983\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 259s 2s/step - loss: 0.0058 - accuracy: 0.9982\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 260s 2s/step - loss: 0.0055 - accuracy: 0.9983\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 260s 2s/step - loss: 0.0067 - accuracy: 0.9979\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 275s 2s/step - loss: 0.0065 - accuracy: 0.9980\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 262s 2s/step - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 259s 2s/step - loss: 0.0063 - accuracy: 0.9979\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 257s 2s/step - loss: 0.0076 - accuracy: 0.9977\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 311s 3s/step - loss: 0.0056 - accuracy: 0.9984\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 336s 3s/step - loss: 0.0049 - accuracy: 0.9985\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 300s 3s/step - loss: 0.0038 - accuracy: 0.9989\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 298s 3s/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 305s 3s/step - loss: 0.0046 - accuracy: 0.9986\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 299s 3s/step - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 300s 3s/step - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 308s 3s/step - loss: 0.3505 - accuracy: 0.9101\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0771 - accuracy: 0.9799\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0415 - accuracy: 0.9884\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 3041s 26s/step - loss: 0.0361 - accuracy: 0.9897\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 307s 3s/step - loss: 0.0320 - accuracy: 0.9908\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 2105s 18s/step - loss: 0.0270 - accuracy: 0.9922\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 305s 3s/step - loss: 0.0222 - accuracy: 0.9935\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 2080s 18s/step - loss: 0.0186 - accuracy: 0.9944\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 306s 3s/step - loss: 0.0159 - accuracy: 0.9951\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 287s 2s/step - loss: 0.0146 - accuracy: 0.9955\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 2986s 26s/step - loss: 0.0144 - accuracy: 0.9956\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 297s 3s/step - loss: 0.0131 - accuracy: 0.9960\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 2084s 18s/step - loss: 0.0120 - accuracy: 0.9962\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 302s 3s/step - loss: 0.0107 - accuracy: 0.9966\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 2081s 18s/step - loss: 0.0095 - accuracy: 0.9970\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 279s 2s/step - loss: 0.0100 - accuracy: 0.9968\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 264s 2s/step - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 297s 3s/step - loss: 0.0084 - accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 299s 3s/step - loss: 0.0107 - accuracy: 0.9966\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 2090s 18s/step - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 296s 3s/step - loss: 0.0074 - accuracy: 0.9977\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 2078s 18s/step - loss: 0.0076 - accuracy: 0.9976\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 298s 3s/step - loss: 0.0069 - accuracy: 0.9977\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 2085s 18s/step - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 324s 3s/step - loss: 0.0071 - accuracy: 0.9977\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 1565s 14s/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 355s 3s/step - loss: 0.0077 - accuracy: 0.9975\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 366s 3s/step - loss: 0.0088 - accuracy: 0.9972\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 403s 3s/step - loss: 0.0084 - accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 492s 4s/step - loss: 0.0065 - accuracy: 0.9980\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 308s 3s/step - loss: 0.0053 - accuracy: 0.9984\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 335s 3s/step - loss: 0.0064 - accuracy: 0.9980\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 304s 3s/step - loss: 0.0071 - accuracy: 0.9978\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 288s 2s/step - loss: 0.0054 - accuracy: 0.9984\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 286s 2s/step - loss: 0.0103 - accuracy: 0.9971\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 285s 2s/step - loss: 0.0100 - accuracy: 0.9969\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 285s 2s/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 286s 2s/step - loss: 0.0073 - accuracy: 0.9977\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 279s 2s/step - loss: 0.0074 - accuracy: 0.9977\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 281s 2s/step - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 289s 2s/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 231s 2s/step - loss: 0.0056 - accuracy: 0.9984\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0046 - accuracy: 0.9985\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 281s 2s/step - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 270s 2s/step - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 254s 2s/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 230s 2s/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 226s 2s/step - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 225s 2s/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0033 - accuracy: 0.9990\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 238s 2s/step - loss: 0.3911 - accuracy: 0.9034\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 225s 2s/step - loss: 0.0845 - accuracy: 0.9769\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 227s 2s/step - loss: 0.0453 - accuracy: 0.9876\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 228s 2s/step - loss: 0.0321 - accuracy: 0.9911\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0272 - accuracy: 0.9924\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0240 - accuracy: 0.9930\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0208 - accuracy: 0.9937\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 222s 2s/step - loss: 0.0190 - accuracy: 0.9942\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 224s 2s/step - loss: 0.0173 - accuracy: 0.9947\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 224s 2s/step - loss: 0.0169 - accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 225s 2s/step - loss: 0.0154 - accuracy: 0.9952\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 226s 2s/step - loss: 0.0147 - accuracy: 0.9955\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 224s 2s/step - loss: 0.0214 - accuracy: 0.9934\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 223s 2s/step - loss: 0.0168 - accuracy: 0.9948\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 225s 2s/step - loss: 0.0135 - accuracy: 0.9960\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 228s 2s/step - loss: 0.0108 - accuracy: 0.9968\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 227s 2s/step - loss: 0.0098 - accuracy: 0.9970\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 228s 2s/step - loss: 0.0086 - accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 230s 2s/step - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0075 - accuracy: 0.9976\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 236s 2s/step - loss: 0.0076 - accuracy: 0.9976\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 229s 2s/step - loss: 0.0077 - accuracy: 0.9976\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 282s 2s/step - loss: 0.0082 - accuracy: 0.9973\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 534s 5s/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 376s 3s/step - loss: 0.0091 - accuracy: 0.9970\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 307s 3s/step - loss: 0.0098 - accuracy: 0.9968\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 342s 3s/step - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 403s 3s/step - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 480s 4s/step - loss: 0.0061 - accuracy: 0.9979\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 551s 5s/step - loss: 0.0055 - accuracy: 0.9982\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 484s 4s/step - loss: 0.0057 - accuracy: 0.9980\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.0097 - accuracy: 0.9969\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 368s 3s/step - loss: 0.0068 - accuracy: 0.9977\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 374s 3s/step - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 360s 3s/step - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 358s 3s/step - loss: 0.0047 - accuracy: 0.9984\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 364s 3s/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 355s 3s/step - loss: 0.0060 - accuracy: 0.9980\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 385s 3s/step - loss: 0.0056 - accuracy: 0.9981\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 500s 4s/step - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 591s 5s/step - loss: 0.0156 - accuracy: 0.9950\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 356s 3s/step - loss: 0.0288 - accuracy: 0.9915\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 341s 3s/step - loss: 0.0109 - accuracy: 0.9965\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 360s 3s/step - loss: 0.0083 - accuracy: 0.9973\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 362s 3s/step - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 353s 3s/step - loss: 0.0065 - accuracy: 0.9979\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 357s 3s/step - loss: 0.0053 - accuracy: 0.9982\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 350s 3s/step - loss: 0.0049 - accuracy: 0.9983\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.0047 - accuracy: 0.9983\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 451s 4s/step - loss: 0.0043 - accuracy: 0.9984\n"
          ]
        }
      ],
      "source": [
        "#import os, pickle\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Conv1D, MaxPooling1D, Embedding, TimeDistributed, Bidirectional,GlobalMaxPooling1D\n",
        "\n",
        "acc_3 = []\n",
        "loss_3 = []\n",
        "f1_3 = []\n",
        "reports_3 = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        " \n",
        "  x_train = inputs[train]\n",
        "  x_test = inputs[test]\n",
        "  y_train = targets[train]\n",
        "  y_test = targets[test]\n",
        "          \n",
        "  cnn_bilstm = Sequential()\n",
        "  cnn_bilstm.add(Embedding(input_dim=words_amt, output_dim=50, input_length=max_length))\n",
        "  cnn_bilstm.add(Conv1D(filters=tags_amt, kernel_size=3, padding='same', activation='relu'))\n",
        "  cnn_bilstm.add(BatchNormalization())\n",
        "  cnn_bilstm.add(Dropout(0.5))\n",
        "  cnn_bilstm.add(Bidirectional(LSTM(cnnbilstm_units, return_sequences=True)))\n",
        "  cnn_bilstm.add(TimeDistributed(Dense(tags_amt, activation=\"softmax\")))\n",
        "\n",
        "  adam = Adam(learning_rate=cnnbilstm_lr)\n",
        "\n",
        "  cnn_bilstm.compile(optimizer=adam,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "  early_stopping = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
        "  callbacks = [early_stopping]\n",
        "\n",
        "  history = cnn_bilstm.fit(x_train,y_train,batch_size=cnnbatch_size, epochs=cnnepochs)\n",
        "\n",
        "  scores = cnn_bilstm.evaluate(x_test,y_test,verbose=0)\n",
        "  acc_3.append(scores[1])\n",
        "  loss_3.append(scores[0])\n",
        "\n",
        "  predictions = cnn_bilstm.predict(x_test, verbose=0)\n",
        "  #y_pred = cnn_bilstm.predict(x_test, verbose=0)\n",
        " \n",
        "  predictions = np.argmax(predictions, axis=-1)\n",
        "  y_pred = np.argmax(predictions, axis=-1)\n",
        "  real_tags, pred_tags = convert_values(predictions,y_test)\n",
        "  \n",
        "\n",
        "  f1_3.append(f1_score(real_tags, pred_tags))\n",
        "  reports_3.append(classification_report(real_tags, pred_tags))\n",
        "  \n",
        "  r = classification_report(real_tags,pred_tags, output_dict=True, mode='strict', scheme=IOB2)\n",
        "  \n",
        "  name =  act_name + '_f' + str(fold) +\".npy\"\n",
        "  np.save('./Results/V2/CISTI/27_06/BILSTM/'+name, r)\n",
        "\n",
        "  fold = fold + 1\n",
        "  reports_3.append(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pred_tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM1KApIvrw5k",
        "outputId": "ceac799a-f4dd-4ca4-81d9-6e9aba689974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.73837784371909"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_3[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x3Sp6dSrx37",
        "outputId": "fb92423a-3f13-4495-8838-11e6dba74119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(f1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0hX5KRKAAFa",
        "outputId": "7a7a4b79-0eda-41c2-94c1-a3c215815080"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.std(f1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'AVISO_LICITACAO'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "act_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lt7RSjdPLWTb",
        "outputId": "02ca80c3-085e-431e-a4ee-998d7e430072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "        decisao_tcdf       0.00      0.00      0.00         1\n",
            "modalidade_licitacao       0.75      0.63      0.69        19\n",
            "    nome_responsavel       0.68      0.76      0.72        17\n",
            "    numero_licitacao       0.83      0.88      0.86        17\n",
            "    objeto_licitacao       0.43      0.56      0.49        18\n",
            "     orgao_licitante       0.65      0.81      0.72        16\n",
            "        processo_gdf       0.80      0.67      0.73        12\n",
            "\n",
            "           micro avg       0.65      0.71      0.68       100\n",
            "           macro avg       0.59      0.62      0.60       100\n",
            "        weighted avg       0.68      0.71      0.69       100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(reports_3[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QT1bvQEraCHm",
        "vnJCcepIfpfQ",
        "8ZS0Whbtkuc7"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "96baed6db0003f61f4a930eafeae8ace7abdbffdf58b8c787c6463efd11f449a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
