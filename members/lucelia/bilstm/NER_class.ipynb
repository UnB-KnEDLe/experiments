{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /home/lucelia_vieira/.local/lib/python3.8/site-packages (1.10.0+cu113)\n",
      "Requirement already satisfied: torchvision in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.11.1+cu113)\n",
      "Requirement already satisfied: torchaudio in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.10.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from torchvision) (1.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: seqeval in /home/lucelia_vieira/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from seqeval) (1.23.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from seqeval) (0.24.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn==0.24 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn==0.24) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn==0.24) (1.23.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn==0.24) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn==0.24) (1.8.1)\n",
      "Requirement already satisfied: sklearn==0.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from sklearn==0.0) (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn->sklearn==0.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn->sklearn==0.0) (1.23.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn->sklearn==0.0) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from scikit-learn->sklearn==0.0) (1.8.1)\n",
      "Requirement already satisfied: sklearn-crfsuite==0.3.6 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied: tqdm>=2.0 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from sklearn-crfsuite==0.3.6) (4.64.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from sklearn-crfsuite==0.3.6) (0.9.7)\n",
      "Requirement already satisfied: tabulate in /home/lucelia_vieira/.local/lib/python3.8/site-packages (from sklearn-crfsuite==0.3.6) (0.8.9)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sklearn-crfsuite==0.3.6) (1.14.0)\n",
      "Requirement already satisfied: python-crfsuite==0.9.7 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.9.7)\n",
      "Requirement already satisfied: tqdm in /home/lucelia_vieira/.local/lib/python3.8/site-packages (4.64.0)\n",
      "Requirement already satisfied: pytorch-crf==0.7.2 in /home/lucelia_vieira/.local/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: torch-summary in /home/lucelia_vieira/.local/lib/python3.8/site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "#!virtualenv --python=python3.8 venv #rodar apenas na primeira vez que rodar o script na maquina\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install seqeval\n",
    "!pip install scikit-learn==0.24\n",
    "!pip install sklearn==0.0\n",
    "!pip install sklearn-crfsuite==0.3.6\n",
    "!pip install python-crfsuite==0.9.7\n",
    "!pip install tqdm\n",
    "!pip install pytorch-crf==0.7.2\n",
    "#!pip install torch==1.8.1\n",
    "#!pip install torch==1.11.0\n",
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created virtual environment CPython3.8.10.final.0-64 in 75ms\n",
      "  creator CPython3Posix(dest=/home/lucelia_vieira/Experimentos/bilstm/venv, clear=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/lucelia_vieira/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)\n",
      "  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\n"
     ]
    }
   ],
   "source": [
    "#!virtualenv --python=python3.8 venv\n",
    "#source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucelia_vieira/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "#from TorchCRF import CRF\n",
    "from torchcrf import CRF\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuraçao para que as variáveis não mudem quando executadas nas mesmas condições pelo modelo\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "seed = 3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "!export CUBLAS_WORKSPACE_CONFIG=:16:8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados de notícias no padrão CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_train.txt'\n",
    "sentences = open(train_path, 'r').readlines()\n",
    "\n",
    "train_path = '/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_valid.txt'\n",
    "sentences = open(train_path, 'r').readlines()\n",
    "\n",
    "train_path = '/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_test.txt'\n",
    "sentences = open(train_path, 'r').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "\n",
    "* Passo 1: Separar as palavras e as classes\n",
    "* Passo 2: Criar dicionarios de palavras e classes (utilizados para treinar o modelo neural)\n",
    "* Passo 3: Substituir as palavras pelo seu indice no dicionario criado\n",
    "* Passo 4: Adicionar tokens de inicio e final de sentenca\n",
    "* Passo 5: Criar os mini-batches de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: Separando as palavras e as classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as palavras e as classes do CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ner_set):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "\n",
    "    temp_sentence = []\n",
    "    temp_tag = []\n",
    "    for line in ner_set:\n",
    "        try:\n",
    "            word, _, _, tag = line.split()\n",
    "            temp_sentence.append(word)\n",
    "            temp_tag.append(tag)\n",
    "        except:\n",
    "            sentences.append(temp_sentence)\n",
    "            tags.append(temp_tag)\n",
    "            temp_sentence = []\n",
    "            temp_tag = []\n",
    "\n",
    "    if temp_sentence:\n",
    "        sentences.append(temp_sentence)\n",
    "        tags.append(temp_tag)\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14989, 3466, 3466)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'conll'\n",
    "\n",
    "train_x, train_y = preprocess(open('/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_train.txt', 'r'))\n",
    "valid_x, valid_y = preprocess(open('/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_valid.txt', 'r'))\n",
    "test_x, test_y = preprocess(open('/home/lucelia_vieira/Experimentos/Data/CoNLL/conll_valid.txt', 'r'))\n",
    "\n",
    "len(train_x), len(valid_x), len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .\n",
      "\n",
      "O O O O O O O B-ORG O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(train_x[10]))\n",
    "print()\n",
    "print(' '.join(train_y[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as palavras e as classes do Ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessO(ner_set):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "\n",
    "    temp_sentence = []\n",
    "    temp_tag = []\n",
    "    for line in ner_set:\n",
    "        try:\n",
    "            word, tag = line.split()\n",
    "            temp_sentence.append(word)\n",
    "            temp_tag.append(tag)\n",
    "        except:\n",
    "            sentences.append(temp_sentence)\n",
    "            tags.append(temp_tag)\n",
    "            temp_sentence = []\n",
    "            temp_tag = []\n",
    "\n",
    "    if temp_sentence:\n",
    "        sentences.append(temp_sentence)\n",
    "        tags.append(temp_tag)\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x_o, valid_y_o = preprocessO(open('/home/lucelia_vieira/Experimentos/Data/Ontonotes/ner_train_label_teste.txt', 'r'))\n",
    "len(valid_x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man showed Elisha the place where the ax head fell .\n",
      "\n",
      "O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(valid_x_o[10]))\n",
    "print()\n",
    "print(' '.join(valid_y_o[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Criando os dicionários de palavras e classes (utilizando o conjunto de treinamento)\n",
    "\n",
    "Incluindo os tokens especiais \\<UNK\\>, \\<BOS\\>, \\<EOS\\> de palavras e \\<PAD\\> para classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def word_dict(sentences):\n",
    "    word2idx = OrderedDict({'<UNK>': 0, '<PAD>': 1, '<BOS>': 2, '<EOS>': 3})\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx)\n",
    "    return word2idx\n",
    "\n",
    "def tag_dict(tag_sentences):\n",
    "    tag2idx = OrderedDict({'<PAD>': 0})\n",
    "    for tags in tag_sentences:\n",
    "        for tag in tags:\n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = len(tag2idx)\n",
    "    return tag2idx\n",
    "\n",
    "word2idx = word_dict(train_x)\n",
    "tag2idx  = tag_dict(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('<PAD>', 0),\n",
       "             ('O', 1),\n",
       "             ('B-ORG', 2),\n",
       "             ('B-MISC', 3),\n",
       "             ('B-PER', 4),\n",
       "             ('I-PER', 5),\n",
       "             ('B-LOC', 6),\n",
       "             ('I-ORG', 7),\n",
       "             ('I-MISC', 8),\n",
       "             ('I-LOC', 9)])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 0\n",
      "<PAD> 1\n",
      "<BOS> 2\n",
      "<EOS> 3\n",
      "-DOCSTART- 4\n",
      "EU 5\n",
      "rejects 6\n",
      "German 7\n",
      "call 8\n",
      "to 9\n",
      "boycott 10\n",
      "British 11\n",
      "lamb 12\n",
      ". 13\n",
      "Peter 14\n",
      "Blackburn 15\n",
      "BRUSSELS 16\n",
      "1996-08-22 17\n",
      "The 18\n",
      "European 19\n",
      "Commission 20\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(word2idx):\n",
    "    print(word, word2idx[word])\n",
    "    if idx >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de classes por dataset\n",
      "['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']\n",
      "Conjunto de treinamento: ('B-ORG', 10)\n",
      "Conjunto de treinamento: ('B-MISC', 17)\n",
      "Conjunto de treinamento: ('B-PER', 6)\n",
      "Conjunto de treinamento: ('B-LOC', 6)\n",
      "Conjunto de treinamento: ('Total de Tokens', 39)\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de classes por dataset\")\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "#print(idx2tag)\n",
    "label = list(idx2tag.values())\n",
    "label.remove('<PAD>')\n",
    "label.remove('O')\n",
    "print(label)\n",
    "\n",
    "count_org = 0\n",
    "count_misc = 0\n",
    "count_per = 0\n",
    "count_loc = 0\n",
    "\n",
    "for i in label:\n",
    "  #for j in train_y:\n",
    "  for j in valid_y_o:\n",
    "    if i in j:\n",
    "        if i in ('B-ORG','I-ORG'):\n",
    "          count_org +=1\n",
    "        if i in ('B-MISC', 'I-MISC'):\n",
    "          count_misc +=1\n",
    "        if i in ('B-PER', 'I-PER'):\n",
    "              count_per +=1\n",
    "        if i in ('B-LOC', 'I-LOC'):\n",
    "              count_loc +=1\n",
    "print(\"Conjunto de treinamento:\",('B-ORG', count_org))\n",
    "print(\"Conjunto de treinamento:\",('B-MISC', count_misc))\n",
    "print(\"Conjunto de treinamento:\",('B-PER', count_per))\n",
    "print(\"Conjunto de treinamento:\",('B-LOC', count_loc))\n",
    "\n",
    "print(\"Conjunto de treinamento:\",('Total de Tokens', count_org+count_misc+count_per+count_loc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3: Substituir as palavras e classes pelos seus indices nos dicionarios criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(sentences, word2idx, tag_sentences, tag2idx):\n",
    "    numericalized_sentences = [[word2idx['<UNK>'] if word not in word2idx else word2idx[word] for word in sentence] for sentence in sentences]\n",
    "    numericalized_tags = [[tag2idx[tag] for tag in tags] for tags in tag_sentences]\n",
    "    return numericalized_sentences, numericalized_tags\n",
    "\n",
    "train_x, train_y = numericalize(train_x, word2idx, train_y, tag2idx)\n",
    "valid_x, valid_y = numericalize(valid_x, word2idx, valid_y, tag2idx)\n",
    "test_x, test_y = numericalize(test_x, word2idx, test_y, tag2idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[335,\n",
       " 336,\n",
       " 83,\n",
       " 337,\n",
       " 338,\n",
       " 90,\n",
       " 339,\n",
       " 166,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 97,\n",
       " 266,\n",
       " 9,\n",
       " 344,\n",
       " 141,\n",
       " 345,\n",
       " 75,\n",
       " 194,\n",
       " 161,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 74,\n",
       " 350,\n",
       " 291,\n",
       " 134,\n",
       " 271,\n",
       " 351,\n",
       " 136,\n",
       " 13]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4: Adicionar tokens de inicio e final de sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,  18, 352, 353, 166,  83, 345, 354, 240, 355, 356, 357,  13,   3])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "def add_special_tokens(sentences, word2idx, tag_sentences, tag2idx):\n",
    "    formatted_sentences = [torch.LongTensor([word for word in itertools.chain([word2idx['<BOS>']], sentence, [word2idx['<EOS>']])]) for sentence in sentences]\n",
    "    formatted_tags = [torch.LongTensor([tag for tag in itertools.chain([tag2idx['O']], tags, [tag2idx['O']])]) for tags in tag_sentences]\n",
    "    return formatted_sentences, formatted_tags\n",
    "\n",
    "train_x, train_y = add_special_tokens(train_x, word2idx, train_y, tag2idx)\n",
    "valid_x, valid_y = add_special_tokens(valid_x, word2idx, valid_y, tag2idx)\n",
    "test_x, test_y   = add_special_tokens(test_x, word2idx, test_y, tag2idx)\n",
    "\n",
    "train_x[31]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 5: Criar os mini-batches de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ordenando sentencas por tamanho (antes de criar os batches)\n",
    "ordered_idx = np.argsort([len(train_x[i]) for i in range(len(train_x))])\n",
    "train_x = [train_x[idx] for idx in ordered_idx]\n",
    "train_y = [train_y[idx] for idx in ordered_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_batches(x, y, batch_size, pad_token, pad_class):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    mask = []\n",
    "\n",
    "    # Separando os batches pelo tamanho de batch_size\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "        batch_x.append(x[i:min(len(x), i+batch_size)])\n",
    "        batch_y.append(y[i:min(len(y), i+batch_size)])\n",
    "        i += batch_size\n",
    "    \n",
    "    # Realizando padding dos batches e criando mask para identificar padding durante o treinamento\n",
    "    for i in range(len(batch_x)):\n",
    "        batch_x[i] = pad_sequence(batch_x[i], batch_first = True, padding_value = pad_token)\n",
    "        batch_y[i] = pad_sequence(batch_y[i], batch_first = True, padding_value = pad_class)\n",
    "        mask.append(batch_x[i] != pad_token)\n",
    "\n",
    "    return batch_x, batch_y, mask\n",
    "\n",
    "train_x, train_y, mask = create_batches(train_x, train_y, batch_size=32, pad_token=word2idx['<PAD>'], pad_class=tag2idx['<PAD>'])\n",
    "#valid_x, _, valid_mask = create_batches(valid_x, valid_y, batch_size=32, pad_token=word2idx['<PAD>'], pad_class=tag2idx['<PAD>'])\n",
    "valid_x, _, valid_mask = create_batches(valid_x, valid_y, batch_size=32, pad_token=word2idx['<PAD>'], pad_class=tag2idx['<PAD>'])\n",
    "test_x, _, test_mask   = create_batches(test_x,  test_y,  batch_size=32,  pad_token=word2idx['<PAD>'], pad_class=tag2idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]),\n",
       " torch.Size([32, 3]),\n",
       " torch.Size([32, 3]),\n",
       " torch.Size([32, 43]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_x[0].shape, train_y[0].shape, mask[0].shape\n",
    "train_x[0].shape, train_y[0].shape, mask[0].shape, test_x[0].shape, test_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 3, 1]), tensor([ True,  True, False]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_x[0][0, :mask[0][0].sum()]\n",
    "train_x[0][0], mask[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo neural biLSTM-CRF\n",
    "\n",
    "O modelo consiste em:\n",
    "\n",
    "\n",
    "\n",
    "1.   Camada de embeddings (transforma indices das palavras em vetores numericos)\n",
    "2.   Camada biLSTM para encode da informação (-> <-)\n",
    "3.   Camada linear para reducao da dimensao do vetor de saida da camada biLSTM\n",
    "3.   Camada CRF para classificação de cada token de entrada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class bilstm_crf(torch.nn.Module):\n",
    "  \n",
    "    def __init__(self, word2idx, tag2idx):\n",
    "        super(bilstm_crf, self).__init__()\n",
    "        # Camada de embeddings\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=len(word2idx), embedding_dim = 50, padding_idx = word2idx['<PAD>'])\n",
    "        # Camada biLSTM\n",
    "        self.bilstm = torch.nn.LSTM(input_size=50, hidden_size = 200, num_layers = 2, batch_first = True, bidirectional = True, dropout = 0.25)\n",
    "        # Camada linear\n",
    "        self.linear = torch.nn.Linear(400, len(tag2idx))\n",
    "        # Camada CRF\n",
    "        self.crf = CRF(num_tags = len(tag2idx), batch_first = True)\n",
    "\n",
    "    def forward(self, x, y, mask):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm(x)\n",
    "        x = self.linear(x)\n",
    "        loss = self.crf(x, y, mask=mask)\n",
    "        return loss\n",
    "\n",
    "    def decode(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm(x)\n",
    "        x = self.linear(x)\n",
    "        prediction = self.crf.decode(x, mask=mask)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-217.1929, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = bilstm_crf(word2idx = word2idx, tag2idx = tag2idx)\n",
    "model = model.to(device)\n",
    "loss = model(train_x[0].to(device), train_y[0].to(device), mask[0].to(device))\n",
    "#prediction = model.decode(valid_y[0].to(device), valid_mask[0].to(device))\n",
    "prediction = model.decode(valid_x[0].to(device), valid_mask[0].to(device))\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 9, 3],\n",
       " [4, 9, 3, 4, 9, 3, 4, 9, 8, 3, 4, 9, 3],\n",
       " [4, 9, 3, 5],\n",
       " [4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3],\n",
       " [4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3],\n",
       " [4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [1,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5],\n",
       " [1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  5],\n",
       " [1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [1,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [9, 3, 4, 9, 8, 3, 4, 9, 3, 4, 9, 8, 3, 7, 2, 2, 2, 2, 9, 3, 4, 9, 3, 5],\n",
       " [4, 9, 1, 9, 1, 9, 1, 9, 1, 9, 3],\n",
       " [1, 9, 3],\n",
       " [4, 9, 4, 9, 8, 3, 4, 9, 3],\n",
       " [4, 9, 8, 3],\n",
       " [4, 9, 8, 3, 4, 9, 3, 4, 9, 1, 9, 1, 9, 1, 9, 3],\n",
       " [1, 9, 8, 3, 4, 9, 8, 3, 4, 9, 3, 4, 9, 3],\n",
       " [4, 9, 3, 4, 9, 8, 3, 4, 9, 8, 3, 4, 9, 3, 5],\n",
       " [9, 3, 4, 9, 3, 4, 9, 3, 5],\n",
       " [4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [1, 4, 9, 3, 4, 9, 3, 4, 9, 8, 3, 4, 9, 3, 4, 9, 1, 9, 3, 5],\n",
       " [4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3],\n",
       " [1,\n",
       "  9,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3],\n",
       " [1,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  5],\n",
       " [4, 9, 3]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save trained pytorch model\n",
    "torch.save(model.state_dict(), \"./modelo/modelo_inicial\")\n",
    "\n",
    "# # To load trained pytorch model\n",
    "# loaded_model = LSTM_CRF(embedding_dim=100, word2idx_dict=dic, num_tags=3, hidden_dim=128)\n",
    "# new_model.load_state_dict(torch.load(\"seg_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Para rodar o pyTorch no cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version 3.8.10 (default, Mar 15 2022, 12:22:08) \n",
      "[GCC 9.4.0]\n",
      "Torch Version 1.11.0+cu113\n",
      "Cuda available True\n",
      "Cuda Version 11.3\n",
      "8200\n",
      "D True\n",
      "E _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12053MB, multi_processor_count=28)\n",
      "F tensor([1., 2.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print('Python Version', sys.version)\n",
    "print('Torch Version', torch.__version__)\n",
    "print('Cuda available', torch.cuda.is_available())\n",
    "\n",
    "print('Cuda Version',torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "#print(torch.ls cuda.get_device_name(0))\n",
    "\n",
    "print('D', torch.backends.cudnn.enabled)\n",
    "device = torch.device('cuda')\n",
    "print('E', torch.cuda.get_device_properties(device))\n",
    "print('F', torch.tensor([1.0, 2.0]).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando as palavras e as classes do CoNLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para avaliação do modelo\n",
    "\n",
    "Métrica span-based f1-score (f1-score a nível de entidades)\n",
    "\n",
    "$f_1 = 2\\frac{precision\\times recall}{precision + recall}$\n",
    "\n",
    "$precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "$recall = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2177",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=6'>7</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m iob_y\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=9'>10</a>\u001b[0m y_true \u001b[39m=\u001b[39m IOBify(valid_x[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), idx2tag)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m#y_true = IOBify(valid_x[0].tolist(), idx2tag)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=12'>13</a>\u001b[0m y_pred \u001b[39m=\u001b[39m IOBify(prediction, idx2tag)\n",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 43'\u001b[0m in \u001b[0;36mIOBify\u001b[0;34m(tags_sequence, idx2tag)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIOBify\u001b[39m(tags_sequence, idx2tag):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tags_sequence[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=4'>5</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=6'>7</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 43'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIOBify\u001b[39m(tags_sequence, idx2tag):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tags_sequence[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=4'>5</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=6'>7</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 43'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIOBify\u001b[39m(tags_sequence, idx2tag):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tags_sequence[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=4'>5</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000044vscode-remote?line=6'>7</a>\u001b[0m         iob_y \u001b[39m=\u001b[39m [[idx2tag[tag\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mfor\u001b[39;00m tags \u001b[39min\u001b[39;00m tags_sequence]\n",
      "\u001b[0;31mKeyError\u001b[0m: 2177"
     ]
    }
   ],
   "source": [
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "\n",
    "def IOBify(tags_sequence, idx2tag):\n",
    "    if isinstance(tags_sequence[0], list):\n",
    "        iob_y = [[idx2tag[tag] for tag in tags] for tags in tags_sequence]\n",
    "    else:\n",
    "        iob_y = [[idx2tag[tag.item()] for tag in tags] for tags in tags_sequence]\n",
    "    return iob_y\n",
    "\n",
    "y_true = IOBify(valid_y, idx2tag)\n",
    "#y_true = IOBify(valid_x[0].tolist(), idx2tag)\n",
    "\n",
    "y_pred = IOBify(prediction, idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_x[0]), len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 9, 3],\n",
       " [3, 2, 5, 2, 5, 2, 3, 9, 0, 6, 8, 0, 5],\n",
       " [1, 6, 0, 5],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3],\n",
       " [3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  5],\n",
       " [1,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9],\n",
       " [1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  5],\n",
       " [1,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [3, 6, 6, 6, 8, 0, 6, 0, 6, 6, 0, 6, 0, 6, 0, 6, 0, 6, 0, 6, 0, 6, 9, 3],\n",
       " [3, 9, 0, 6, 6, 8, 0, 6, 9, 3, 9],\n",
       " [3, 9, 3],\n",
       " [3, 2, 5, 2, 5, 7, 9, 2, 5],\n",
       " [3, 9, 2, 5],\n",
       " [6, 0, 6, 0, 6, 0, 6, 0, 6, 7, 9, 0, 6, 0, 6, 9],\n",
       " [1, 6, 8, 0, 6, 6, 0, 6, 0, 6, 9, 3, 9, 3],\n",
       " [3, 9, 0, 6, 8, 0, 6, 6, 6, 0, 6, 0, 6, 0, 5],\n",
       " [1, 6, 8, 0, 6, 0, 6, 7, 3],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1, 6, 0, 6, 8, 0, 6, 0, 6, 9, 3, 9, 0, 6, 0, 6, 0, 6, 0, 5],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  2,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5],\n",
       " [3, 9, 3]]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 9, 3],\n",
       " [3, 2, 5, 2, 5, 2, 3, 9, 0, 6, 8, 0, 5],\n",
       " [1, 6, 0, 5],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3],\n",
       " [3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  5],\n",
       " [1,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9],\n",
       " [1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  5],\n",
       " [1,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [1,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [3,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3],\n",
       " [3, 6, 6, 6, 8, 0, 6, 0, 6, 6, 0, 6, 0, 6, 0, 6, 0, 6, 0, 6, 0, 6, 9, 3],\n",
       " [3, 9, 0, 6, 6, 8, 0, 6, 9, 3, 9],\n",
       " [3, 9, 3],\n",
       " [3, 2, 5, 2, 5, 7, 9, 2, 5],\n",
       " [3, 9, 2, 5],\n",
       " [6, 0, 6, 0, 6, 0, 6, 0, 6, 7, 9, 0, 6, 0, 6, 9],\n",
       " [1, 6, 8, 0, 6, 6, 0, 6, 0, 6, 9, 3, 9, 3],\n",
       " [3, 9, 0, 6, 8, 0, 6, 6, 6, 0, 6, 0, 6, 0, 5],\n",
       " [1, 6, 8, 0, 6, 0, 6, 7, 3],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1, 6, 0, 6, 8, 0, 6, 0, 6, 9, 3, 9, 0, 6, 0, 6, 0, 6, 0, 5],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  9,\n",
       "  2,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  9],\n",
       " [1,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5],\n",
       " [3, 9, 3]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-MISC', 'I-LOC', 'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'I-PER'],\n",
       " ['O', 'B-LOC', '<PAD>', 'I-PER'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'I-PER'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'I-PER'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC'],\n",
       " ['B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC'],\n",
       " ['B-MISC', 'I-LOC', 'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'I-ORG',\n",
       "  'I-LOC',\n",
       "  'B-ORG',\n",
       "  'I-PER'],\n",
       " ['B-MISC', 'I-LOC', 'B-ORG', 'I-PER'],\n",
       " ['B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  'B-MISC'],\n",
       " ['B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'I-PER'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'I-PER'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC',\n",
       "  'B-ORG',\n",
       "  'B-MISC',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'I-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-PER',\n",
       "  'O',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " ['O',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-MISC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  '<PAD>',\n",
       "  'B-LOC',\n",
       "  'I-ORG',\n",
       "  'B-MISC',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'I-PER'],\n",
       " ['B-MISC', 'I-LOC', 'B-MISC']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Teste Lucelia\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3466"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred), len(y_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples:\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3, 8, 4, 8, 11, 15, 6, 10, 13, 10, 11, 12, 4, 5, 3, 7, 8, 14, 6, 6, 6, 11, 4, 12, 4, 14, 12, 4, 13, 3, 13, 14, 10, 11, 14, 10, 3, 13, 8, 6, 10, 10, 10, 3, 10, 13, 10, 14, 3, 10, 4, 19, 42, 22, 36, 28, 30, 22, 30, 20, 16, 3, 8, 4, 6, 7, 15, 4, 3, 11, 4, 19, 4, 15, 9, 5, 3, 12, 4, 40, 31, 22, 19, 31, 3, 14, 5, 28, 25, 39, 9, 9, 6, 12, 41, 18, 30, 33, 21, 3, 10, 5, 34, 17, 21, 20, 3, 11, 4, 7, 7, 10, 10, 12, 17, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 11, 4, 6, 9, 6, 6, 6, 6, 6, 6, 15, 11, 16, 7, 8, 9, 8, 9, 8, 9, 8, 9, 3, 12, 5, 23, 8, 16, 8, 22, 16, 18, 19, 18, 8, 22, 18, 8, 17, 18, 19, 47, 39, 44, 22, 3, 9, 13, 9, 15, 3, 13, 10, 9, 15, 4, 3, 45, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 6, 5, 5, 4, 4, 6, 7, 7, 7, 8, 7, 4, 7, 9, 7, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 6, 6, 5, 7, 6, 3, 9, 5, 6, 14, 4, 7, 6, 7, 6, 4, 8, 6, 6, 6, 7, 7, 3, 14, 4, 5, 30, 38, 25, 13, 36, 10, 34, 34, 38, 29, 24, 39, 33, 21, 20, 15, 48, 23, 16, 14, 23, 14, 18, 20, 22, 10, 15, 10, 9, 10, 8, 12, 10, 16, 15, 12, 31, 16, 14, 16, 3, 8, 4, 33, 13, 17, 28, 36, 23, 35, 23, 11, 3, 11, 6, 5, 13, 12, 11, 5, 5, 14, 16, 15, 13, 16, 14, 4, 3, 15, 6, 37, 23, 24, 21, 21, 11, 17, 8, 10, 24, 18, 13, 17, 13, 15, 37, 47, 14, 11, 41, 16, 27, 31, 3, 15, 4, 46, 31, 14, 3, 13, 4, 4, 35, 43, 36, 16, 29, 14, 22, 17, 36, 18, 36, 3, 9, 4, 7, 9, 7, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 5, 12, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 10, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 10, 16, 14, 17, 12, 16, 13, 3, 13, 4, 28, 26, 19, 45, 15, 16, 3, 12, 5, 31, 45, 47, 49, 3, 9, 6, 23, 35, 27, 3, 11, 4, 42, 16, 39, 32, 31, 3, 12, 4, 28, 17, 3, 10, 4, 7, 12, 4, 3, 9, 7, 9, 9, 7, 7, 9, 9, 9, 9, 7, 8, 11, 13, 5, 12, 11, 4, 4, 9, 8, 7, 7, 8, 8, 7, 7, 9, 11, 13, 12, 14, 13, 7, 10, 13, 3, 13, 4, 31, 3, 12, 4, 7, 13, 12, 4, 4, 14, 14, 14, 4, 14, 12, 11, 11, 3, 10, 4, 26, 32, 32, 28, 36, 25, 20, 29, 13, 39, 10, 3, 10, 4, 7, 13, 5, 9, 3, 10, 4, 26, 12, 8, 9, 8, 8, 9, 9, 7, 9, 6, 8, 8, 6, 6, 6, 13, 10, 3, 7, 5, 31, 11, 24, 8, 3, 11, 5, 32, 31, 15, 14, 14, 11, 27, 36, 13, 33, 12, 13, 3, 13, 4, 46, 29, 30, 31, 39, 22, 13, 29, 39, 23, 20, 39, 43, 31, 30, 22, 20, 57, 3, 10, 7, 3, 44, 15, 32, 33, 39, 29, 11, 33, 34, 37, 27, 23, 19, 18, 35, 3, 13, 4, 29, 27, 46, 12, 3, 11, 4, 39, 35, 45, 41, 22, 22, 22, 3, 7, 4, 18, 32, 31, 19, 41, 22, 20, 24, 29, 21, 36, 26, 12, 31, 55, 31, 17, 19, 12, 19, 3, 9, 4, 24, 26, 43, 27, 44, 34, 23, 29, 16, 20, 30, 3, 11, 4, 23, 25, 13, 8, 24, 9, 3, 11, 4, 32, 26, 30, 27, 13, 7, 3, 11, 4, 33, 20, 8, 32, 9, 3, 9, 4, 37, 30, 27, 13, 19, 18, 3, 11, 4, 38, 20, 9, 14, 35, 32, 30, 31, 14, 33, 19, 12, 32, 3, 10, 6, 34, 39, 8, 21, 24, 36, 28, 21, 24, 22, 3, 9, 4, 38, 38, 21, 19, 13, 34, 32, 44, 3, 9, 4, 34, 37, 28, 32, 26, 11, 3, 8, 4, 4, 25, 40, 42, 32, 12, 31, 19, 37, 33, 29, 20, 27, 26, 25, 21, 3, 9, 4, 6, 33, 38, 33, 24, 20, 16, 30, 34, 28, 22, 16, 20, 22, 31, 24, 15, 35, 18, 23, 3, 9, 4, 38, 38, 21, 18, 19, 40, 17, 3, 11, 4, 26, 11, 38, 25, 26, 42, 21, 27, 3, 9, 6, 31, 39, 13, 3, 12, 4, 36, 45, 15, 9, 18, 3, 8, 4, 4, 32, 36, 44, 24, 24, 22, 27, 30, 19, 23, 23, 39, 46, 28, 13, 34, 11, 3, 12, 4, 39, 30, 43, 11, 7, 3, 9, 6, 34, 46, 28, 23, 19, 18, 30, 3, 9, 6, 24, 49, 25, 20, 16, 32, 3, 8, 5, 24, 41, 47, 15, 15, 35, 22, 3, 11, 4, 5, 30, 44, 37, 43, 25, 25, 24, 32, 32, 47, 43, 42, 19, 3, 9, 4, 4, 27, 48, 35, 21, 43, 11, 38, 26, 23, 16, 34, 24, 3, 13, 4, 5, 26, 45, 36, 23, 55, 30, 61, 35, 32, 33, 42, 36, 19, 32, 26, 48, 16, 19, 29, 25, 38, 25, 28, 43, 12, 64, 16, 12, 14, 12, 25, 22, 3, 9, 4, 4, 34, 32, 34, 35, 11, 26, 45, 41, 45, 33, 18, 38, 30, 29, 22, 44, 41, 11, 8, 30, 32, 25, 31, 19, 29, 23, 58, 23, 29, 16, 3, 9, 4, 4, 42, 34, 23, 18, 21, 28, 22, 40, 30, 32, 31, 22, 51, 31, 32, 37, 28, 19, 21, 3, 10, 4, 38, 41, 20, 29, 35, 51, 16, 23, 9, 15, 22, 24, 36, 34, 33, 51, 18, 14, 38, 25, 45, 3, 10, 4, 4, 40, 35, 22, 36, 35, 26, 13, 6, 18, 13, 38, 28, 12, 15, 26, 23, 25, 27, 38, 17, 20, 51, 3, 11, 4, 37, 29, 24, 25, 43, 23, 44, 14, 3, 13, 5, 29, 24, 36, 26, 8, 3, 11, 6, 40, 29, 46, 10, 10, 12, 7, 27, 58, 3, 8, 5, 35, 57, 42, 30, 34, 9, 30, 3, 9, 4, 28, 27, 13, 22, 11, 32, 48, 23, 26, 24, 30, 28, 21, 19, 3, 11, 4, 37, 44, 30, 16, 39, 42, 11, 28, 9, 32, 22, 3, 12, 4, 30, 22, 20, 22, 24, 3, 11, 6, 37, 20, 24, 17, 9, 13, 16, 24, 22, 23, 22, 20, 3, 12, 4, 28, 18, 27, 20, 21, 9, 7, 3, 12, 4, 8, 8, 8, 6, 11, 7, 3, 12, 4, 30, 37, 20, 13, 23, 32, 14, 29, 44, 18, 34, 24, 22, 13, 25, 19, 13, 3, 10, 5, 4, 9, 7, 5, 6, 4, 9, 7, 5, 6, 12, 8, 3, 9, 4, 7, 6, 8, 10, 9, 9, 9, 7, 28, 20, 9, 10, 11, 3, 8, 4, 23, 40, 31, 24, 21, 20, 34, 27, 36, 40, 17, 3, 10, 4, 27, 26, 24, 11, 12, 34, 3, 9, 4, 7, 10, 25, 6, 18, 46, 10, 34, 29, 17, 11, 8, 22, 17, 23, 35, 6, 13, 18, 16, 18, 22, 11, 33, 3, 11, 15, 11, 17, 17, 9, 9, 8, 6, 11, 9, 10, 11, 10, 6, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 10, 3, 11, 4, 4, 29, 25, 29, 25, 23, 23, 30, 27, 25, 16, 34, 27, 13, 30, 19, 29, 41, 32, 40, 22, 3, 10, 5, 5, 5, 9, 12, 8, 12, 8, 7, 4, 11, 29, 19, 31, 28, 47, 29, 19, 16, 11, 7, 22, 20, 7, 10, 22, 38, 31, 37, 26, 53, 21, 20, 15, 11, 23, 45, 43, 41, 23, 3, 10, 4, 4, 31, 46, 42, 34, 42, 36, 25, 20, 39, 41, 43, 38, 31, 13, 3, 10, 4, 39, 41, 9, 29, 38, 23, 14, 15, 3, 10, 4, 39, 37, 9, 29, 17, 36, 28, 30, 48, 46, 20, 21, 3, 13, 5, 39, 39, 38, 15, 31, 15, 3, 11, 4, 36, 38, 32, 15, 26, 22, 33, 35, 40, 3, 11, 4, 6, 29, 17, 33, 12, 18, 31, 23, 17, 26, 31, 22, 21, 14, 9, 30, 39, 10, 18, 16, 14, 35, 21, 26, 14, 20, 14, 8, 20, 29, 33, 14, 35, 10, 3, 11, 4, 32, 21, 36, 15, 7, 3, 12, 4, 33, 56, 32, 42, 29, 25, 8, 3, 11, 23, 15, 9, 9, 6, 3, 25, 6, 4, 34, 52, 6, 4, 29, 36, 6, 3, 41, 18, 3, 10, 4, 9, 10, 5, 8, 6, 9, 9, 13, 3, 9, 4, 9, 10, 5, 8, 6, 6, 9, 15, 3, 13, 4, 33, 35, 35, 22, 13, 15, 8, 3, 8, 4, 25, 32, 52, 24, 3, 11, 7, 23, 23, 54, 16, 24, 31, 3, 9, 5, 30, 39, 42, 24, 48, 34, 40, 33, 19, 3, 13, 7, 35, 26, 34, 29, 31, 30, 40, 38, 32, 3, 12, 6, 13, 7, 3, 12, 6, 13, 25, 6, 3, 12, 6, 32, 38, 27, 43, 3, 13, 4, 25, 30, 5, 3, 9, 6, 22, 31, 12, 13, 9, 12, 22, 53, 43, 34, 3, 12, 7, 25, 4, 12, 15, 6, 3, 14, 6, 23, 25, 3, 12, 6, 5, 14, 9, 15, 12, 11, 11, 10, 11, 10, 10, 9, 12, 11, 10, 12, 5, 10, 10, 5, 6, 11, 5, 5, 3, 10, 6, 16, 3, 11, 8, 9, 8, 7, 7, 7, 7, 8, 7, 9, 12, 13, 9, 12, 11, 8, 3, 9, 9, 8, 7, 8, 9, 9, 7, 7, 8, 8, 8, 8, 14, 4, 11, 13, 3, 9, 6, 6, 8, 10, 10, 13, 9, 9, 9, 9, 9, 9, 9, 9, 9, 35, 33, 12, 11, 9, 9, 9, 9, 9, 9, 9, 9, 10, 9, 9, 9, 9, 10, 33, 11, 4, 14, 14, 14, 15, 10, 4, 14, 7, 11, 6, 10, 7, 12, 6, 3, 14, 6, 24, 29, 27, 4, 40, 38, 3, 12, 6, 30, 23, 20, 33, 19, 23, 11, 35, 30, 29, 13, 11, 19, 14, 34, 24, 22, 11, 13, 17, 31, 16, 19, 16, 23, 47, 14, 9, 20, 37, 13, 10, 24, 14, 36, 24, 16, 13, 34, 11, 22, 25, 21, 3, 14, 4, 37, 34, 34, 40, 46, 22, 16, 3, 11, 4, 7, 13, 9, 8, 6, 9, 6, 9, 9, 6, 9, 6, 6, 9, 10, 9, 9, 10, 10, 6, 10, 6, 6, 3, 12, 4, 8, 9, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 6, 6, 6, 7, 6, 8, 6, 7, 3, 13, 4, 23, 33, 5, 3, 13, 4, 23, 10, 5, 3, 13, 4, 34, 45, 28, 32, 18, 51, 3, 8, 4, 6, 17, 10, 4, 11, 10, 11, 11, 10, 10, 10, 10, 10, 11, 4, 10, 12, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 12, 10, 11, 11, 11, 3, 8, 4, 6, 17, 11, 4, 10, 10, 10, 10, 10, 12, 10, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 11, 11, 10, 11, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 11, 10, 10, 10, 10, 10, 10, 3, 8, 4, 6, 6, 4, 7, 7, 6, 12, 4, 4, 6, 8, 6, 6, 6, 4, 6, 7, 7, 7, 8, 3, 8, 4, 7, 5, 4, 6, 6, 7, 6, 6, 7, 6, 6, 12, 10, 4, 6, 6, 7, 7, 6, 6, 6, 6, 7, 5, 7, 4, 6, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 3, 9, 4, 15, 12, 21, 9, 12, 12, 9, 12, 27, 9, 19, 40, 9, 31, 15, 33, 20, 3, 12, 4, 8, 11, 15, 7, 15, 7, 14, 13, 13, 13, 13, 14, 13, 14, 14, 3, 13, 4, 25, 4, 23, 11, 5, 3, 12, 4, 4, 36, 34, 39, 42, 29, 38, 25, 36, 34, 48, 38, 25, 46, 15, 37, 111, 95, 3, 12, 4, 27, 4, 18, 7, 14, 16, 10, 6, 9, 3, 12, 4, 36, 38, 26, 3, 13, 4, 22, 8, 3, 10, 4, 6, 8, 4, 9, 9, 9, 6, 7, 6, 16, 7, 11, 10, 13, 10, 10, 10, 10, 10, 13, 10, 13, 10, 4, 9, 10, 7, 9, 6, 15, 4, 10, 11, 10, 10, 11, 13, 10, 10, 13, 13, 10, 13, 3, 12, 6, 35, 30, 34, 19, 17, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 12, 4, 22, 4, 22, 5, 3, 14, 4, 19, 5, 3, 12, 4, 23, 4, 7, 5, 3, 9, 4, 30, 3, 12, 4, 20, 14, 5, 3, 12, 4, 22, 9, 5, 3, 11, 4, 22, 16, 5, 3, 12, 5, 29, 25, 30, 39, 19, 28, 25, 19, 23, 27, 15, 20, 21, 20, 20, 22, 22, 31, 24, 10, 18, 3, 10, 5, 54, 3, 13, 6, 31, 21, 28, 28, 20, 29, 41, 24, 28, 31, 19, 13, 9, 21, 17, 32, 17, 8, 18, 9, 13, 18, 16, 32, 34, 16, 3, 16, 4, 5, 42, 21, 21, 15, 38, 43, 9, 30, 24, 24, 19, 36, 12, 24, 21, 31, 26, 3, 12, 5, 23, 54, 24, 3, 14, 5, 23, 12, 6, 6, 5, 5, 12, 12, 5, 6, 6, 6, 3, 10, 5, 21, 4, 21, 10, 5, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 5, 5, 6, 4, 4, 6, 7, 8, 8, 9, 8, 4, 7, 9, 8, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 7, 5, 6, 6, 6, 3, 9, 5, 6, 14, 4, 7, 6, 10, 6, 7, 6, 6, 4, 10, 10, 6, 7, 11, 6, 8, 7, 3, 13, 4, 37, 35, 13, 22, 27, 24, 26, 28, 17, 14, 44, 38, 13, 24, 14, 20, 12, 13, 39, 20, 45, 14, 32, 39, 18, 24, 18, 12, 12, 36, 39, 23, 28, 29, 32, 20, 20, 26, 14, 34, 15, 26, 3, 10, 4, 5, 41, 47, 9, 32, 31, 27, 16, 9, 34, 44, 19, 9, 12, 27, 17, 21, 18, 33, 24, 14, 22, 16, 14, 3, 11, 4, 31, 3, 12, 4, 4, 38, 22, 36, 29, 26, 28, 17, 27, 31, 16, 8, 20, 19, 4, 48, 42, 3, 10, 4, 26, 3, 14, 4, 29, 42, 39, 21, 23, 47, 38, 39, 4, 93, 107, 3, 11, 4, 18, 16, 5, 3, 12, 4, 4, 32, 27, 11, 33, 43, 38, 51, 44, 34, 30, 26, 4, 85, 81, 20, 13, 20, 21, 3, 11, 4, 33, 5, 5, 3, 10, 4, 8, 8, 8, 3, 13, 4, 6, 15, 4, 4, 15, 9, 5, 3, 14, 4, 19, 5, 3, 10, 4, 35, 46, 28, 40, 3, 13, 4, 7, 14, 4, 14, 7, 14, 3, 10, 4, 28, 3, 10, 4, 7, 14, 10, 13, 10, 9, 10, 12, 7, 10, 3, 12, 4, 20, 40, 27, 27, 15, 12, 28, 3, 10, 4, 8, 6, 7, 8, 11, 3, 11, 4, 19, 4, 15, 9, 5, 3, 10, 4, 37, 45, 24, 27, 10, 21, 36, 37, 33, 3, 9, 4, 18, 9, 20, 23, 35, 26, 18, 27, 9, 21, 11, 14, 24, 24, 27, 17, 11, 25, 9, 13, 34, 10, 21, 10, 18, 24, 12, 22, 18, 18, 14, 21, 18, 15, 35, 34, 37, 3, 7, 4, 29, 36, 29, 31, 18, 12, 31, 3, 9, 6, 37, 28, 39, 29, 29, 31, 3, 10, 4, 28, 8, 20, 32, 39, 14, 20, 10, 3, 8, 4, 28, 35, 11, 23, 21, 18, 23, 27, 20, 3, 11, 4, 32, 45, 42, 23, 20, 36, 45, 3, 11, 4, 26, 34, 33, 3, 9, 4, 12, 6, 6, 25, 7, 8, 8, 8, 8, 9, 9, 8, 8, 3, 10, 5, 36, 28, 21, 32, 46, 23, 8, 35, 39, 3, 11, 4, 30, 42, 37, 34, 36, 25, 45, 24, 13, 12, 41, 3, 10, 6, 37, 17, 25, 33, 13, 22, 15, 23, 31, 3, 10, 4, 6, 33, 47, 15, 35, 3, 39, 41, 31, 21, 17, 18, 33, 44, 22, 26, 28, 17, 7, 8, 44, 3, 38, 21, 14, 3, 13, 4, 38, 41, 32, 44, 44, 35, 22, 31, 28, 31, 22, 22, 45, 9, 3, 10, 4, 26, 25, 16, 31, 3, 11, 4, 29, 30, 38, 77, 22, 27, 14, 13, 23, 21, 3, 9, 4, 37, 37, 22, 21, 31, 11, 3, 11, 5, 32, 39, 30, 21, 16, 38, 3, 11, 4, 38, 46, 46, 12, 33, 41, 23, 14, 17, 37, 26, 23, 26, 3, 12, 4, 35, 29, 15, 23, 16, 26, 21, 3, 12, 4, 4, 39, 48, 31, 36, 12, 31, 36, 36, 18, 12, 33, 14, 40, 27, 31, 22, 27, 17, 13, 20, 40, 26, 35, 26, 32, 8, 11, 3, 9, 4, 34, 16, 11, 21, 22, 32, 8, 3, 12, 4, 32, 41, 14, 16, 27, 18, 38, 10, 29, 3, 8, 4, 24, 39, 31, 38, 16, 25, 39, 29, 37, 38, 3, 9, 4, 23, 27, 24, 13, 39, 29, 38, 3, 9, 5, 36, 32, 23, 50, 11, 3, 10, 4, 29, 32, 7, 28, 18, 29, 15, 8, 3, 11, 4, 30, 8, 18, 28, 43, 13, 14, 36, 24, 29, 12, 17, 17, 3, 10, 4, 35, 50, 30, 15, 30, 30, 33, 21, 3, 9, 4, 43, 20, 29, 3, 9, 4, 18, 33, 18, 9, 3, 12, 4, 30, 28, 30, 54, 58, 32, 3, 12, 4, 35, 16, 7, 8, 27, 3, 10, 4, 14, 16, 4, 23, 17, 4, 12, 25, 9, 3, 12, 4, 41, 33, 30, 53, 19, 31, 42, 37, 25, 27, 31, 12, 3, 12, 6, 8, 21, 16, 32, 26, 21, 10, 21, 3, 12, 4, 33, 54, 12, 19, 25, 3, 12, 4, 4, 38, 57, 41, 11, 35, 23, 33, 24, 30, 21, 30, 58, 21, 37, 17, 31, 3, 9, 4, 19, 14, 14, 23, 42, 39, 3, 10, 4, 24, 33, 20, 34, 30, 12, 43, 38, 3, 12, 4, 34, 38, 38, 19, 36, 21, 15, 26, 38, 25, 32, 23, 22, 24, 3, 10, 4, 26, 45, 43, 10, 26, 8, 44, 23, 32, 3, 10, 4, 23, 18, 32, 3, 9, 4, 26, 32, 11, 27, 3, 11, 4, 26, 23, 47, 30, 9, 37, 3, 10, 4, 6, 40, 37, 31, 34, 34, 11, 6, 37, 33, 16, 20, 36, 26, 23, 14, 29, 28, 23, 10, 41, 38, 28, 3, 12, 4, 46, 11, 17, 15, 18, 22, 24, 27, 6]\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 47'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000046vscode-remote?line=0'>1</a>\u001b[0m f1_score(y_true, y_pred)\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:359\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    350\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001b[1;32m    351\u001b[0m                                                     average\u001b[39m=\u001b[39maverage,\n\u001b[1;32m    352\u001b[0m                                                     warn_for\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mf-score\u001b[39m\u001b[39m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                                     scheme\u001b[39m=\u001b[39mscheme,\n\u001b[1;32m    357\u001b[0m                                                     suffix\u001b[39m=\u001b[39msuffix)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(y_true, y_pred,\n\u001b[1;32m    360\u001b[0m                                                  average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    361\u001b[0m                                                  warn_for\u001b[39m=\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m'\u001b[39;49m,),\n\u001b[1;32m    362\u001b[0m                                                  beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    363\u001b[0m                                                  sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    364\u001b[0m                                                  zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    365\u001b[0m                                                  suffix\u001b[39m=\u001b[39;49msuffix)\n\u001b[1;32m    366\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(true_sum, \u001b[39mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[39m=\u001b[39m _precision_recall_fscore_support(\n\u001b[1;32m    131\u001b[0m     y_true, y_pred,\n\u001b[1;32m    132\u001b[0m     average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    133\u001b[0m     warn_for\u001b[39m=\u001b[39;49mwarn_for,\n\u001b[1;32m    134\u001b[0m     beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m    135\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    136\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    137\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    138\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m    139\u001b[0m     extract_tp_actual_correct\u001b[39m=\u001b[39;49mextract_tp_actual_correct\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:122\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options:\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(average_options))\n\u001b[0;32m--> 122\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    124\u001b[0m pred_sum, tp_sum, true_sum \u001b[39m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:101\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_true) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(y_pred) \u001b[39mor\u001b[39;00m len_true \u001b[39m!=\u001b[39m len_pred:\n\u001b[1;32m    100\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(len_true, len_pred)\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples:\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3, 8, 4, 8, 11, 15, 6, 10, 13, 10, 11, 12, 4, 5, 3, 7, 8, 14, 6, 6, 6, 11, 4, 12, 4, 14, 12, 4, 13, 3, 13, 14, 10, 11, 14, 10, 3, 13, 8, 6, 10, 10, 10, 3, 10, 13, 10, 14, 3, 10, 4, 19, 42, 22, 36, 28, 30, 22, 30, 20, 16, 3, 8, 4, 6, 7, 15, 4, 3, 11, 4, 19, 4, 15, 9, 5, 3, 12, 4, 40, 31, 22, 19, 31, 3, 14, 5, 28, 25, 39, 9, 9, 6, 12, 41, 18, 30, 33, 21, 3, 10, 5, 34, 17, 21, 20, 3, 11, 4, 7, 7, 10, 10, 12, 17, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 11, 4, 6, 9, 6, 6, 6, 6, 6, 6, 15, 11, 16, 7, 8, 9, 8, 9, 8, 9, 8, 9, 3, 12, 5, 23, 8, 16, 8, 22, 16, 18, 19, 18, 8, 22, 18, 8, 17, 18, 19, 47, 39, 44, 22, 3, 9, 13, 9, 15, 3, 13, 10, 9, 15, 4, 3, 45, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 6, 5, 5, 4, 4, 6, 7, 7, 7, 8, 7, 4, 7, 9, 7, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 6, 6, 5, 7, 6, 3, 9, 5, 6, 14, 4, 7, 6, 7, 6, 4, 8, 6, 6, 6, 7, 7, 3, 14, 4, 5, 30, 38, 25, 13, 36, 10, 34, 34, 38, 29, 24, 39, 33, 21, 20, 15, 48, 23, 16, 14, 23, 14, 18, 20, 22, 10, 15, 10, 9, 10, 8, 12, 10, 16, 15, 12, 31, 16, 14, 16, 3, 8, 4, 33, 13, 17, 28, 36, 23, 35, 23, 11, 3, 11, 6, 5, 13, 12, 11, 5, 5, 14, 16, 15, 13, 16, 14, 4, 3, 15, 6, 37, 23, 24, 21, 21, 11, 17, 8, 10, 24, 18, 13, 17, 13, 15, 37, 47, 14, 11, 41, 16, 27, 31, 3, 15, 4, 46, 31, 14, 3, 13, 4, 4, 35, 43, 36, 16, 29, 14, 22, 17, 36, 18, 36, 3, 9, 4, 7, 9, 7, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 5, 12, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 10, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 10, 16, 14, 17, 12, 16, 13, 3, 13, 4, 28, 26, 19, 45, 15, 16, 3, 12, 5, 31, 45, 47, 49, 3, 9, 6, 23, 35, 27, 3, 11, 4, 42, 16, 39, 32, 31, 3, 12, 4, 28, 17, 3, 10, 4, 7, 12, 4, 3, 9, 7, 9, 9, 7, 7, 9, 9, 9, 9, 7, 8, 11, 13, 5, 12, 11, 4, 4, 9, 8, 7, 7, 8, 8, 7, 7, 9, 11, 13, 12, 14, 13, 7, 10, 13, 3, 13, 4, 31, 3, 12, 4, 7, 13, 12, 4, 4, 14, 14, 14, 4, 14, 12, 11, 11, 3, 10, 4, 26, 32, 32, 28, 36, 25, 20, 29, 13, 39, 10, 3, 10, 4, 7, 13, 5, 9, 3, 10, 4, 26, 12, 8, 9, 8, 8, 9, 9, 7, 9, 6, 8, 8, 6, 6, 6, 13, 10, 3, 7, 5, 31, 11, 24, 8, 3, 11, 5, 32, 31, 15, 14, 14, 11, 27, 36, 13, 33, 12, 13, 3, 13, 4, 46, 29, 30, 31, 39, 22, 13, 29, 39, 23, 20, 39, 43, 31, 30, 22, 20, 57, 3, 10, 7, 3, 44, 15, 32, 33, 39, 29, 11, 33, 34, 37, 27, 23, 19, 18, 35, 3, 13, 4, 29, 27, 46, 12, 3, 11, 4, 39, 35, 45, 41, 22, 22, 22, 3, 7, 4, 18, 32, 31, 19, 41, 22, 20, 24, 29, 21, 36, 26, 12, 31, 55, 31, 17, 19, 12, 19, 3, 9, 4, 24, 26, 43, 27, 44, 34, 23, 29, 16, 20, 30, 3, 11, 4, 23, 25, 13, 8, 24, 9, 3, 11, 4, 32, 26, 30, 27, 13, 7, 3, 11, 4, 33, 20, 8, 32, 9, 3, 9, 4, 37, 30, 27, 13, 19, 18, 3, 11, 4, 38, 20, 9, 14, 35, 32, 30, 31, 14, 33, 19, 12, 32, 3, 10, 6, 34, 39, 8, 21, 24, 36, 28, 21, 24, 22, 3, 9, 4, 38, 38, 21, 19, 13, 34, 32, 44, 3, 9, 4, 34, 37, 28, 32, 26, 11, 3, 8, 4, 4, 25, 40, 42, 32, 12, 31, 19, 37, 33, 29, 20, 27, 26, 25, 21, 3, 9, 4, 6, 33, 38, 33, 24, 20, 16, 30, 34, 28, 22, 16, 20, 22, 31, 24, 15, 35, 18, 23, 3, 9, 4, 38, 38, 21, 18, 19, 40, 17, 3, 11, 4, 26, 11, 38, 25, 26, 42, 21, 27, 3, 9, 6, 31, 39, 13, 3, 12, 4, 36, 45, 15, 9, 18, 3, 8, 4, 4, 32, 36, 44, 24, 24, 22, 27, 30, 19, 23, 23, 39, 46, 28, 13, 34, 11, 3, 12, 4, 39, 30, 43, 11, 7, 3, 9, 6, 34, 46, 28, 23, 19, 18, 30, 3, 9, 6, 24, 49, 25, 20, 16, 32, 3, 8, 5, 24, 41, 47, 15, 15, 35, 22, 3, 11, 4, 5, 30, 44, 37, 43, 25, 25, 24, 32, 32, 47, 43, 42, 19, 3, 9, 4, 4, 27, 48, 35, 21, 43, 11, 38, 26, 23, 16, 34, 24, 3, 13, 4, 5, 26, 45, 36, 23, 55, 30, 61, 35, 32, 33, 42, 36, 19, 32, 26, 48, 16, 19, 29, 25, 38, 25, 28, 43, 12, 64, 16, 12, 14, 12, 25, 22, 3, 9, 4, 4, 34, 32, 34, 35, 11, 26, 45, 41, 45, 33, 18, 38, 30, 29, 22, 44, 41, 11, 8, 30, 32, 25, 31, 19, 29, 23, 58, 23, 29, 16, 3, 9, 4, 4, 42, 34, 23, 18, 21, 28, 22, 40, 30, 32, 31, 22, 51, 31, 32, 37, 28, 19, 21, 3, 10, 4, 38, 41, 20, 29, 35, 51, 16, 23, 9, 15, 22, 24, 36, 34, 33, 51, 18, 14, 38, 25, 45, 3, 10, 4, 4, 40, 35, 22, 36, 35, 26, 13, 6, 18, 13, 38, 28, 12, 15, 26, 23, 25, 27, 38, 17, 20, 51, 3, 11, 4, 37, 29, 24, 25, 43, 23, 44, 14, 3, 13, 5, 29, 24, 36, 26, 8, 3, 11, 6, 40, 29, 46, 10, 10, 12, 7, 27, 58, 3, 8, 5, 35, 57, 42, 30, 34, 9, 30, 3, 9, 4, 28, 27, 13, 22, 11, 32, 48, 23, 26, 24, 30, 28, 21, 19, 3, 11, 4, 37, 44, 30, 16, 39, 42, 11, 28, 9, 32, 22, 3, 12, 4, 30, 22, 20, 22, 24, 3, 11, 6, 37, 20, 24, 17, 9, 13, 16, 24, 22, 23, 22, 20, 3, 12, 4, 28, 18, 27, 20, 21, 9, 7, 3, 12, 4, 8, 8, 8, 6, 11, 7, 3, 12, 4, 30, 37, 20, 13, 23, 32, 14, 29, 44, 18, 34, 24, 22, 13, 25, 19, 13, 3, 10, 5, 4, 9, 7, 5, 6, 4, 9, 7, 5, 6, 12, 8, 3, 9, 4, 7, 6, 8, 10, 9, 9, 9, 7, 28, 20, 9, 10, 11, 3, 8, 4, 23, 40, 31, 24, 21, 20, 34, 27, 36, 40, 17, 3, 10, 4, 27, 26, 24, 11, 12, 34, 3, 9, 4, 7, 10, 25, 6, 18, 46, 10, 34, 29, 17, 11, 8, 22, 17, 23, 35, 6, 13, 18, 16, 18, 22, 11, 33, 3, 11, 15, 11, 17, 17, 9, 9, 8, 6, 11, 9, 10, 11, 10, 6, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 10, 3, 11, 4, 4, 29, 25, 29, 25, 23, 23, 30, 27, 25, 16, 34, 27, 13, 30, 19, 29, 41, 32, 40, 22, 3, 10, 5, 5, 5, 9, 12, 8, 12, 8, 7, 4, 11, 29, 19, 31, 28, 47, 29, 19, 16, 11, 7, 22, 20, 7, 10, 22, 38, 31, 37, 26, 53, 21, 20, 15, 11, 23, 45, 43, 41, 23, 3, 10, 4, 4, 31, 46, 42, 34, 42, 36, 25, 20, 39, 41, 43, 38, 31, 13, 3, 10, 4, 39, 41, 9, 29, 38, 23, 14, 15, 3, 10, 4, 39, 37, 9, 29, 17, 36, 28, 30, 48, 46, 20, 21, 3, 13, 5, 39, 39, 38, 15, 31, 15, 3, 11, 4, 36, 38, 32, 15, 26, 22, 33, 35, 40, 3, 11, 4, 6, 29, 17, 33, 12, 18, 31, 23, 17, 26, 31, 22, 21, 14, 9, 30, 39, 10, 18, 16, 14, 35, 21, 26, 14, 20, 14, 8, 20, 29, 33, 14, 35, 10, 3, 11, 4, 32, 21, 36, 15, 7, 3, 12, 4, 33, 56, 32, 42, 29, 25, 8, 3, 11, 23, 15, 9, 9, 6, 3, 25, 6, 4, 34, 52, 6, 4, 29, 36, 6, 3, 41, 18, 3, 10, 4, 9, 10, 5, 8, 6, 9, 9, 13, 3, 9, 4, 9, 10, 5, 8, 6, 6, 9, 15, 3, 13, 4, 33, 35, 35, 22, 13, 15, 8, 3, 8, 4, 25, 32, 52, 24, 3, 11, 7, 23, 23, 54, 16, 24, 31, 3, 9, 5, 30, 39, 42, 24, 48, 34, 40, 33, 19, 3, 13, 7, 35, 26, 34, 29, 31, 30, 40, 38, 32, 3, 12, 6, 13, 7, 3, 12, 6, 13, 25, 6, 3, 12, 6, 32, 38, 27, 43, 3, 13, 4, 25, 30, 5, 3, 9, 6, 22, 31, 12, 13, 9, 12, 22, 53, 43, 34, 3, 12, 7, 25, 4, 12, 15, 6, 3, 14, 6, 23, 25, 3, 12, 6, 5, 14, 9, 15, 12, 11, 11, 10, 11, 10, 10, 9, 12, 11, 10, 12, 5, 10, 10, 5, 6, 11, 5, 5, 3, 10, 6, 16, 3, 11, 8, 9, 8, 7, 7, 7, 7, 8, 7, 9, 12, 13, 9, 12, 11, 8, 3, 9, 9, 8, 7, 8, 9, 9, 7, 7, 8, 8, 8, 8, 14, 4, 11, 13, 3, 9, 6, 6, 8, 10, 10, 13, 9, 9, 9, 9, 9, 9, 9, 9, 9, 35, 33, 12, 11, 9, 9, 9, 9, 9, 9, 9, 9, 10, 9, 9, 9, 9, 10, 33, 11, 4, 14, 14, 14, 15, 10, 4, 14, 7, 11, 6, 10, 7, 12, 6, 3, 14, 6, 24, 29, 27, 4, 40, 38, 3, 12, 6, 30, 23, 20, 33, 19, 23, 11, 35, 30, 29, 13, 11, 19, 14, 34, 24, 22, 11, 13, 17, 31, 16, 19, 16, 23, 47, 14, 9, 20, 37, 13, 10, 24, 14, 36, 24, 16, 13, 34, 11, 22, 25, 21, 3, 14, 4, 37, 34, 34, 40, 46, 22, 16, 3, 11, 4, 7, 13, 9, 8, 6, 9, 6, 9, 9, 6, 9, 6, 6, 9, 10, 9, 9, 10, 10, 6, 10, 6, 6, 3, 12, 4, 8, 9, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 6, 6, 6, 7, 6, 8, 6, 7, 3, 13, 4, 23, 33, 5, 3, 13, 4, 23, 10, 5, 3, 13, 4, 34, 45, 28, 32, 18, 51, 3, 8, 4, 6, 17, 10, 4, 11, 10, 11, 11, 10, 10, 10, 10, 10, 11, 4, 10, 12, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 12, 10, 11, 11, 11, 3, 8, 4, 6, 17, 11, 4, 10, 10, 10, 10, 10, 12, 10, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 11, 11, 10, 11, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 11, 10, 10, 10, 10, 10, 10, 3, 8, 4, 6, 6, 4, 7, 7, 6, 12, 4, 4, 6, 8, 6, 6, 6, 4, 6, 7, 7, 7, 8, 3, 8, 4, 7, 5, 4, 6, 6, 7, 6, 6, 7, 6, 6, 12, 10, 4, 6, 6, 7, 7, 6, 6, 6, 6, 7, 5, 7, 4, 6, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 3, 9, 4, 15, 12, 21, 9, 12, 12, 9, 12, 27, 9, 19, 40, 9, 31, 15, 33, 20, 3, 12, 4, 8, 11, 15, 7, 15, 7, 14, 13, 13, 13, 13, 14, 13, 14, 14, 3, 13, 4, 25, 4, 23, 11, 5, 3, 12, 4, 4, 36, 34, 39, 42, 29, 38, 25, 36, 34, 48, 38, 25, 46, 15, 37, 111, 95, 3, 12, 4, 27, 4, 18, 7, 14, 16, 10, 6, 9, 3, 12, 4, 36, 38, 26, 3, 13, 4, 22, 8, 3, 10, 4, 6, 8, 4, 9, 9, 9, 6, 7, 6, 16, 7, 11, 10, 13, 10, 10, 10, 10, 10, 13, 10, 13, 10, 4, 9, 10, 7, 9, 6, 15, 4, 10, 11, 10, 10, 11, 13, 10, 10, 13, 13, 10, 13, 3, 12, 6, 35, 30, 34, 19, 17, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 12, 4, 22, 4, 22, 5, 3, 14, 4, 19, 5, 3, 12, 4, 23, 4, 7, 5, 3, 9, 4, 30, 3, 12, 4, 20, 14, 5, 3, 12, 4, 22, 9, 5, 3, 11, 4, 22, 16, 5, 3, 12, 5, 29, 25, 30, 39, 19, 28, 25, 19, 23, 27, 15, 20, 21, 20, 20, 22, 22, 31, 24, 10, 18, 3, 10, 5, 54, 3, 13, 6, 31, 21, 28, 28, 20, 29, 41, 24, 28, 31, 19, 13, 9, 21, 17, 32, 17, 8, 18, 9, 13, 18, 16, 32, 34, 16, 3, 16, 4, 5, 42, 21, 21, 15, 38, 43, 9, 30, 24, 24, 19, 36, 12, 24, 21, 31, 26, 3, 12, 5, 23, 54, 24, 3, 14, 5, 23, 12, 6, 6, 5, 5, 12, 12, 5, 6, 6, 6, 3, 10, 5, 21, 4, 21, 10, 5, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 5, 5, 6, 4, 4, 6, 7, 8, 8, 9, 8, 4, 7, 9, 8, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 7, 5, 6, 6, 6, 3, 9, 5, 6, 14, 4, 7, 6, 10, 6, 7, 6, 6, 4, 10, 10, 6, 7, 11, 6, 8, 7, 3, 13, 4, 37, 35, 13, 22, 27, 24, 26, 28, 17, 14, 44, 38, 13, 24, 14, 20, 12, 13, 39, 20, 45, 14, 32, 39, 18, 24, 18, 12, 12, 36, 39, 23, 28, 29, 32, 20, 20, 26, 14, 34, 15, 26, 3, 10, 4, 5, 41, 47, 9, 32, 31, 27, 16, 9, 34, 44, 19, 9, 12, 27, 17, 21, 18, 33, 24, 14, 22, 16, 14, 3, 11, 4, 31, 3, 12, 4, 4, 38, 22, 36, 29, 26, 28, 17, 27, 31, 16, 8, 20, 19, 4, 48, 42, 3, 10, 4, 26, 3, 14, 4, 29, 42, 39, 21, 23, 47, 38, 39, 4, 93, 107, 3, 11, 4, 18, 16, 5, 3, 12, 4, 4, 32, 27, 11, 33, 43, 38, 51, 44, 34, 30, 26, 4, 85, 81, 20, 13, 20, 21, 3, 11, 4, 33, 5, 5, 3, 10, 4, 8, 8, 8, 3, 13, 4, 6, 15, 4, 4, 15, 9, 5, 3, 14, 4, 19, 5, 3, 10, 4, 35, 46, 28, 40, 3, 13, 4, 7, 14, 4, 14, 7, 14, 3, 10, 4, 28, 3, 10, 4, 7, 14, 10, 13, 10, 9, 10, 12, 7, 10, 3, 12, 4, 20, 40, 27, 27, 15, 12, 28, 3, 10, 4, 8, 6, 7, 8, 11, 3, 11, 4, 19, 4, 15, 9, 5, 3, 10, 4, 37, 45, 24, 27, 10, 21, 36, 37, 33, 3, 9, 4, 18, 9, 20, 23, 35, 26, 18, 27, 9, 21, 11, 14, 24, 24, 27, 17, 11, 25, 9, 13, 34, 10, 21, 10, 18, 24, 12, 22, 18, 18, 14, 21, 18, 15, 35, 34, 37, 3, 7, 4, 29, 36, 29, 31, 18, 12, 31, 3, 9, 6, 37, 28, 39, 29, 29, 31, 3, 10, 4, 28, 8, 20, 32, 39, 14, 20, 10, 3, 8, 4, 28, 35, 11, 23, 21, 18, 23, 27, 20, 3, 11, 4, 32, 45, 42, 23, 20, 36, 45, 3, 11, 4, 26, 34, 33, 3, 9, 4, 12, 6, 6, 25, 7, 8, 8, 8, 8, 9, 9, 8, 8, 3, 10, 5, 36, 28, 21, 32, 46, 23, 8, 35, 39, 3, 11, 4, 30, 42, 37, 34, 36, 25, 45, 24, 13, 12, 41, 3, 10, 6, 37, 17, 25, 33, 13, 22, 15, 23, 31, 3, 10, 4, 6, 33, 47, 15, 35, 3, 39, 41, 31, 21, 17, 18, 33, 44, 22, 26, 28, 17, 7, 8, 44, 3, 38, 21, 14, 3, 13, 4, 38, 41, 32, 44, 44, 35, 22, 31, 28, 31, 22, 22, 45, 9, 3, 10, 4, 26, 25, 16, 31, 3, 11, 4, 29, 30, 38, 77, 22, 27, 14, 13, 23, 21, 3, 9, 4, 37, 37, 22, 21, 31, 11, 3, 11, 5, 32, 39, 30, 21, 16, 38, 3, 11, 4, 38, 46, 46, 12, 33, 41, 23, 14, 17, 37, 26, 23, 26, 3, 12, 4, 35, 29, 15, 23, 16, 26, 21, 3, 12, 4, 4, 39, 48, 31, 36, 12, 31, 36, 36, 18, 12, 33, 14, 40, 27, 31, 22, 27, 17, 13, 20, 40, 26, 35, 26, 32, 8, 11, 3, 9, 4, 34, 16, 11, 21, 22, 32, 8, 3, 12, 4, 32, 41, 14, 16, 27, 18, 38, 10, 29, 3, 8, 4, 24, 39, 31, 38, 16, 25, 39, 29, 37, 38, 3, 9, 4, 23, 27, 24, 13, 39, 29, 38, 3, 9, 5, 36, 32, 23, 50, 11, 3, 10, 4, 29, 32, 7, 28, 18, 29, 15, 8, 3, 11, 4, 30, 8, 18, 28, 43, 13, 14, 36, 24, 29, 12, 17, 17, 3, 10, 4, 35, 50, 30, 15, 30, 30, 33, 21, 3, 9, 4, 43, 20, 29, 3, 9, 4, 18, 33, 18, 9, 3, 12, 4, 30, 28, 30, 54, 58, 32, 3, 12, 4, 35, 16, 7, 8, 27, 3, 10, 4, 14, 16, 4, 23, 17, 4, 12, 25, 9, 3, 12, 4, 41, 33, 30, 53, 19, 31, 42, 37, 25, 27, 31, 12, 3, 12, 6, 8, 21, 16, 32, 26, 21, 10, 21, 3, 12, 4, 33, 54, 12, 19, 25, 3, 12, 4, 4, 38, 57, 41, 11, 35, 23, 33, 24, 30, 21, 30, 58, 21, 37, 17, 31, 3, 9, 4, 19, 14, 14, 23, 42, 39, 3, 10, 4, 24, 33, 20, 34, 30, 12, 43, 38, 3, 12, 4, 34, 38, 38, 19, 36, 21, 15, 26, 38, 25, 32, 23, 22, 24, 3, 10, 4, 26, 45, 43, 10, 26, 8, 44, 23, 32, 3, 10, 4, 23, 18, 32, 3, 9, 4, 26, 32, 11, 27, 3, 11, 4, 26, 23, 47, 30, 9, 37, 3, 10, 4, 6, 40, 37, 31, 34, 34, 11, 6, 37, 33, 16, 20, 36, 26, 23, 14, 29, 28, 23, 10, 41, 38, 28, 3, 12, 4, 46, 11, 17, 15, 18, 22, 24, 27, 6]\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3]"
     ]
    }
   ],
   "source": [
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 0.01\n",
    "optim = torch.optim.SGD(model.parameters(), lr=lrate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples:\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3, 8, 4, 8, 11, 15, 6, 10, 13, 10, 11, 12, 4, 5, 3, 7, 8, 14, 6, 6, 6, 11, 4, 12, 4, 14, 12, 4, 13, 3, 13, 14, 10, 11, 14, 10, 3, 13, 8, 6, 10, 10, 10, 3, 10, 13, 10, 14, 3, 10, 4, 19, 42, 22, 36, 28, 30, 22, 30, 20, 16, 3, 8, 4, 6, 7, 15, 4, 3, 11, 4, 19, 4, 15, 9, 5, 3, 12, 4, 40, 31, 22, 19, 31, 3, 14, 5, 28, 25, 39, 9, 9, 6, 12, 41, 18, 30, 33, 21, 3, 10, 5, 34, 17, 21, 20, 3, 11, 4, 7, 7, 10, 10, 12, 17, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 11, 4, 6, 9, 6, 6, 6, 6, 6, 6, 15, 11, 16, 7, 8, 9, 8, 9, 8, 9, 8, 9, 3, 12, 5, 23, 8, 16, 8, 22, 16, 18, 19, 18, 8, 22, 18, 8, 17, 18, 19, 47, 39, 44, 22, 3, 9, 13, 9, 15, 3, 13, 10, 9, 15, 4, 3, 45, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 6, 5, 5, 4, 4, 6, 7, 7, 7, 8, 7, 4, 7, 9, 7, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 6, 6, 5, 7, 6, 3, 9, 5, 6, 14, 4, 7, 6, 7, 6, 4, 8, 6, 6, 6, 7, 7, 3, 14, 4, 5, 30, 38, 25, 13, 36, 10, 34, 34, 38, 29, 24, 39, 33, 21, 20, 15, 48, 23, 16, 14, 23, 14, 18, 20, 22, 10, 15, 10, 9, 10, 8, 12, 10, 16, 15, 12, 31, 16, 14, 16, 3, 8, 4, 33, 13, 17, 28, 36, 23, 35, 23, 11, 3, 11, 6, 5, 13, 12, 11, 5, 5, 14, 16, 15, 13, 16, 14, 4, 3, 15, 6, 37, 23, 24, 21, 21, 11, 17, 8, 10, 24, 18, 13, 17, 13, 15, 37, 47, 14, 11, 41, 16, 27, 31, 3, 15, 4, 46, 31, 14, 3, 13, 4, 4, 35, 43, 36, 16, 29, 14, 22, 17, 36, 18, 36, 3, 9, 4, 7, 9, 7, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 5, 12, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 10, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 10, 16, 14, 17, 12, 16, 13, 3, 13, 4, 28, 26, 19, 45, 15, 16, 3, 12, 5, 31, 45, 47, 49, 3, 9, 6, 23, 35, 27, 3, 11, 4, 42, 16, 39, 32, 31, 3, 12, 4, 28, 17, 3, 10, 4, 7, 12, 4, 3, 9, 7, 9, 9, 7, 7, 9, 9, 9, 9, 7, 8, 11, 13, 5, 12, 11, 4, 4, 9, 8, 7, 7, 8, 8, 7, 7, 9, 11, 13, 12, 14, 13, 7, 10, 13, 3, 13, 4, 31, 3, 12, 4, 7, 13, 12, 4, 4, 14, 14, 14, 4, 14, 12, 11, 11, 3, 10, 4, 26, 32, 32, 28, 36, 25, 20, 29, 13, 39, 10, 3, 10, 4, 7, 13, 5, 9, 3, 10, 4, 26, 12, 8, 9, 8, 8, 9, 9, 7, 9, 6, 8, 8, 6, 6, 6, 13, 10, 3, 7, 5, 31, 11, 24, 8, 3, 11, 5, 32, 31, 15, 14, 14, 11, 27, 36, 13, 33, 12, 13, 3, 13, 4, 46, 29, 30, 31, 39, 22, 13, 29, 39, 23, 20, 39, 43, 31, 30, 22, 20, 57, 3, 10, 7, 3, 44, 15, 32, 33, 39, 29, 11, 33, 34, 37, 27, 23, 19, 18, 35, 3, 13, 4, 29, 27, 46, 12, 3, 11, 4, 39, 35, 45, 41, 22, 22, 22, 3, 7, 4, 18, 32, 31, 19, 41, 22, 20, 24, 29, 21, 36, 26, 12, 31, 55, 31, 17, 19, 12, 19, 3, 9, 4, 24, 26, 43, 27, 44, 34, 23, 29, 16, 20, 30, 3, 11, 4, 23, 25, 13, 8, 24, 9, 3, 11, 4, 32, 26, 30, 27, 13, 7, 3, 11, 4, 33, 20, 8, 32, 9, 3, 9, 4, 37, 30, 27, 13, 19, 18, 3, 11, 4, 38, 20, 9, 14, 35, 32, 30, 31, 14, 33, 19, 12, 32, 3, 10, 6, 34, 39, 8, 21, 24, 36, 28, 21, 24, 22, 3, 9, 4, 38, 38, 21, 19, 13, 34, 32, 44, 3, 9, 4, 34, 37, 28, 32, 26, 11, 3, 8, 4, 4, 25, 40, 42, 32, 12, 31, 19, 37, 33, 29, 20, 27, 26, 25, 21, 3, 9, 4, 6, 33, 38, 33, 24, 20, 16, 30, 34, 28, 22, 16, 20, 22, 31, 24, 15, 35, 18, 23, 3, 9, 4, 38, 38, 21, 18, 19, 40, 17, 3, 11, 4, 26, 11, 38, 25, 26, 42, 21, 27, 3, 9, 6, 31, 39, 13, 3, 12, 4, 36, 45, 15, 9, 18, 3, 8, 4, 4, 32, 36, 44, 24, 24, 22, 27, 30, 19, 23, 23, 39, 46, 28, 13, 34, 11, 3, 12, 4, 39, 30, 43, 11, 7, 3, 9, 6, 34, 46, 28, 23, 19, 18, 30, 3, 9, 6, 24, 49, 25, 20, 16, 32, 3, 8, 5, 24, 41, 47, 15, 15, 35, 22, 3, 11, 4, 5, 30, 44, 37, 43, 25, 25, 24, 32, 32, 47, 43, 42, 19, 3, 9, 4, 4, 27, 48, 35, 21, 43, 11, 38, 26, 23, 16, 34, 24, 3, 13, 4, 5, 26, 45, 36, 23, 55, 30, 61, 35, 32, 33, 42, 36, 19, 32, 26, 48, 16, 19, 29, 25, 38, 25, 28, 43, 12, 64, 16, 12, 14, 12, 25, 22, 3, 9, 4, 4, 34, 32, 34, 35, 11, 26, 45, 41, 45, 33, 18, 38, 30, 29, 22, 44, 41, 11, 8, 30, 32, 25, 31, 19, 29, 23, 58, 23, 29, 16, 3, 9, 4, 4, 42, 34, 23, 18, 21, 28, 22, 40, 30, 32, 31, 22, 51, 31, 32, 37, 28, 19, 21, 3, 10, 4, 38, 41, 20, 29, 35, 51, 16, 23, 9, 15, 22, 24, 36, 34, 33, 51, 18, 14, 38, 25, 45, 3, 10, 4, 4, 40, 35, 22, 36, 35, 26, 13, 6, 18, 13, 38, 28, 12, 15, 26, 23, 25, 27, 38, 17, 20, 51, 3, 11, 4, 37, 29, 24, 25, 43, 23, 44, 14, 3, 13, 5, 29, 24, 36, 26, 8, 3, 11, 6, 40, 29, 46, 10, 10, 12, 7, 27, 58, 3, 8, 5, 35, 57, 42, 30, 34, 9, 30, 3, 9, 4, 28, 27, 13, 22, 11, 32, 48, 23, 26, 24, 30, 28, 21, 19, 3, 11, 4, 37, 44, 30, 16, 39, 42, 11, 28, 9, 32, 22, 3, 12, 4, 30, 22, 20, 22, 24, 3, 11, 6, 37, 20, 24, 17, 9, 13, 16, 24, 22, 23, 22, 20, 3, 12, 4, 28, 18, 27, 20, 21, 9, 7, 3, 12, 4, 8, 8, 8, 6, 11, 7, 3, 12, 4, 30, 37, 20, 13, 23, 32, 14, 29, 44, 18, 34, 24, 22, 13, 25, 19, 13, 3, 10, 5, 4, 9, 7, 5, 6, 4, 9, 7, 5, 6, 12, 8, 3, 9, 4, 7, 6, 8, 10, 9, 9, 9, 7, 28, 20, 9, 10, 11, 3, 8, 4, 23, 40, 31, 24, 21, 20, 34, 27, 36, 40, 17, 3, 10, 4, 27, 26, 24, 11, 12, 34, 3, 9, 4, 7, 10, 25, 6, 18, 46, 10, 34, 29, 17, 11, 8, 22, 17, 23, 35, 6, 13, 18, 16, 18, 22, 11, 33, 3, 11, 15, 11, 17, 17, 9, 9, 8, 6, 11, 9, 10, 11, 10, 6, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 10, 3, 11, 4, 4, 29, 25, 29, 25, 23, 23, 30, 27, 25, 16, 34, 27, 13, 30, 19, 29, 41, 32, 40, 22, 3, 10, 5, 5, 5, 9, 12, 8, 12, 8, 7, 4, 11, 29, 19, 31, 28, 47, 29, 19, 16, 11, 7, 22, 20, 7, 10, 22, 38, 31, 37, 26, 53, 21, 20, 15, 11, 23, 45, 43, 41, 23, 3, 10, 4, 4, 31, 46, 42, 34, 42, 36, 25, 20, 39, 41, 43, 38, 31, 13, 3, 10, 4, 39, 41, 9, 29, 38, 23, 14, 15, 3, 10, 4, 39, 37, 9, 29, 17, 36, 28, 30, 48, 46, 20, 21, 3, 13, 5, 39, 39, 38, 15, 31, 15, 3, 11, 4, 36, 38, 32, 15, 26, 22, 33, 35, 40, 3, 11, 4, 6, 29, 17, 33, 12, 18, 31, 23, 17, 26, 31, 22, 21, 14, 9, 30, 39, 10, 18, 16, 14, 35, 21, 26, 14, 20, 14, 8, 20, 29, 33, 14, 35, 10, 3, 11, 4, 32, 21, 36, 15, 7, 3, 12, 4, 33, 56, 32, 42, 29, 25, 8, 3, 11, 23, 15, 9, 9, 6, 3, 25, 6, 4, 34, 52, 6, 4, 29, 36, 6, 3, 41, 18, 3, 10, 4, 9, 10, 5, 8, 6, 9, 9, 13, 3, 9, 4, 9, 10, 5, 8, 6, 6, 9, 15, 3, 13, 4, 33, 35, 35, 22, 13, 15, 8, 3, 8, 4, 25, 32, 52, 24, 3, 11, 7, 23, 23, 54, 16, 24, 31, 3, 9, 5, 30, 39, 42, 24, 48, 34, 40, 33, 19, 3, 13, 7, 35, 26, 34, 29, 31, 30, 40, 38, 32, 3, 12, 6, 13, 7, 3, 12, 6, 13, 25, 6, 3, 12, 6, 32, 38, 27, 43, 3, 13, 4, 25, 30, 5, 3, 9, 6, 22, 31, 12, 13, 9, 12, 22, 53, 43, 34, 3, 12, 7, 25, 4, 12, 15, 6, 3, 14, 6, 23, 25, 3, 12, 6, 5, 14, 9, 15, 12, 11, 11, 10, 11, 10, 10, 9, 12, 11, 10, 12, 5, 10, 10, 5, 6, 11, 5, 5, 3, 10, 6, 16, 3, 11, 8, 9, 8, 7, 7, 7, 7, 8, 7, 9, 12, 13, 9, 12, 11, 8, 3, 9, 9, 8, 7, 8, 9, 9, 7, 7, 8, 8, 8, 8, 14, 4, 11, 13, 3, 9, 6, 6, 8, 10, 10, 13, 9, 9, 9, 9, 9, 9, 9, 9, 9, 35, 33, 12, 11, 9, 9, 9, 9, 9, 9, 9, 9, 10, 9, 9, 9, 9, 10, 33, 11, 4, 14, 14, 14, 15, 10, 4, 14, 7, 11, 6, 10, 7, 12, 6, 3, 14, 6, 24, 29, 27, 4, 40, 38, 3, 12, 6, 30, 23, 20, 33, 19, 23, 11, 35, 30, 29, 13, 11, 19, 14, 34, 24, 22, 11, 13, 17, 31, 16, 19, 16, 23, 47, 14, 9, 20, 37, 13, 10, 24, 14, 36, 24, 16, 13, 34, 11, 22, 25, 21, 3, 14, 4, 37, 34, 34, 40, 46, 22, 16, 3, 11, 4, 7, 13, 9, 8, 6, 9, 6, 9, 9, 6, 9, 6, 6, 9, 10, 9, 9, 10, 10, 6, 10, 6, 6, 3, 12, 4, 8, 9, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 6, 6, 6, 7, 6, 8, 6, 7, 3, 13, 4, 23, 33, 5, 3, 13, 4, 23, 10, 5, 3, 13, 4, 34, 45, 28, 32, 18, 51, 3, 8, 4, 6, 17, 10, 4, 11, 10, 11, 11, 10, 10, 10, 10, 10, 11, 4, 10, 12, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 12, 10, 11, 11, 11, 3, 8, 4, 6, 17, 11, 4, 10, 10, 10, 10, 10, 12, 10, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 11, 11, 10, 11, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 11, 10, 10, 10, 10, 10, 10, 3, 8, 4, 6, 6, 4, 7, 7, 6, 12, 4, 4, 6, 8, 6, 6, 6, 4, 6, 7, 7, 7, 8, 3, 8, 4, 7, 5, 4, 6, 6, 7, 6, 6, 7, 6, 6, 12, 10, 4, 6, 6, 7, 7, 6, 6, 6, 6, 7, 5, 7, 4, 6, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 3, 9, 4, 15, 12, 21, 9, 12, 12, 9, 12, 27, 9, 19, 40, 9, 31, 15, 33, 20, 3, 12, 4, 8, 11, 15, 7, 15, 7, 14, 13, 13, 13, 13, 14, 13, 14, 14, 3, 13, 4, 25, 4, 23, 11, 5, 3, 12, 4, 4, 36, 34, 39, 42, 29, 38, 25, 36, 34, 48, 38, 25, 46, 15, 37, 111, 95, 3, 12, 4, 27, 4, 18, 7, 14, 16, 10, 6, 9, 3, 12, 4, 36, 38, 26, 3, 13, 4, 22, 8, 3, 10, 4, 6, 8, 4, 9, 9, 9, 6, 7, 6, 16, 7, 11, 10, 13, 10, 10, 10, 10, 10, 13, 10, 13, 10, 4, 9, 10, 7, 9, 6, 15, 4, 10, 11, 10, 10, 11, 13, 10, 10, 13, 13, 10, 13, 3, 12, 6, 35, 30, 34, 19, 17, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 12, 4, 22, 4, 22, 5, 3, 14, 4, 19, 5, 3, 12, 4, 23, 4, 7, 5, 3, 9, 4, 30, 3, 12, 4, 20, 14, 5, 3, 12, 4, 22, 9, 5, 3, 11, 4, 22, 16, 5, 3, 12, 5, 29, 25, 30, 39, 19, 28, 25, 19, 23, 27, 15, 20, 21, 20, 20, 22, 22, 31, 24, 10, 18, 3, 10, 5, 54, 3, 13, 6, 31, 21, 28, 28, 20, 29, 41, 24, 28, 31, 19, 13, 9, 21, 17, 32, 17, 8, 18, 9, 13, 18, 16, 32, 34, 16, 3, 16, 4, 5, 42, 21, 21, 15, 38, 43, 9, 30, 24, 24, 19, 36, 12, 24, 21, 31, 26, 3, 12, 5, 23, 54, 24, 3, 14, 5, 23, 12, 6, 6, 5, 5, 12, 12, 5, 6, 6, 6, 3, 10, 5, 21, 4, 21, 10, 5, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 5, 5, 6, 4, 4, 6, 7, 8, 8, 9, 8, 4, 7, 9, 8, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 7, 5, 6, 6, 6, 3, 9, 5, 6, 14, 4, 7, 6, 10, 6, 7, 6, 6, 4, 10, 10, 6, 7, 11, 6, 8, 7, 3, 13, 4, 37, 35, 13, 22, 27, 24, 26, 28, 17, 14, 44, 38, 13, 24, 14, 20, 12, 13, 39, 20, 45, 14, 32, 39, 18, 24, 18, 12, 12, 36, 39, 23, 28, 29, 32, 20, 20, 26, 14, 34, 15, 26, 3, 10, 4, 5, 41, 47, 9, 32, 31, 27, 16, 9, 34, 44, 19, 9, 12, 27, 17, 21, 18, 33, 24, 14, 22, 16, 14, 3, 11, 4, 31, 3, 12, 4, 4, 38, 22, 36, 29, 26, 28, 17, 27, 31, 16, 8, 20, 19, 4, 48, 42, 3, 10, 4, 26, 3, 14, 4, 29, 42, 39, 21, 23, 47, 38, 39, 4, 93, 107, 3, 11, 4, 18, 16, 5, 3, 12, 4, 4, 32, 27, 11, 33, 43, 38, 51, 44, 34, 30, 26, 4, 85, 81, 20, 13, 20, 21, 3, 11, 4, 33, 5, 5, 3, 10, 4, 8, 8, 8, 3, 13, 4, 6, 15, 4, 4, 15, 9, 5, 3, 14, 4, 19, 5, 3, 10, 4, 35, 46, 28, 40, 3, 13, 4, 7, 14, 4, 14, 7, 14, 3, 10, 4, 28, 3, 10, 4, 7, 14, 10, 13, 10, 9, 10, 12, 7, 10, 3, 12, 4, 20, 40, 27, 27, 15, 12, 28, 3, 10, 4, 8, 6, 7, 8, 11, 3, 11, 4, 19, 4, 15, 9, 5, 3, 10, 4, 37, 45, 24, 27, 10, 21, 36, 37, 33, 3, 9, 4, 18, 9, 20, 23, 35, 26, 18, 27, 9, 21, 11, 14, 24, 24, 27, 17, 11, 25, 9, 13, 34, 10, 21, 10, 18, 24, 12, 22, 18, 18, 14, 21, 18, 15, 35, 34, 37, 3, 7, 4, 29, 36, 29, 31, 18, 12, 31, 3, 9, 6, 37, 28, 39, 29, 29, 31, 3, 10, 4, 28, 8, 20, 32, 39, 14, 20, 10, 3, 8, 4, 28, 35, 11, 23, 21, 18, 23, 27, 20, 3, 11, 4, 32, 45, 42, 23, 20, 36, 45, 3, 11, 4, 26, 34, 33, 3, 9, 4, 12, 6, 6, 25, 7, 8, 8, 8, 8, 9, 9, 8, 8, 3, 10, 5, 36, 28, 21, 32, 46, 23, 8, 35, 39, 3, 11, 4, 30, 42, 37, 34, 36, 25, 45, 24, 13, 12, 41, 3, 10, 6, 37, 17, 25, 33, 13, 22, 15, 23, 31, 3, 10, 4, 6, 33, 47, 15, 35, 3, 39, 41, 31, 21, 17, 18, 33, 44, 22, 26, 28, 17, 7, 8, 44, 3, 38, 21, 14, 3, 13, 4, 38, 41, 32, 44, 44, 35, 22, 31, 28, 31, 22, 22, 45, 9, 3, 10, 4, 26, 25, 16, 31, 3, 11, 4, 29, 30, 38, 77, 22, 27, 14, 13, 23, 21, 3, 9, 4, 37, 37, 22, 21, 31, 11, 3, 11, 5, 32, 39, 30, 21, 16, 38, 3, 11, 4, 38, 46, 46, 12, 33, 41, 23, 14, 17, 37, 26, 23, 26, 3, 12, 4, 35, 29, 15, 23, 16, 26, 21, 3, 12, 4, 4, 39, 48, 31, 36, 12, 31, 36, 36, 18, 12, 33, 14, 40, 27, 31, 22, 27, 17, 13, 20, 40, 26, 35, 26, 32, 8, 11, 3, 9, 4, 34, 16, 11, 21, 22, 32, 8, 3, 12, 4, 32, 41, 14, 16, 27, 18, 38, 10, 29, 3, 8, 4, 24, 39, 31, 38, 16, 25, 39, 29, 37, 38, 3, 9, 4, 23, 27, 24, 13, 39, 29, 38, 3, 9, 5, 36, 32, 23, 50, 11, 3, 10, 4, 29, 32, 7, 28, 18, 29, 15, 8, 3, 11, 4, 30, 8, 18, 28, 43, 13, 14, 36, 24, 29, 12, 17, 17, 3, 10, 4, 35, 50, 30, 15, 30, 30, 33, 21, 3, 9, 4, 43, 20, 29, 3, 9, 4, 18, 33, 18, 9, 3, 12, 4, 30, 28, 30, 54, 58, 32, 3, 12, 4, 35, 16, 7, 8, 27, 3, 10, 4, 14, 16, 4, 23, 17, 4, 12, 25, 9, 3, 12, 4, 41, 33, 30, 53, 19, 31, 42, 37, 25, 27, 31, 12, 3, 12, 6, 8, 21, 16, 32, 26, 21, 10, 21, 3, 12, 4, 33, 54, 12, 19, 25, 3, 12, 4, 4, 38, 57, 41, 11, 35, 23, 33, 24, 30, 21, 30, 58, 21, 37, 17, 31, 3, 9, 4, 19, 14, 14, 23, 42, 39, 3, 10, 4, 24, 33, 20, 34, 30, 12, 43, 38, 3, 12, 4, 34, 38, 38, 19, 36, 21, 15, 26, 38, 25, 32, 23, 22, 24, 3, 10, 4, 26, 45, 43, 10, 26, 8, 44, 23, 32, 3, 10, 4, 23, 18, 32, 3, 9, 4, 26, 32, 11, 27, 3, 11, 4, 26, 23, 47, 30, 9, 37, 3, 10, 4, 6, 40, 37, 31, 34, 34, 11, 6, 37, 33, 16, 20, 36, 26, 23, 14, 29, 28, 23, 10, 41, 38, 28, 3, 12, 4, 46, 11, 17, 15, 18, 22, 24, 27, 6]\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000049vscode-remote?line=25'>26</a>\u001b[0m y_pred \u001b[39m=\u001b[39m IOBify(y_pred, idx2tag)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000049vscode-remote?line=26'>27</a>\u001b[0m y_true \u001b[39m=\u001b[39m IOBify(valid_y, idx2tag)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000049vscode-remote?line=27'>28</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_true, y_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000049vscode-remote?line=28'>29</a>\u001b[0m f1_history\u001b[39m.\u001b[39mappend(f1)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B164.41.76.28_luc/home/lucelia_vieira/Experimentos/bilstm/NER_class.ipynb#ch0000049vscode-remote?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Loss media: \u001b[39m\u001b[39m{\u001b[39;00mmean_loss\u001b[39m}\u001b[39;00m\u001b[39m | f1-score: \u001b[39m\u001b[39m{\u001b[39;00mf1\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:359\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    350\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001b[1;32m    351\u001b[0m                                                     average\u001b[39m=\u001b[39maverage,\n\u001b[1;32m    352\u001b[0m                                                     warn_for\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mf-score\u001b[39m\u001b[39m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                                     scheme\u001b[39m=\u001b[39mscheme,\n\u001b[1;32m    357\u001b[0m                                                     suffix\u001b[39m=\u001b[39msuffix)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(y_true, y_pred,\n\u001b[1;32m    360\u001b[0m                                                  average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    361\u001b[0m                                                  warn_for\u001b[39m=\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m'\u001b[39;49m,),\n\u001b[1;32m    362\u001b[0m                                                  beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    363\u001b[0m                                                  sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    364\u001b[0m                                                  zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    365\u001b[0m                                                  suffix\u001b[39m=\u001b[39;49msuffix)\n\u001b[1;32m    366\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(true_sum, \u001b[39mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[39m=\u001b[39m _precision_recall_fscore_support(\n\u001b[1;32m    131\u001b[0m     y_true, y_pred,\n\u001b[1;32m    132\u001b[0m     average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    133\u001b[0m     warn_for\u001b[39m=\u001b[39;49mwarn_for,\n\u001b[1;32m    134\u001b[0m     beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m    135\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    136\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    137\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    138\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m    139\u001b[0m     extract_tp_actual_correct\u001b[39m=\u001b[39;49mextract_tp_actual_correct\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:122\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options:\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(average_options))\n\u001b[0;32m--> 122\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    124\u001b[0m pred_sum, tp_sum, true_sum \u001b[39m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Experimentos/bilstm/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:101\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_true) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(y_pred) \u001b[39mor\u001b[39;00m len_true \u001b[39m!=\u001b[39m len_pred:\n\u001b[1;32m    100\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(len_true, len_pred)\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples:\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3, 8, 4, 8, 11, 15, 6, 10, 13, 10, 11, 12, 4, 5, 3, 7, 8, 14, 6, 6, 6, 11, 4, 12, 4, 14, 12, 4, 13, 3, 13, 14, 10, 11, 14, 10, 3, 13, 8, 6, 10, 10, 10, 3, 10, 13, 10, 14, 3, 10, 4, 19, 42, 22, 36, 28, 30, 22, 30, 20, 16, 3, 8, 4, 6, 7, 15, 4, 3, 11, 4, 19, 4, 15, 9, 5, 3, 12, 4, 40, 31, 22, 19, 31, 3, 14, 5, 28, 25, 39, 9, 9, 6, 12, 41, 18, 30, 33, 21, 3, 10, 5, 34, 17, 21, 20, 3, 11, 4, 7, 7, 10, 10, 12, 17, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 11, 4, 6, 9, 6, 6, 6, 6, 6, 6, 15, 11, 16, 7, 8, 9, 8, 9, 8, 9, 8, 9, 3, 12, 5, 23, 8, 16, 8, 22, 16, 18, 19, 18, 8, 22, 18, 8, 17, 18, 19, 47, 39, 44, 22, 3, 9, 13, 9, 15, 3, 13, 10, 9, 15, 4, 3, 45, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 6, 5, 5, 4, 4, 6, 7, 7, 7, 8, 7, 4, 7, 9, 7, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 6, 6, 5, 7, 6, 3, 9, 5, 6, 14, 4, 7, 6, 7, 6, 4, 8, 6, 6, 6, 7, 7, 3, 14, 4, 5, 30, 38, 25, 13, 36, 10, 34, 34, 38, 29, 24, 39, 33, 21, 20, 15, 48, 23, 16, 14, 23, 14, 18, 20, 22, 10, 15, 10, 9, 10, 8, 12, 10, 16, 15, 12, 31, 16, 14, 16, 3, 8, 4, 33, 13, 17, 28, 36, 23, 35, 23, 11, 3, 11, 6, 5, 13, 12, 11, 5, 5, 14, 16, 15, 13, 16, 14, 4, 3, 15, 6, 37, 23, 24, 21, 21, 11, 17, 8, 10, 24, 18, 13, 17, 13, 15, 37, 47, 14, 11, 41, 16, 27, 31, 3, 15, 4, 46, 31, 14, 3, 13, 4, 4, 35, 43, 36, 16, 29, 14, 22, 17, 36, 18, 36, 3, 9, 4, 7, 9, 7, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 5, 12, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 9, 9, 9, 9, 9, 7, 10, 9, 9, 9, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 9, 9, 9, 9, 9, 9, 9, 6, 9, 10, 9, 9, 9, 9, 9, 9, 6, 12, 9, 9, 10, 9, 9, 9, 9, 6, 10, 9, 9, 9, 9, 9, 9, 9, 5, 10, 9, 9, 9, 9, 9, 9, 9, 10, 16, 14, 17, 12, 16, 13, 3, 13, 4, 28, 26, 19, 45, 15, 16, 3, 12, 5, 31, 45, 47, 49, 3, 9, 6, 23, 35, 27, 3, 11, 4, 42, 16, 39, 32, 31, 3, 12, 4, 28, 17, 3, 10, 4, 7, 12, 4, 3, 9, 7, 9, 9, 7, 7, 9, 9, 9, 9, 7, 8, 11, 13, 5, 12, 11, 4, 4, 9, 8, 7, 7, 8, 8, 7, 7, 9, 11, 13, 12, 14, 13, 7, 10, 13, 3, 13, 4, 31, 3, 12, 4, 7, 13, 12, 4, 4, 14, 14, 14, 4, 14, 12, 11, 11, 3, 10, 4, 26, 32, 32, 28, 36, 25, 20, 29, 13, 39, 10, 3, 10, 4, 7, 13, 5, 9, 3, 10, 4, 26, 12, 8, 9, 8, 8, 9, 9, 7, 9, 6, 8, 8, 6, 6, 6, 13, 10, 3, 7, 5, 31, 11, 24, 8, 3, 11, 5, 32, 31, 15, 14, 14, 11, 27, 36, 13, 33, 12, 13, 3, 13, 4, 46, 29, 30, 31, 39, 22, 13, 29, 39, 23, 20, 39, 43, 31, 30, 22, 20, 57, 3, 10, 7, 3, 44, 15, 32, 33, 39, 29, 11, 33, 34, 37, 27, 23, 19, 18, 35, 3, 13, 4, 29, 27, 46, 12, 3, 11, 4, 39, 35, 45, 41, 22, 22, 22, 3, 7, 4, 18, 32, 31, 19, 41, 22, 20, 24, 29, 21, 36, 26, 12, 31, 55, 31, 17, 19, 12, 19, 3, 9, 4, 24, 26, 43, 27, 44, 34, 23, 29, 16, 20, 30, 3, 11, 4, 23, 25, 13, 8, 24, 9, 3, 11, 4, 32, 26, 30, 27, 13, 7, 3, 11, 4, 33, 20, 8, 32, 9, 3, 9, 4, 37, 30, 27, 13, 19, 18, 3, 11, 4, 38, 20, 9, 14, 35, 32, 30, 31, 14, 33, 19, 12, 32, 3, 10, 6, 34, 39, 8, 21, 24, 36, 28, 21, 24, 22, 3, 9, 4, 38, 38, 21, 19, 13, 34, 32, 44, 3, 9, 4, 34, 37, 28, 32, 26, 11, 3, 8, 4, 4, 25, 40, 42, 32, 12, 31, 19, 37, 33, 29, 20, 27, 26, 25, 21, 3, 9, 4, 6, 33, 38, 33, 24, 20, 16, 30, 34, 28, 22, 16, 20, 22, 31, 24, 15, 35, 18, 23, 3, 9, 4, 38, 38, 21, 18, 19, 40, 17, 3, 11, 4, 26, 11, 38, 25, 26, 42, 21, 27, 3, 9, 6, 31, 39, 13, 3, 12, 4, 36, 45, 15, 9, 18, 3, 8, 4, 4, 32, 36, 44, 24, 24, 22, 27, 30, 19, 23, 23, 39, 46, 28, 13, 34, 11, 3, 12, 4, 39, 30, 43, 11, 7, 3, 9, 6, 34, 46, 28, 23, 19, 18, 30, 3, 9, 6, 24, 49, 25, 20, 16, 32, 3, 8, 5, 24, 41, 47, 15, 15, 35, 22, 3, 11, 4, 5, 30, 44, 37, 43, 25, 25, 24, 32, 32, 47, 43, 42, 19, 3, 9, 4, 4, 27, 48, 35, 21, 43, 11, 38, 26, 23, 16, 34, 24, 3, 13, 4, 5, 26, 45, 36, 23, 55, 30, 61, 35, 32, 33, 42, 36, 19, 32, 26, 48, 16, 19, 29, 25, 38, 25, 28, 43, 12, 64, 16, 12, 14, 12, 25, 22, 3, 9, 4, 4, 34, 32, 34, 35, 11, 26, 45, 41, 45, 33, 18, 38, 30, 29, 22, 44, 41, 11, 8, 30, 32, 25, 31, 19, 29, 23, 58, 23, 29, 16, 3, 9, 4, 4, 42, 34, 23, 18, 21, 28, 22, 40, 30, 32, 31, 22, 51, 31, 32, 37, 28, 19, 21, 3, 10, 4, 38, 41, 20, 29, 35, 51, 16, 23, 9, 15, 22, 24, 36, 34, 33, 51, 18, 14, 38, 25, 45, 3, 10, 4, 4, 40, 35, 22, 36, 35, 26, 13, 6, 18, 13, 38, 28, 12, 15, 26, 23, 25, 27, 38, 17, 20, 51, 3, 11, 4, 37, 29, 24, 25, 43, 23, 44, 14, 3, 13, 5, 29, 24, 36, 26, 8, 3, 11, 6, 40, 29, 46, 10, 10, 12, 7, 27, 58, 3, 8, 5, 35, 57, 42, 30, 34, 9, 30, 3, 9, 4, 28, 27, 13, 22, 11, 32, 48, 23, 26, 24, 30, 28, 21, 19, 3, 11, 4, 37, 44, 30, 16, 39, 42, 11, 28, 9, 32, 22, 3, 12, 4, 30, 22, 20, 22, 24, 3, 11, 6, 37, 20, 24, 17, 9, 13, 16, 24, 22, 23, 22, 20, 3, 12, 4, 28, 18, 27, 20, 21, 9, 7, 3, 12, 4, 8, 8, 8, 6, 11, 7, 3, 12, 4, 30, 37, 20, 13, 23, 32, 14, 29, 44, 18, 34, 24, 22, 13, 25, 19, 13, 3, 10, 5, 4, 9, 7, 5, 6, 4, 9, 7, 5, 6, 12, 8, 3, 9, 4, 7, 6, 8, 10, 9, 9, 9, 7, 28, 20, 9, 10, 11, 3, 8, 4, 23, 40, 31, 24, 21, 20, 34, 27, 36, 40, 17, 3, 10, 4, 27, 26, 24, 11, 12, 34, 3, 9, 4, 7, 10, 25, 6, 18, 46, 10, 34, 29, 17, 11, 8, 22, 17, 23, 35, 6, 13, 18, 16, 18, 22, 11, 33, 3, 11, 15, 11, 17, 17, 9, 9, 8, 6, 11, 9, 10, 11, 10, 6, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 10, 3, 11, 4, 4, 29, 25, 29, 25, 23, 23, 30, 27, 25, 16, 34, 27, 13, 30, 19, 29, 41, 32, 40, 22, 3, 10, 5, 5, 5, 9, 12, 8, 12, 8, 7, 4, 11, 29, 19, 31, 28, 47, 29, 19, 16, 11, 7, 22, 20, 7, 10, 22, 38, 31, 37, 26, 53, 21, 20, 15, 11, 23, 45, 43, 41, 23, 3, 10, 4, 4, 31, 46, 42, 34, 42, 36, 25, 20, 39, 41, 43, 38, 31, 13, 3, 10, 4, 39, 41, 9, 29, 38, 23, 14, 15, 3, 10, 4, 39, 37, 9, 29, 17, 36, 28, 30, 48, 46, 20, 21, 3, 13, 5, 39, 39, 38, 15, 31, 15, 3, 11, 4, 36, 38, 32, 15, 26, 22, 33, 35, 40, 3, 11, 4, 6, 29, 17, 33, 12, 18, 31, 23, 17, 26, 31, 22, 21, 14, 9, 30, 39, 10, 18, 16, 14, 35, 21, 26, 14, 20, 14, 8, 20, 29, 33, 14, 35, 10, 3, 11, 4, 32, 21, 36, 15, 7, 3, 12, 4, 33, 56, 32, 42, 29, 25, 8, 3, 11, 23, 15, 9, 9, 6, 3, 25, 6, 4, 34, 52, 6, 4, 29, 36, 6, 3, 41, 18, 3, 10, 4, 9, 10, 5, 8, 6, 9, 9, 13, 3, 9, 4, 9, 10, 5, 8, 6, 6, 9, 15, 3, 13, 4, 33, 35, 35, 22, 13, 15, 8, 3, 8, 4, 25, 32, 52, 24, 3, 11, 7, 23, 23, 54, 16, 24, 31, 3, 9, 5, 30, 39, 42, 24, 48, 34, 40, 33, 19, 3, 13, 7, 35, 26, 34, 29, 31, 30, 40, 38, 32, 3, 12, 6, 13, 7, 3, 12, 6, 13, 25, 6, 3, 12, 6, 32, 38, 27, 43, 3, 13, 4, 25, 30, 5, 3, 9, 6, 22, 31, 12, 13, 9, 12, 22, 53, 43, 34, 3, 12, 7, 25, 4, 12, 15, 6, 3, 14, 6, 23, 25, 3, 12, 6, 5, 14, 9, 15, 12, 11, 11, 10, 11, 10, 10, 9, 12, 11, 10, 12, 5, 10, 10, 5, 6, 11, 5, 5, 3, 10, 6, 16, 3, 11, 8, 9, 8, 7, 7, 7, 7, 8, 7, 9, 12, 13, 9, 12, 11, 8, 3, 9, 9, 8, 7, 8, 9, 9, 7, 7, 8, 8, 8, 8, 14, 4, 11, 13, 3, 9, 6, 6, 8, 10, 10, 13, 9, 9, 9, 9, 9, 9, 9, 9, 9, 35, 33, 12, 11, 9, 9, 9, 9, 9, 9, 9, 9, 10, 9, 9, 9, 9, 10, 33, 11, 4, 14, 14, 14, 15, 10, 4, 14, 7, 11, 6, 10, 7, 12, 6, 3, 14, 6, 24, 29, 27, 4, 40, 38, 3, 12, 6, 30, 23, 20, 33, 19, 23, 11, 35, 30, 29, 13, 11, 19, 14, 34, 24, 22, 11, 13, 17, 31, 16, 19, 16, 23, 47, 14, 9, 20, 37, 13, 10, 24, 14, 36, 24, 16, 13, 34, 11, 22, 25, 21, 3, 14, 4, 37, 34, 34, 40, 46, 22, 16, 3, 11, 4, 7, 13, 9, 8, 6, 9, 6, 9, 9, 6, 9, 6, 6, 9, 10, 9, 9, 10, 10, 6, 10, 6, 6, 3, 12, 4, 8, 9, 6, 6, 7, 7, 6, 6, 6, 5, 6, 7, 6, 6, 6, 7, 6, 8, 6, 7, 3, 13, 4, 23, 33, 5, 3, 13, 4, 23, 10, 5, 3, 13, 4, 34, 45, 28, 32, 18, 51, 3, 8, 4, 6, 17, 10, 4, 11, 10, 11, 11, 10, 10, 10, 10, 10, 11, 4, 10, 12, 10, 10, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 12, 10, 11, 11, 11, 3, 8, 4, 6, 17, 11, 4, 10, 10, 10, 10, 10, 12, 10, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 11, 11, 10, 11, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 11, 11, 10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 11, 10, 10, 10, 10, 10, 10, 3, 8, 4, 6, 6, 4, 7, 7, 6, 12, 4, 4, 6, 8, 6, 6, 6, 4, 6, 7, 7, 7, 8, 3, 8, 4, 7, 5, 4, 6, 6, 7, 6, 6, 7, 6, 6, 12, 10, 4, 6, 6, 7, 7, 6, 6, 6, 6, 7, 5, 7, 4, 6, 7, 6, 6, 6, 6, 7, 6, 6, 6, 6, 3, 9, 4, 15, 12, 21, 9, 12, 12, 9, 12, 27, 9, 19, 40, 9, 31, 15, 33, 20, 3, 12, 4, 8, 11, 15, 7, 15, 7, 14, 13, 13, 13, 13, 14, 13, 14, 14, 3, 13, 4, 25, 4, 23, 11, 5, 3, 12, 4, 4, 36, 34, 39, 42, 29, 38, 25, 36, 34, 48, 38, 25, 46, 15, 37, 111, 95, 3, 12, 4, 27, 4, 18, 7, 14, 16, 10, 6, 9, 3, 12, 4, 36, 38, 26, 3, 13, 4, 22, 8, 3, 10, 4, 6, 8, 4, 9, 9, 9, 6, 7, 6, 16, 7, 11, 10, 13, 10, 10, 10, 10, 10, 13, 10, 13, 10, 4, 9, 10, 7, 9, 6, 15, 4, 10, 11, 10, 10, 11, 13, 10, 10, 13, 13, 10, 13, 3, 12, 6, 35, 30, 34, 19, 17, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 9, 4, 8, 8, 5, 16, 5, 16, 3, 12, 4, 22, 4, 22, 5, 3, 14, 4, 19, 5, 3, 12, 4, 23, 4, 7, 5, 3, 9, 4, 30, 3, 12, 4, 20, 14, 5, 3, 12, 4, 22, 9, 5, 3, 11, 4, 22, 16, 5, 3, 12, 5, 29, 25, 30, 39, 19, 28, 25, 19, 23, 27, 15, 20, 21, 20, 20, 22, 22, 31, 24, 10, 18, 3, 10, 5, 54, 3, 13, 6, 31, 21, 28, 28, 20, 29, 41, 24, 28, 31, 19, 13, 9, 21, 17, 32, 17, 8, 18, 9, 13, 18, 16, 32, 34, 16, 3, 16, 4, 5, 42, 21, 21, 15, 38, 43, 9, 30, 24, 24, 19, 36, 12, 24, 21, 31, 26, 3, 12, 5, 23, 54, 24, 3, 14, 5, 23, 12, 6, 6, 5, 5, 12, 12, 5, 6, 6, 6, 3, 10, 5, 21, 4, 21, 10, 5, 3, 12, 5, 5, 13, 11, 4, 4, 6, 8, 7, 8, 8, 8, 4, 7, 7, 8, 7, 8, 4, 7, 7, 8, 8, 7, 6, 5, 5, 5, 5, 5, 6, 4, 4, 6, 7, 8, 8, 9, 8, 4, 7, 9, 8, 7, 7, 4, 8, 8, 7, 8, 7, 5, 5, 7, 5, 6, 6, 6, 3, 9, 5, 6, 14, 4, 7, 6, 10, 6, 7, 6, 6, 4, 10, 10, 6, 7, 11, 6, 8, 7, 3, 13, 4, 37, 35, 13, 22, 27, 24, 26, 28, 17, 14, 44, 38, 13, 24, 14, 20, 12, 13, 39, 20, 45, 14, 32, 39, 18, 24, 18, 12, 12, 36, 39, 23, 28, 29, 32, 20, 20, 26, 14, 34, 15, 26, 3, 10, 4, 5, 41, 47, 9, 32, 31, 27, 16, 9, 34, 44, 19, 9, 12, 27, 17, 21, 18, 33, 24, 14, 22, 16, 14, 3, 11, 4, 31, 3, 12, 4, 4, 38, 22, 36, 29, 26, 28, 17, 27, 31, 16, 8, 20, 19, 4, 48, 42, 3, 10, 4, 26, 3, 14, 4, 29, 42, 39, 21, 23, 47, 38, 39, 4, 93, 107, 3, 11, 4, 18, 16, 5, 3, 12, 4, 4, 32, 27, 11, 33, 43, 38, 51, 44, 34, 30, 26, 4, 85, 81, 20, 13, 20, 21, 3, 11, 4, 33, 5, 5, 3, 10, 4, 8, 8, 8, 3, 13, 4, 6, 15, 4, 4, 15, 9, 5, 3, 14, 4, 19, 5, 3, 10, 4, 35, 46, 28, 40, 3, 13, 4, 7, 14, 4, 14, 7, 14, 3, 10, 4, 28, 3, 10, 4, 7, 14, 10, 13, 10, 9, 10, 12, 7, 10, 3, 12, 4, 20, 40, 27, 27, 15, 12, 28, 3, 10, 4, 8, 6, 7, 8, 11, 3, 11, 4, 19, 4, 15, 9, 5, 3, 10, 4, 37, 45, 24, 27, 10, 21, 36, 37, 33, 3, 9, 4, 18, 9, 20, 23, 35, 26, 18, 27, 9, 21, 11, 14, 24, 24, 27, 17, 11, 25, 9, 13, 34, 10, 21, 10, 18, 24, 12, 22, 18, 18, 14, 21, 18, 15, 35, 34, 37, 3, 7, 4, 29, 36, 29, 31, 18, 12, 31, 3, 9, 6, 37, 28, 39, 29, 29, 31, 3, 10, 4, 28, 8, 20, 32, 39, 14, 20, 10, 3, 8, 4, 28, 35, 11, 23, 21, 18, 23, 27, 20, 3, 11, 4, 32, 45, 42, 23, 20, 36, 45, 3, 11, 4, 26, 34, 33, 3, 9, 4, 12, 6, 6, 25, 7, 8, 8, 8, 8, 9, 9, 8, 8, 3, 10, 5, 36, 28, 21, 32, 46, 23, 8, 35, 39, 3, 11, 4, 30, 42, 37, 34, 36, 25, 45, 24, 13, 12, 41, 3, 10, 6, 37, 17, 25, 33, 13, 22, 15, 23, 31, 3, 10, 4, 6, 33, 47, 15, 35, 3, 39, 41, 31, 21, 17, 18, 33, 44, 22, 26, 28, 17, 7, 8, 44, 3, 38, 21, 14, 3, 13, 4, 38, 41, 32, 44, 44, 35, 22, 31, 28, 31, 22, 22, 45, 9, 3, 10, 4, 26, 25, 16, 31, 3, 11, 4, 29, 30, 38, 77, 22, 27, 14, 13, 23, 21, 3, 9, 4, 37, 37, 22, 21, 31, 11, 3, 11, 5, 32, 39, 30, 21, 16, 38, 3, 11, 4, 38, 46, 46, 12, 33, 41, 23, 14, 17, 37, 26, 23, 26, 3, 12, 4, 35, 29, 15, 23, 16, 26, 21, 3, 12, 4, 4, 39, 48, 31, 36, 12, 31, 36, 36, 18, 12, 33, 14, 40, 27, 31, 22, 27, 17, 13, 20, 40, 26, 35, 26, 32, 8, 11, 3, 9, 4, 34, 16, 11, 21, 22, 32, 8, 3, 12, 4, 32, 41, 14, 16, 27, 18, 38, 10, 29, 3, 8, 4, 24, 39, 31, 38, 16, 25, 39, 29, 37, 38, 3, 9, 4, 23, 27, 24, 13, 39, 29, 38, 3, 9, 5, 36, 32, 23, 50, 11, 3, 10, 4, 29, 32, 7, 28, 18, 29, 15, 8, 3, 11, 4, 30, 8, 18, 28, 43, 13, 14, 36, 24, 29, 12, 17, 17, 3, 10, 4, 35, 50, 30, 15, 30, 30, 33, 21, 3, 9, 4, 43, 20, 29, 3, 9, 4, 18, 33, 18, 9, 3, 12, 4, 30, 28, 30, 54, 58, 32, 3, 12, 4, 35, 16, 7, 8, 27, 3, 10, 4, 14, 16, 4, 23, 17, 4, 12, 25, 9, 3, 12, 4, 41, 33, 30, 53, 19, 31, 42, 37, 25, 27, 31, 12, 3, 12, 6, 8, 21, 16, 32, 26, 21, 10, 21, 3, 12, 4, 33, 54, 12, 19, 25, 3, 12, 4, 4, 38, 57, 41, 11, 35, 23, 33, 24, 30, 21, 30, 58, 21, 37, 17, 31, 3, 9, 4, 19, 14, 14, 23, 42, 39, 3, 10, 4, 24, 33, 20, 34, 30, 12, 43, 38, 3, 12, 4, 34, 38, 38, 19, 36, 21, 15, 26, 38, 25, 32, 23, 22, 24, 3, 10, 4, 26, 45, 43, 10, 26, 8, 44, 23, 32, 3, 10, 4, 23, 18, 32, 3, 9, 4, 26, 32, 11, 27, 3, 11, 4, 26, 23, 47, 30, 9, 37, 3, 10, 4, 6, 40, 37, 31, 34, 34, 11, 6, 37, 33, 16, 20, 36, 26, 23, 14, 29, 28, 23, 10, 41, 38, 28, 3, 12, 4, 46, 11, 17, 15, 18, 22, 24, 27, 6]\n[3, 13, 4, 37, 39, 40, 26, 32, 36, 41, 43, 27, 36, 33, 30, 24, 11, 3, 9, 4, 16, 14, 15, 9, 32, 20, 37, 27, 27, 29, 28, 3]"
     ]
    }
   ],
   "source": [
    "f1_history = []\n",
    "mean_loss_history = []\n",
    "\n",
    "# Alterar numero de epocas de treinamento (~30-50 epocas para modelo bem treinado)\n",
    "for epoch in range(10):\n",
    "    mean_loss = 0.0\n",
    "    model.train()\n",
    "    # Iniciando uma epoch de treinamento supervisionado\n",
    "    for batch in range(len(train_x)):\n",
    "        x = train_x[batch].to(device)\n",
    "        y = train_y[batch].to(device)\n",
    "        m = mask[batch].to(device)\n",
    "        optim.zero_grad()\n",
    "        loss = -model(x, y, m)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optim.step()\n",
    "        mean_loss += loss\n",
    "    mean_loss /= len(train_x)\n",
    "    mean_loss_history.append(mean_loss)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    # Calculo do desempenho do modelo treinado nesta epoch\n",
    "    y_pred = model.decode(valid_x[0].to(device), valid_mask[0].to(device))\n",
    "    y_pred = IOBify(y_pred, idx2tag)\n",
    "    y_true = IOBify(valid_y, idx2tag)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    f1_history.append(f1)\n",
    "\n",
    "    print(f'Epoch: {epoch} | Loss media: {mean_loss} | f1-score: {f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "mean_loss_history = [y.to(device).detach().numpy() for y in mean_loss_history]\n",
    "#tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_loss_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(f1_history)\n",
    "axs[1].plot(mean_loss_history)\n",
    "axs[0].set(ylabel='f1-score')\n",
    "axs[1].set(xlabel='epochs', ylabel='mean loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Utilização do modelo treinado para predição em novos dados e interface com usuário\n",
    "\n",
    "Passos:\n",
    "\n",
    "\n",
    "1.   Transformar as palavras do texto em indices utilizando o dicionario word2idx e converter para tensor\n",
    "2.   Realizar as predições\n",
    "3.   Realizar extração das entidades de acordo com as predições\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_teste_path = '/content' + '/ner_train_sem_label_teste_01_ajuste.txt'\n",
    "#x_teste_path = '/content' + '/ner_train_sem_label_teste_01.txt'\n",
    "x_teste_path = '/content' + '/ner_train_sem_label_teste_1.txt'\n",
    "f_x = open(x_teste_path, 'r').read().splitlines()\n",
    "len(f_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x_l = []\n",
    "for i in f_x:\n",
    "  #print(i)\n",
    "  if i != '':\n",
    "    f_x_l.append(i)\n",
    "len(f_x_l)\n",
    "#print(y_pred_1[1:20])\n",
    "f_x = f_x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "x_test_dataloader = DataLoader(dataset = f_x, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(len(x_test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar as palavras do texto em indices utilizando o dicionario word2idx e converter para tensor\n",
    "\n",
    "for i, data_batch in enumerate(x_test_dataloader):\n",
    "  if i % 10 == 0: print(i)\n",
    "  text = f_x\n",
    "  num_text = torch.LongTensor([word2idx['<UNK>'] if word not in word2idx else word2idx[word] for word in text]).unsqueeze(dim=0)\n",
    "  mask = num_text != -1\n",
    "  num_text.shape, mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Realizar predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvcc --version\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_o \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mnum_text\u001b[49m, mask)\n\u001b[1;32m      2\u001b[0m y_pred_o \u001b[38;5;241m=\u001b[39m IOBify(y_pred_o, idx2tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_text' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_o = model.decode(num_text, mask)\n",
    "y_pred_o = IOBify(y_pred_o, idx2tag)\n",
    "#y_pred = IOBify(y_pred)\n",
    "#for idx, (word, tag) in enumerate(zip(text, y_pred_o[0])):\n",
    "#for idx, (word) in enumerate(zip(text, y_pred[0])):\n",
    "#    print(word)\n",
    "#    if idx >= 20:\n",
    "#        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_o)\n",
    "y_pred_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3: Realizar extração das entidades de acordo com as predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(y_pred, text):\n",
    "    inside_entity = False\n",
    "    entity_type = ''\n",
    "    entity = ''\n",
    "    entities = []\n",
    "    for word, tag in zip(text, y_pred[0]):\n",
    "        if not inside_entity:\n",
    "            if tag[0] == 'B':\n",
    "                inside_entity = True\n",
    "                entity = word\n",
    "                entity_type = tag[2:]\n",
    "        else:\n",
    "            if tag[0] == 'B':\n",
    "                entities.append((entity, entity_type ))\n",
    "                entity = word\n",
    "                entity_type = tag[2:]\n",
    "                inside_entity = True\n",
    "            elif tag[0] == 'I':\n",
    "                entity = entity + ' ' + word\n",
    "                inside_entity = True\n",
    "            else:\n",
    "                entities.append((entity, entity_type))\n",
    "                entity = ''\n",
    "                entity_type = 'O'\n",
    "                inside_entity = False\n",
    "    return entities\n",
    "\n",
    "entities = extract_entities(y_pred_o, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y_o_list = []\n",
    "for i in valid_y_o:\n",
    "   if not isinstance(i, list):\n",
    "      valid_y_o_list.append(i)\n",
    "   else:\n",
    "      for j in i:\n",
    "        valid_y_o_list.append(j)\n",
    "\n",
    "len(valid_y_o_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_o_list = []\n",
    "for i in y_pred_o:\n",
    "   if not isinstance(i, list):\n",
    "      y_pred_o_list.append(i)\n",
    "   else:\n",
    "      for j in i:\n",
    "        y_pred_o_list.append(j)\n",
    "\n",
    "len(y_pred_o_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "f1_score([valid_y_o_list], y_pred_o)\n",
    "\n",
    "#len(y_pred)\n",
    "#len(y_true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "accuracy_score([valid_y_o_list], y_pred_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(idx2tag.values())\n",
    "label.remove('<PAD>')\n",
    "label.remove('O')\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "# group B and I results\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    label,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(classification_report([valid_y_o_list], [y_pred_o_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn import metrics\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    label,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(sklearn.metrics.classification_report(valid_y_o_list, y_pred_o_list,labels=['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC'],target_names=sorted_labels, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a364e88e268f24bb4b4cd28b7ddb26344d4bee608858daf4c5718cf9ad82c2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
